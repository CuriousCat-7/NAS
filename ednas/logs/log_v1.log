[33mIP:10.60.242.134 [0m[32m[0229 14:07:51 @trainer.py:217][0m Start to train w for epoch 0
[33mIP:10.60.242.134 [0m[32m[0229 14:07:51 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:08:09 @trainer.py:198][0m Epoch[0] Batch[100] Speed: 364.187548 samples/sec loss: -30.17936 acc: 0.16368 ce: 2.19656 lat: -16.18796
[33mIP:10.60.242.134 [0m[32m[0229 14:08:25 @trainer.py:198][0m Epoch[0] Batch[200] Speed: 392.103099 samples/sec loss: -30.27877 acc: 0.20040 ce: 2.09729 lat: -16.18803
[33mIP:10.60.242.134 [0m[32m[0229 14:08:41 @trainer.py:198][0m Epoch[0] Batch[300] Speed: 392.788007 samples/sec loss: -30.34255 acc: 0.22244 ce: 2.03359 lat: -16.18807
[33mIP:10.60.242.134 [0m[32m[0229 14:08:57 @trainer.py:198][0m Epoch[0] Batch[400] Speed: 403.699122 samples/sec loss: -30.37867 acc: 0.23691 ce: 1.99748 lat: -16.18807
[33mIP:10.60.242.134 [0m[32m[0229 14:09:12 @trainer.py:198][0m Epoch[0] Batch[500] Speed: 421.014038 samples/sec loss: -30.40955 acc: 0.24891 ce: 1.96663 lat: -16.18809
[33mIP:10.60.242.134 [0m[32m[0229 14:09:27 @trainer.py:198][0m Epoch[0] Batch[600] Speed: 424.995685 samples/sec loss: -30.43475 acc: 0.25939 ce: 1.94145 lat: -16.18810
[33mIP:10.60.242.134 [0m[32m[0229 14:09:35 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:09:35 @trainer.py:233][0m acc curve [0.2524]
[33mIP:10.60.242.134 [0m[32m[0229 14:09:35 @trainer.py:234][0m acc 0.2524
[33mIP:10.60.242.134 [0m[32m[0229 14:09:35 @trainer.py:235][0m max_acc 0.2524
[33mIP:10.60.242.134 [0m[32m[0229 14:09:35 @trainer.py:217][0m Start to train w for epoch 1
[33mIP:10.60.242.134 [0m[32m[0229 14:09:35 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:09:51 @trainer.py:198][0m Epoch[1] Batch[100] Speed: 265.808358 samples/sec loss: -30.45460 acc: 0.26720 ce: 1.92157 lat: -16.18808
[33mIP:10.60.242.134 [0m[32m[0229 14:10:08 @trainer.py:198][0m Epoch[1] Batch[200] Speed: 395.209388 samples/sec loss: -30.47299 acc: 0.27546 ce: 1.90319 lat: -16.18809
[33mIP:10.60.242.134 [0m[32m[0229 14:10:23 @trainer.py:198][0m Epoch[1] Batch[300] Speed: 407.863097 samples/sec loss: -30.49238 acc: 0.28446 ce: 1.88374 lat: -16.18806
[33mIP:10.60.242.134 [0m[32m[0229 14:10:40 @trainer.py:198][0m Epoch[1] Batch[400] Speed: 373.516461 samples/sec loss: -30.51107 acc: 0.29298 ce: 1.86506 lat: -16.18807
[33mIP:10.60.242.134 [0m[32m[0229 14:10:57 @trainer.py:198][0m Epoch[1] Batch[500] Speed: 378.568673 samples/sec loss: -30.53053 acc: 0.30064 ce: 1.84562 lat: -16.18808
[33mIP:10.60.242.134 [0m[32m[0229 14:11:13 @trainer.py:198][0m Epoch[1] Batch[600] Speed: 409.050052 samples/sec loss: -30.54841 acc: 0.30786 ce: 1.82777 lat: -16.18809
[33mIP:10.60.242.134 [0m[32m[0229 14:11:21 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:11:21 @trainer.py:233][0m acc curve [0.2524, 0.3558]
[33mIP:10.60.242.134 [0m[32m[0229 14:11:21 @trainer.py:234][0m acc 0.3558
[33mIP:10.60.242.134 [0m[32m[0229 14:11:21 @trainer.py:235][0m max_acc 0.3558
[33mIP:10.60.242.134 [0m[32m[0229 14:11:21 @trainer.py:217][0m Start to train w for epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:11:21 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:11:37 @trainer.py:198][0m Epoch[2] Batch[100] Speed: 263.343605 samples/sec loss: -30.57039 acc: 0.31758 ce: 1.80578 lat: -16.18809
[33mIP:10.60.242.134 [0m[32m[0229 14:11:52 @trainer.py:198][0m Epoch[2] Batch[200] Speed: 422.396727 samples/sec loss: -30.58579 acc: 0.32390 ce: 1.79036 lat: -16.18808
[33mIP:10.60.242.134 [0m[32m[0229 14:12:08 @trainer.py:198][0m Epoch[2] Batch[300] Speed: 403.869656 samples/sec loss: -30.59990 acc: 0.32979 ce: 1.77627 lat: -16.18808
[33mIP:10.60.242.134 [0m[32m[0229 14:12:25 @trainer.py:198][0m Epoch[2] Batch[400] Speed: 385.296429 samples/sec loss: -30.61364 acc: 0.33553 ce: 1.76253 lat: -16.18809
[33mIP:10.60.242.134 [0m[32m[0229 14:12:41 @trainer.py:198][0m Epoch[2] Batch[500] Speed: 389.862928 samples/sec loss: -30.62578 acc: 0.34082 ce: 1.75039 lat: -16.18809
[33mIP:10.60.242.134 [0m[32m[0229 14:12:57 @trainer.py:198][0m Epoch[2] Batch[600] Speed: 415.405066 samples/sec loss: -30.63744 acc: 0.34512 ce: 1.73873 lat: -16.18809
[33mIP:10.60.242.134 [0m[32m[0229 14:13:00 @trainer.py:173][0m Change temperature from 5.00000 to 4.78000
[33mIP:10.60.242.134 [0m[32m[0229 14:13:05 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:13:05 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917]
[33mIP:10.60.242.134 [0m[32m[0229 14:13:05 @trainer.py:234][0m acc 0.3917
[33mIP:10.60.242.134 [0m[32m[0229 14:13:05 @trainer.py:235][0m max_acc 0.3917
[33mIP:10.60.242.134 [0m[32m[0229 14:13:05 @trainer.py:217][0m Start to train w for epoch 3
[33mIP:10.60.242.134 [0m[32m[0229 14:13:05 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:13:20 @trainer.py:198][0m Epoch[3] Batch[100] Speed: 272.713191 samples/sec loss: -30.64746 acc: 0.34981 ce: 1.72873 lat: -16.18810
[33mIP:10.60.242.134 [0m[32m[0229 14:13:35 @trainer.py:198][0m Epoch[3] Batch[200] Speed: 429.283146 samples/sec loss: -30.65402 acc: 0.35277 ce: 1.72216 lat: -16.18809
[33mIP:10.60.242.134 [0m[32m[0229 14:13:50 @trainer.py:198][0m Epoch[3] Batch[300] Speed: 434.551214 samples/sec loss: -30.66137 acc: 0.35581 ce: 1.71482 lat: -16.18810
[33mIP:10.60.242.134 [0m[32m[0229 14:14:05 @trainer.py:198][0m Epoch[3] Batch[400] Speed: 423.609660 samples/sec loss: -30.66922 acc: 0.35935 ce: 1.70699 lat: -16.18810
[33mIP:10.60.242.134 [0m[32m[0229 14:14:20 @trainer.py:198][0m Epoch[3] Batch[500] Speed: 434.112737 samples/sec loss: -30.67655 acc: 0.36216 ce: 1.69966 lat: -16.18810
[33mIP:10.60.242.134 [0m[32m[0229 14:14:35 @trainer.py:198][0m Epoch[3] Batch[600] Speed: 420.123558 samples/sec loss: -30.68403 acc: 0.36548 ce: 1.69218 lat: -16.18811
[33mIP:10.60.242.134 [0m[32m[0229 14:14:39 @trainer.py:173][0m Change temperature from 4.78000 to 4.56968
[33mIP:10.60.242.134 [0m[32m[0229 14:14:42 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:14:42 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345]
[33mIP:10.60.242.134 [0m[32m[0229 14:14:42 @trainer.py:234][0m acc 0.4345
[33mIP:10.60.242.134 [0m[32m[0229 14:14:42 @trainer.py:235][0m max_acc 0.4345
[33mIP:10.60.242.134 [0m[32m[0229 14:14:42 @trainer.py:217][0m Start to train w for epoch 4
[33mIP:10.60.242.134 [0m[32m[0229 14:14:42 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:14:58 @trainer.py:198][0m Epoch[4] Batch[100] Speed: 281.116921 samples/sec loss: -30.69429 acc: 0.36995 ce: 1.68192 lat: -16.18810
[33mIP:10.60.242.134 [0m[32m[0229 14:15:14 @trainer.py:198][0m Epoch[4] Batch[200] Speed: 402.361309 samples/sec loss: -30.70294 acc: 0.37360 ce: 1.67327 lat: -16.18810
[33mIP:10.60.242.134 [0m[32m[0229 14:15:29 @trainer.py:198][0m Epoch[4] Batch[300] Speed: 408.718514 samples/sec loss: -30.71075 acc: 0.37680 ce: 1.66544 lat: -16.18810
[33mIP:10.60.242.134 [0m[32m[0229 14:15:45 @trainer.py:198][0m Epoch[4] Batch[400] Speed: 404.162450 samples/sec loss: -30.71931 acc: 0.38035 ce: 1.65690 lat: -16.18811
[33mIP:10.60.242.134 [0m[32m[0229 14:16:01 @trainer.py:198][0m Epoch[4] Batch[500] Speed: 409.316802 samples/sec loss: -30.72699 acc: 0.38366 ce: 1.64925 lat: -16.18812
[33mIP:10.60.242.134 [0m[32m[0229 14:16:16 @trainer.py:198][0m Epoch[4] Batch[600] Speed: 415.035980 samples/sec loss: -30.73435 acc: 0.38651 ce: 1.64190 lat: -16.18812
[33mIP:10.60.242.134 [0m[32m[0229 14:16:20 @trainer.py:173][0m Change temperature from 4.56968 to 4.36861
[33mIP:10.60.242.134 [0m[32m[0229 14:16:24 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:16:24 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671]
[33mIP:10.60.242.134 [0m[32m[0229 14:16:24 @trainer.py:234][0m acc 0.4671
[33mIP:10.60.242.134 [0m[32m[0229 14:16:24 @trainer.py:235][0m max_acc 0.4671
[33mIP:10.60.242.134 [0m[32m[0229 14:16:24 @trainer.py:217][0m Start to train w for epoch 5
[33mIP:10.60.242.134 [0m[32m[0229 14:16:24 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:16:40 @trainer.py:198][0m Epoch[5] Batch[100] Speed: 269.232057 samples/sec loss: -30.74403 acc: 0.39045 ce: 1.63221 lat: -16.18812
[33mIP:10.60.242.134 [0m[32m[0229 14:16:55 @trainer.py:198][0m Epoch[5] Batch[200] Speed: 427.612409 samples/sec loss: -30.75193 acc: 0.39377 ce: 1.62432 lat: -16.18812
[33mIP:10.60.242.134 [0m[32m[0229 14:17:10 @trainer.py:198][0m Epoch[5] Batch[300] Speed: 422.601044 samples/sec loss: -30.75993 acc: 0.39725 ce: 1.61632 lat: -16.18812
[33mIP:10.60.242.134 [0m[32m[0229 14:17:25 @trainer.py:198][0m Epoch[5] Batch[400] Speed: 427.991862 samples/sec loss: -30.76733 acc: 0.40036 ce: 1.60893 lat: -16.18813
[33mIP:10.60.242.134 [0m[32m[0229 14:17:40 @trainer.py:198][0m Epoch[5] Batch[500] Speed: 425.586543 samples/sec loss: -30.77499 acc: 0.40352 ce: 1.60126 lat: -16.18813
[33mIP:10.60.242.134 [0m[32m[0229 14:17:55 @trainer.py:198][0m Epoch[5] Batch[600] Speed: 422.273774 samples/sec loss: -30.78222 acc: 0.40660 ce: 1.59404 lat: -16.18813
[33mIP:10.60.242.134 [0m[32m[0229 14:17:59 @trainer.py:173][0m Change temperature from 4.36861 to 4.17640
[33mIP:10.60.242.134 [0m[32m[0229 14:18:02 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:18:02 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898]
[33mIP:10.60.242.134 [0m[32m[0229 14:18:02 @trainer.py:234][0m acc 0.4898
[33mIP:10.60.242.134 [0m[32m[0229 14:18:02 @trainer.py:235][0m max_acc 0.4898
[33mIP:10.60.242.134 [0m[32m[0229 14:18:02 @trainer.py:217][0m Start to train w for epoch 6
[33mIP:10.60.242.134 [0m[32m[0229 14:18:02 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:18:18 @trainer.py:198][0m Epoch[6] Batch[100] Speed: 279.080864 samples/sec loss: -30.79109 acc: 0.41034 ce: 1.58517 lat: -16.18813
[33mIP:10.60.242.134 [0m[32m[0229 14:18:34 @trainer.py:198][0m Epoch[6] Batch[200] Speed: 411.663620 samples/sec loss: -30.79818 acc: 0.41318 ce: 1.57808 lat: -16.18813
[33mIP:10.60.242.134 [0m[32m[0229 14:18:49 @trainer.py:198][0m Epoch[6] Batch[300] Speed: 405.477428 samples/sec loss: -30.80529 acc: 0.41623 ce: 1.57098 lat: -16.18814
[33mIP:10.60.242.134 [0m[32m[0229 14:19:05 @trainer.py:198][0m Epoch[6] Batch[400] Speed: 412.565034 samples/sec loss: -30.81195 acc: 0.41881 ce: 1.56433 lat: -16.18814
[33mIP:10.60.242.134 [0m[32m[0229 14:19:20 @trainer.py:198][0m Epoch[6] Batch[500] Speed: 412.692524 samples/sec loss: -30.81751 acc: 0.42109 ce: 1.55877 lat: -16.18814
[33mIP:10.60.242.134 [0m[32m[0229 14:19:36 @trainer.py:198][0m Epoch[6] Batch[600] Speed: 413.382988 samples/sec loss: -30.82331 acc: 0.42339 ce: 1.55296 lat: -16.18814
[33mIP:10.60.242.134 [0m[32m[0229 14:19:40 @trainer.py:173][0m Change temperature from 4.17640 to 3.99263
[33mIP:10.60.242.134 [0m[32m[0229 14:19:43 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:19:43 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984]
[33mIP:10.60.242.134 [0m[32m[0229 14:19:43 @trainer.py:234][0m acc 0.4984
[33mIP:10.60.242.134 [0m[32m[0229 14:19:43 @trainer.py:235][0m max_acc 0.4984
[33mIP:10.60.242.134 [0m[32m[0229 14:19:43 @trainer.py:217][0m Start to train w for epoch 7
[33mIP:10.60.242.134 [0m[32m[0229 14:19:43 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:19:59 @trainer.py:198][0m Epoch[7] Batch[100] Speed: 280.594016 samples/sec loss: -30.82879 acc: 0.42578 ce: 1.54749 lat: -16.18814
[33mIP:10.60.242.134 [0m[32m[0229 14:20:14 @trainer.py:198][0m Epoch[7] Batch[200] Speed: 410.618847 samples/sec loss: -30.83259 acc: 0.42739 ce: 1.54369 lat: -16.18814
[33mIP:10.60.242.134 [0m[32m[0229 14:20:30 @trainer.py:198][0m Epoch[7] Batch[300] Speed: 400.377827 samples/sec loss: -30.83607 acc: 0.42894 ce: 1.54021 lat: -16.18814
[33mIP:10.60.242.134 [0m[32m[0229 14:20:46 @trainer.py:198][0m Epoch[7] Batch[400] Speed: 409.699105 samples/sec loss: -30.83977 acc: 0.43047 ce: 1.53652 lat: -16.18814
[33mIP:10.60.242.134 [0m[32m[0229 14:21:01 @trainer.py:198][0m Epoch[7] Batch[500] Speed: 417.199958 samples/sec loss: -30.84352 acc: 0.43197 ce: 1.53278 lat: -16.18815
[33mIP:10.60.242.134 [0m[32m[0229 14:21:17 @trainer.py:198][0m Epoch[7] Batch[600] Speed: 419.347382 samples/sec loss: -30.84726 acc: 0.43356 ce: 1.52904 lat: -16.18815
[33mIP:10.60.242.134 [0m[32m[0229 14:21:20 @trainer.py:173][0m Change temperature from 3.99263 to 3.81696
[33mIP:10.60.242.134 [0m[32m[0229 14:21:23 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:21:23 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889]
[33mIP:10.60.242.134 [0m[32m[0229 14:21:23 @trainer.py:234][0m acc 0.4889
[33mIP:10.60.242.134 [0m[32m[0229 14:21:23 @trainer.py:235][0m max_acc 0.4984
[33mIP:10.60.242.134 [0m[32m[0229 14:21:23 @trainer.py:217][0m Start to train w for epoch 8
[33mIP:10.60.242.134 [0m[32m[0229 14:21:23 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:21:40 @trainer.py:198][0m Epoch[8] Batch[100] Speed: 278.347326 samples/sec loss: -30.85264 acc: 0.43576 ce: 1.52366 lat: -16.18815
[33mIP:10.60.242.134 [0m[32m[0229 14:21:55 @trainer.py:198][0m Epoch[8] Batch[200] Speed: 412.300868 samples/sec loss: -30.85688 acc: 0.43770 ce: 1.51943 lat: -16.18816
[33mIP:10.60.242.134 [0m[32m[0229 14:22:11 @trainer.py:198][0m Epoch[8] Batch[300] Speed: 406.292580 samples/sec loss: -30.86101 acc: 0.43947 ce: 1.51531 lat: -16.18816
[33mIP:10.60.242.134 [0m[32m[0229 14:22:26 @trainer.py:198][0m Epoch[8] Batch[400] Speed: 417.139976 samples/sec loss: -30.86539 acc: 0.44125 ce: 1.51093 lat: -16.18816
[33mIP:10.60.242.134 [0m[32m[0229 14:22:41 @trainer.py:198][0m Epoch[8] Batch[500] Speed: 419.496969 samples/sec loss: -30.86942 acc: 0.44289 ce: 1.50691 lat: -16.18816
[33mIP:10.60.242.134 [0m[32m[0229 14:22:56 @trainer.py:198][0m Epoch[8] Batch[600] Speed: 430.531383 samples/sec loss: -30.87357 acc: 0.44457 ce: 1.50276 lat: -16.18816
[33mIP:10.60.242.134 [0m[32m[0229 14:23:00 @trainer.py:173][0m Change temperature from 3.81696 to 3.64901
[33mIP:10.60.242.134 [0m[32m[0229 14:23:04 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:23:04 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301]
[33mIP:10.60.242.134 [0m[32m[0229 14:23:04 @trainer.py:234][0m acc 0.5301
[33mIP:10.60.242.134 [0m[32m[0229 14:23:04 @trainer.py:235][0m max_acc 0.5301
[33mIP:10.60.242.134 [0m[32m[0229 14:23:04 @trainer.py:217][0m Start to train w for epoch 9
[33mIP:10.60.242.134 [0m[32m[0229 14:23:04 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:23:19 @trainer.py:198][0m Epoch[9] Batch[100] Speed: 276.220223 samples/sec loss: -30.87925 acc: 0.44700 ce: 1.49708 lat: -16.18817
[33mIP:10.60.242.134 [0m[32m[0229 14:23:35 @trainer.py:198][0m Epoch[9] Batch[200] Speed: 411.364216 samples/sec loss: -30.88397 acc: 0.44895 ce: 1.49237 lat: -16.18817
[33mIP:10.60.242.134 [0m[32m[0229 14:23:50 @trainer.py:198][0m Epoch[9] Batch[300] Speed: 414.664038 samples/sec loss: -30.88818 acc: 0.45072 ce: 1.48816 lat: -16.18817
[33mIP:10.60.242.134 [0m[32m[0229 14:24:06 @trainer.py:198][0m Epoch[9] Batch[400] Speed: 418.787293 samples/sec loss: -30.89281 acc: 0.45258 ce: 1.48354 lat: -16.18817
[33mIP:10.60.242.134 [0m[32m[0229 14:24:21 @trainer.py:198][0m Epoch[9] Batch[500] Speed: 412.236759 samples/sec loss: -30.89702 acc: 0.45437 ce: 1.47933 lat: -16.18818
[33mIP:10.60.242.134 [0m[32m[0229 14:24:35 @trainer.py:198][0m Epoch[9] Batch[600] Speed: 463.821622 samples/sec loss: -30.90109 acc: 0.45610 ce: 1.47527 lat: -16.18818
[33mIP:10.60.242.134 [0m[32m[0229 14:24:38 @trainer.py:173][0m Change temperature from 3.64901 to 3.48846
[33mIP:10.60.242.134 [0m[32m[0229 14:24:42 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:24:42 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267]
[33mIP:10.60.242.134 [0m[32m[0229 14:24:42 @trainer.py:234][0m acc 0.5267
[33mIP:10.60.242.134 [0m[32m[0229 14:24:42 @trainer.py:235][0m max_acc 0.5301
[33mIP:10.60.242.134 [0m[32m[0229 14:24:42 @trainer.py:217][0m Start to train w for epoch 10
[33mIP:10.60.242.134 [0m[32m[0229 14:24:42 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:24:57 @trainer.py:198][0m Epoch[10] Batch[100] Speed: 298.092235 samples/sec loss: -30.90639 acc: 0.45837 ce: 1.46998 lat: -16.18818
[33mIP:10.60.242.134 [0m[32m[0229 14:25:11 @trainer.py:198][0m Epoch[10] Batch[200] Speed: 436.052914 samples/sec loss: -30.91097 acc: 0.46012 ce: 1.46540 lat: -16.18818
[33mIP:10.60.242.134 [0m[32m[0229 14:25:27 @trainer.py:198][0m Epoch[10] Batch[300] Speed: 401.934992 samples/sec loss: -30.91540 acc: 0.46203 ce: 1.46097 lat: -16.18818
[33mIP:10.60.242.134 [0m[32m[0229 14:25:43 @trainer.py:198][0m Epoch[10] Batch[400] Speed: 401.285109 samples/sec loss: -30.91988 acc: 0.46386 ce: 1.45650 lat: -16.18819
[33mIP:10.60.242.134 [0m[32m[0229 14:25:58 @trainer.py:198][0m Epoch[10] Batch[500] Speed: 418.548179 samples/sec loss: -30.92413 acc: 0.46551 ce: 1.45225 lat: -16.18819
[33mIP:10.60.242.134 [0m[32m[0229 14:26:14 @trainer.py:198][0m Epoch[10] Batch[600] Speed: 422.275534 samples/sec loss: -30.92830 acc: 0.46713 ce: 1.44808 lat: -16.18819
[33mIP:10.60.242.134 [0m[32m[0229 14:26:17 @trainer.py:173][0m Change temperature from 3.48846 to 3.33496
[33mIP:10.60.242.134 [0m[32m[0229 14:26:20 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:26:20 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648]
[33mIP:10.60.242.134 [0m[32m[0229 14:26:20 @trainer.py:234][0m acc 0.5648
[33mIP:10.60.242.134 [0m[32m[0229 14:26:20 @trainer.py:235][0m max_acc 0.5648
[33mIP:10.60.242.134 [0m[32m[0229 14:26:20 @trainer.py:217][0m Start to train w for epoch 11
[33mIP:10.60.242.134 [0m[32m[0229 14:26:20 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:26:37 @trainer.py:198][0m Epoch[11] Batch[100] Speed: 277.501955 samples/sec loss: -30.93403 acc: 0.46935 ce: 1.44236 lat: -16.18819
[33mIP:10.60.242.134 [0m[32m[0229 14:26:52 @trainer.py:198][0m Epoch[11] Batch[200] Speed: 408.827310 samples/sec loss: -30.93868 acc: 0.47115 ce: 1.43772 lat: -16.18820
[33mIP:10.60.242.134 [0m[32m[0229 14:27:08 @trainer.py:198][0m Epoch[11] Batch[300] Speed: 418.031204 samples/sec loss: -30.94332 acc: 0.47296 ce: 1.43307 lat: -16.18820
[33mIP:10.60.242.134 [0m[32m[0229 14:27:23 @trainer.py:198][0m Epoch[11] Batch[400] Speed: 408.273771 samples/sec loss: -30.94734 acc: 0.47458 ce: 1.42905 lat: -16.18820
[33mIP:10.60.242.134 [0m[32m[0229 14:27:38 @trainer.py:198][0m Epoch[11] Batch[500] Speed: 423.067505 samples/sec loss: -30.95169 acc: 0.47628 ce: 1.42472 lat: -16.18820
[33mIP:10.60.242.134 [0m[32m[0229 14:27:54 @trainer.py:198][0m Epoch[11] Batch[600] Speed: 421.585671 samples/sec loss: -30.95578 acc: 0.47791 ce: 1.42064 lat: -16.18821
[33mIP:10.60.242.134 [0m[32m[0229 14:27:57 @trainer.py:173][0m Change temperature from 3.33496 to 3.18822
[33mIP:10.60.242.134 [0m[32m[0229 14:28:01 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:28:01 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835]
[33mIP:10.60.242.134 [0m[32m[0229 14:28:01 @trainer.py:234][0m acc 0.5835
[33mIP:10.60.242.134 [0m[32m[0229 14:28:01 @trainer.py:235][0m max_acc 0.5835
[33mIP:10.60.242.134 [0m[32m[0229 14:28:01 @trainer.py:217][0m Start to train w for epoch 12
[33mIP:10.60.242.134 [0m[32m[0229 14:28:01 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:28:17 @trainer.py:198][0m Epoch[12] Batch[100] Speed: 275.826528 samples/sec loss: -30.96104 acc: 0.48004 ce: 1.41538 lat: -16.18821
[33mIP:10.60.242.134 [0m[32m[0229 14:28:32 @trainer.py:198][0m Epoch[12] Batch[200] Speed: 406.739899 samples/sec loss: -30.96514 acc: 0.48174 ce: 1.41128 lat: -16.18821
[33mIP:10.60.242.134 [0m[32m[0229 14:28:48 @trainer.py:198][0m Epoch[12] Batch[300] Speed: 424.808247 samples/sec loss: -30.96953 acc: 0.48349 ce: 1.40690 lat: -16.18822
[33mIP:10.60.242.134 [0m[32m[0229 14:29:03 @trainer.py:198][0m Epoch[12] Batch[400] Speed: 419.124151 samples/sec loss: -30.97383 acc: 0.48515 ce: 1.40260 lat: -16.18822
[33mIP:10.60.242.134 [0m[32m[0229 14:29:18 @trainer.py:198][0m Epoch[12] Batch[500] Speed: 436.074406 samples/sec loss: -30.97821 acc: 0.48692 ce: 1.39823 lat: -16.18822
[33mIP:10.60.242.134 [0m[32m[0229 14:29:32 @trainer.py:198][0m Epoch[12] Batch[600] Speed: 431.630212 samples/sec loss: -30.98191 acc: 0.48841 ce: 1.39453 lat: -16.18822
[33mIP:10.60.242.134 [0m[32m[0229 14:29:36 @trainer.py:173][0m Change temperature from 3.18822 to 3.04794
[33mIP:10.60.242.134 [0m[32m[0229 14:29:39 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:29:39 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788]
[33mIP:10.60.242.134 [0m[32m[0229 14:29:39 @trainer.py:234][0m acc 0.5788
[33mIP:10.60.242.134 [0m[32m[0229 14:29:39 @trainer.py:235][0m max_acc 0.5835
[33mIP:10.60.242.134 [0m[32m[0229 14:29:39 @trainer.py:217][0m Start to train w for epoch 13
[33mIP:10.60.242.134 [0m[32m[0229 14:29:39 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:29:54 @trainer.py:198][0m Epoch[13] Batch[100] Speed: 297.267542 samples/sec loss: -30.98690 acc: 0.49038 ce: 1.38956 lat: -16.18823
[33mIP:10.60.242.134 [0m[32m[0229 14:30:09 @trainer.py:198][0m Epoch[13] Batch[200] Speed: 414.797526 samples/sec loss: -30.99106 acc: 0.49204 ce: 1.38540 lat: -16.18823
[33mIP:10.60.242.134 [0m[32m[0229 14:30:24 @trainer.py:198][0m Epoch[13] Batch[300] Speed: 438.222711 samples/sec loss: -30.99482 acc: 0.49352 ce: 1.38164 lat: -16.18823
[33mIP:10.60.242.134 [0m[32m[0229 14:30:39 @trainer.py:198][0m Epoch[13] Batch[400] Speed: 415.929547 samples/sec loss: -30.99877 acc: 0.49513 ce: 1.37769 lat: -16.18823
[33mIP:10.60.242.134 [0m[32m[0229 14:30:54 @trainer.py:198][0m Epoch[13] Batch[500] Speed: 425.555628 samples/sec loss: -31.00275 acc: 0.49672 ce: 1.37372 lat: -16.18824
[33mIP:10.60.242.134 [0m[32m[0229 14:31:10 @trainer.py:198][0m Epoch[13] Batch[600] Speed: 419.183841 samples/sec loss: -31.00630 acc: 0.49812 ce: 1.37018 lat: -16.18824
[33mIP:10.60.242.134 [0m[32m[0229 14:31:13 @trainer.py:173][0m Change temperature from 3.04794 to 2.91383
[33mIP:10.60.242.134 [0m[32m[0229 14:31:17 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:31:17 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892]
[33mIP:10.60.242.134 [0m[32m[0229 14:31:17 @trainer.py:234][0m acc 0.5892
[33mIP:10.60.242.134 [0m[32m[0229 14:31:17 @trainer.py:235][0m max_acc 0.5892
[33mIP:10.60.242.134 [0m[32m[0229 14:31:17 @trainer.py:217][0m Start to train w for epoch 14
[33mIP:10.60.242.134 [0m[32m[0229 14:31:17 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:31:33 @trainer.py:198][0m Epoch[14] Batch[100] Speed: 277.031337 samples/sec loss: -31.01132 acc: 0.50013 ce: 1.36517 lat: -16.18824
[33mIP:10.60.242.134 [0m[32m[0229 14:31:48 @trainer.py:198][0m Epoch[14] Batch[200] Speed: 419.242304 samples/sec loss: -31.01493 acc: 0.50152 ce: 1.36156 lat: -16.18825
[33mIP:10.60.242.134 [0m[32m[0229 14:32:03 @trainer.py:198][0m Epoch[14] Batch[300] Speed: 419.466389 samples/sec loss: -31.01827 acc: 0.50282 ce: 1.35822 lat: -16.18825
[33mIP:10.60.242.134 [0m[32m[0229 14:32:18 @trainer.py:198][0m Epoch[14] Batch[400] Speed: 427.680320 samples/sec loss: -31.02182 acc: 0.50424 ce: 1.35467 lat: -16.18825
[33mIP:10.60.242.134 [0m[32m[0229 14:32:33 @trainer.py:198][0m Epoch[14] Batch[500] Speed: 422.052898 samples/sec loss: -31.02551 acc: 0.50567 ce: 1.35099 lat: -16.18825
[33mIP:10.60.242.134 [0m[32m[0229 14:32:49 @trainer.py:198][0m Epoch[14] Batch[600] Speed: 421.884197 samples/sec loss: -31.02873 acc: 0.50700 ce: 1.34777 lat: -16.18825
[33mIP:10.60.242.134 [0m[32m[0229 14:32:52 @trainer.py:173][0m Change temperature from 2.91383 to 2.78562
[33mIP:10.60.242.134 [0m[32m[0229 14:32:56 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:32:56 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586]
[33mIP:10.60.242.134 [0m[32m[0229 14:32:56 @trainer.py:234][0m acc 0.586
[33mIP:10.60.242.134 [0m[32m[0229 14:32:56 @trainer.py:235][0m max_acc 0.5892
[33mIP:10.60.242.134 [0m[32m[0229 14:32:56 @trainer.py:217][0m Start to train w for epoch 15
[33mIP:10.60.242.134 [0m[32m[0229 14:32:56 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:33:12 @trainer.py:198][0m Epoch[15] Batch[100] Speed: 278.229683 samples/sec loss: -31.03208 acc: 0.50836 ce: 1.34442 lat: -16.18825
[33mIP:10.60.242.134 [0m[32m[0229 14:33:27 @trainer.py:198][0m Epoch[15] Batch[200] Speed: 402.748531 samples/sec loss: -31.03410 acc: 0.50919 ce: 1.34241 lat: -16.18825
[33mIP:10.60.242.134 [0m[32m[0229 14:33:43 @trainer.py:198][0m Epoch[15] Batch[300] Speed: 402.671085 samples/sec loss: -31.03617 acc: 0.51013 ce: 1.34034 lat: -16.18826
[33mIP:10.60.242.134 [0m[32m[0229 14:33:59 @trainer.py:198][0m Epoch[15] Batch[400] Speed: 412.591242 samples/sec loss: -31.03823 acc: 0.51097 ce: 1.33829 lat: -16.18826
[33mIP:10.60.242.134 [0m[32m[0229 14:34:14 @trainer.py:198][0m Epoch[15] Batch[500] Speed: 422.778775 samples/sec loss: -31.04055 acc: 0.51188 ce: 1.33598 lat: -16.18826
[33mIP:10.60.242.134 [0m[32m[0229 14:34:29 @trainer.py:198][0m Epoch[15] Batch[600] Speed: 420.546135 samples/sec loss: -31.04250 acc: 0.51272 ce: 1.33404 lat: -16.18827
[33mIP:10.60.242.134 [0m[32m[0229 14:34:33 @trainer.py:173][0m Change temperature from 2.78562 to 2.66306
[33mIP:10.60.242.134 [0m[32m[0229 14:34:36 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:34:36 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662]
[33mIP:10.60.242.134 [0m[32m[0229 14:34:36 @trainer.py:234][0m acc 0.5662
[33mIP:10.60.242.134 [0m[32m[0229 14:34:36 @trainer.py:235][0m max_acc 0.5892
[33mIP:10.60.242.134 [0m[32m[0229 14:34:36 @trainer.py:217][0m Start to train w for epoch 16
[33mIP:10.60.242.134 [0m[32m[0229 14:34:36 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:34:53 @trainer.py:198][0m Epoch[16] Batch[100] Speed: 269.204773 samples/sec loss: -31.04501 acc: 0.51378 ce: 1.33154 lat: -16.18827
[33mIP:10.60.242.134 [0m[32m[0229 14:35:09 @trainer.py:198][0m Epoch[16] Batch[200] Speed: 410.084898 samples/sec loss: -31.04720 acc: 0.51468 ce: 1.32934 lat: -16.18827
[33mIP:10.60.242.134 [0m[32m[0229 14:35:24 @trainer.py:198][0m Epoch[16] Batch[300] Speed: 407.364443 samples/sec loss: -31.04947 acc: 0.51556 ce: 1.32708 lat: -16.18827
[33mIP:10.60.242.134 [0m[32m[0229 14:35:40 @trainer.py:198][0m Epoch[16] Batch[400] Speed: 413.334135 samples/sec loss: -31.05183 acc: 0.51645 ce: 1.32472 lat: -16.18828
[33mIP:10.60.242.134 [0m[32m[0229 14:35:55 @trainer.py:198][0m Epoch[16] Batch[500] Speed: 419.954720 samples/sec loss: -31.05400 acc: 0.51733 ce: 1.32255 lat: -16.18828
[33mIP:10.60.242.134 [0m[32m[0229 14:36:10 @trainer.py:198][0m Epoch[16] Batch[600] Speed: 425.190900 samples/sec loss: -31.05617 acc: 0.51818 ce: 1.32039 lat: -16.18828
[33mIP:10.60.242.134 [0m[32m[0229 14:36:14 @trainer.py:173][0m Change temperature from 2.66306 to 2.54588
[33mIP:10.60.242.134 [0m[32m[0229 14:36:18 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:36:18 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761]
[33mIP:10.60.242.134 [0m[32m[0229 14:36:18 @trainer.py:234][0m acc 0.5761
[33mIP:10.60.242.134 [0m[32m[0229 14:36:18 @trainer.py:235][0m max_acc 0.5892
[33mIP:10.60.242.134 [0m[32m[0229 14:36:18 @trainer.py:217][0m Start to train w for epoch 17
[33mIP:10.60.242.134 [0m[32m[0229 14:36:18 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:36:33 @trainer.py:198][0m Epoch[17] Batch[100] Speed: 274.023558 samples/sec loss: -31.05892 acc: 0.51927 ce: 1.31765 lat: -16.18829
[33mIP:10.60.242.134 [0m[32m[0229 14:36:48 @trainer.py:198][0m Epoch[17] Batch[200] Speed: 434.551755 samples/sec loss: -31.06117 acc: 0.52024 ce: 1.31541 lat: -16.18829
[33mIP:10.60.242.134 [0m[32m[0229 14:37:03 @trainer.py:198][0m Epoch[17] Batch[300] Speed: 440.678101 samples/sec loss: -31.06375 acc: 0.52127 ce: 1.31283 lat: -16.18829
[33mIP:10.60.242.134 [0m[32m[0229 14:37:18 @trainer.py:198][0m Epoch[17] Batch[400] Speed: 416.555186 samples/sec loss: -31.06582 acc: 0.52214 ce: 1.31077 lat: -16.18829
[33mIP:10.60.242.134 [0m[32m[0229 14:37:33 @trainer.py:198][0m Epoch[17] Batch[500] Speed: 426.199899 samples/sec loss: -31.06808 acc: 0.52306 ce: 1.30852 lat: -16.18830
[33mIP:10.60.242.134 [0m[32m[0229 14:37:49 @trainer.py:198][0m Epoch[17] Batch[600] Speed: 409.960342 samples/sec loss: -31.07022 acc: 0.52397 ce: 1.30638 lat: -16.18830
[33mIP:10.60.242.134 [0m[32m[0229 14:37:52 @trainer.py:173][0m Change temperature from 2.54588 to 2.43386
[33mIP:10.60.242.134 [0m[32m[0229 14:37:56 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:37:56 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975]
[33mIP:10.60.242.134 [0m[32m[0229 14:37:56 @trainer.py:234][0m acc 0.5975
[33mIP:10.60.242.134 [0m[32m[0229 14:37:56 @trainer.py:235][0m max_acc 0.5975
[33mIP:10.60.242.134 [0m[32m[0229 14:37:56 @trainer.py:217][0m Start to train w for epoch 18
[33mIP:10.60.242.134 [0m[32m[0229 14:37:56 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:38:13 @trainer.py:198][0m Epoch[18] Batch[100] Speed: 268.143314 samples/sec loss: -31.07313 acc: 0.52516 ce: 1.30348 lat: -16.18830
[33mIP:10.60.242.134 [0m[32m[0229 14:38:28 @trainer.py:198][0m Epoch[18] Batch[200] Speed: 422.635203 samples/sec loss: -31.07540 acc: 0.52606 ce: 1.30122 lat: -16.18831
[33mIP:10.60.242.134 [0m[32m[0229 14:38:42 @trainer.py:198][0m Epoch[18] Batch[300] Speed: 432.144816 samples/sec loss: -31.07765 acc: 0.52701 ce: 1.29898 lat: -16.18831
[33mIP:10.60.242.134 [0m[32m[0229 14:38:57 @trainer.py:198][0m Epoch[18] Batch[400] Speed: 426.697736 samples/sec loss: -31.07962 acc: 0.52782 ce: 1.29702 lat: -16.18832
[33mIP:10.60.242.134 [0m[32m[0229 14:39:12 @trainer.py:198][0m Epoch[18] Batch[500] Speed: 450.684277 samples/sec loss: -31.08189 acc: 0.52869 ce: 1.29475 lat: -16.18832
[33mIP:10.60.242.134 [0m[32m[0229 14:39:26 @trainer.py:198][0m Epoch[18] Batch[600] Speed: 444.143532 samples/sec loss: -31.08414 acc: 0.52966 ce: 1.29251 lat: -16.18832
[33mIP:10.60.242.134 [0m[32m[0229 14:39:30 @trainer.py:173][0m Change temperature from 2.43386 to 2.32677
[33mIP:10.60.242.134 [0m[32m[0229 14:39:33 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:39:33 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225]
[33mIP:10.60.242.134 [0m[32m[0229 14:39:33 @trainer.py:234][0m acc 0.6225
[33mIP:10.60.242.134 [0m[32m[0229 14:39:33 @trainer.py:235][0m max_acc 0.6225
[33mIP:10.60.242.134 [0m[32m[0229 14:39:33 @trainer.py:217][0m Start to train w for epoch 19
[33mIP:10.60.242.134 [0m[32m[0229 14:39:33 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:39:48 @trainer.py:198][0m Epoch[19] Batch[100] Speed: 286.235891 samples/sec loss: -31.08724 acc: 0.53087 ce: 1.28942 lat: -16.18833
[33mIP:10.60.242.134 [0m[32m[0229 14:40:03 @trainer.py:198][0m Epoch[19] Batch[200] Speed: 432.651716 samples/sec loss: -31.08950 acc: 0.53179 ce: 1.28716 lat: -16.18833
[33mIP:10.60.242.134 [0m[32m[0229 14:40:18 @trainer.py:198][0m Epoch[19] Batch[300] Speed: 441.195382 samples/sec loss: -31.09175 acc: 0.53268 ce: 1.28491 lat: -16.18833
[33mIP:10.60.242.134 [0m[32m[0229 14:40:32 @trainer.py:198][0m Epoch[19] Batch[400] Speed: 434.742795 samples/sec loss: -31.09404 acc: 0.53353 ce: 1.28263 lat: -16.18833
[33mIP:10.60.242.134 [0m[32m[0229 14:40:47 @trainer.py:198][0m Epoch[19] Batch[500] Speed: 455.429296 samples/sec loss: -31.09620 acc: 0.53440 ce: 1.28047 lat: -16.18834
[33mIP:10.60.242.134 [0m[32m[0229 14:41:02 @trainer.py:198][0m Epoch[19] Batch[600] Speed: 424.207936 samples/sec loss: -31.09846 acc: 0.53526 ce: 1.27822 lat: -16.18834
[33mIP:10.60.242.134 [0m[32m[0229 14:41:05 @trainer.py:173][0m Change temperature from 2.32677 to 2.22440
[33mIP:10.60.242.134 [0m[32m[0229 14:41:08 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:41:08 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617]
[33mIP:10.60.242.134 [0m[32m[0229 14:41:08 @trainer.py:234][0m acc 0.617
[33mIP:10.60.242.134 [0m[32m[0229 14:41:08 @trainer.py:235][0m max_acc 0.6225
[33mIP:10.60.242.134 [0m[32m[0229 14:41:08 @trainer.py:217][0m Start to train w for epoch 20
[33mIP:10.60.242.134 [0m[32m[0229 14:41:08 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:41:24 @trainer.py:198][0m Epoch[20] Batch[100] Speed: 280.852842 samples/sec loss: -31.10145 acc: 0.53644 ce: 1.27524 lat: -16.18834
[33mIP:10.60.242.134 [0m[32m[0229 14:41:40 @trainer.py:198][0m Epoch[20] Batch[200] Speed: 407.970248 samples/sec loss: -31.10377 acc: 0.53734 ce: 1.27292 lat: -16.18835
[33mIP:10.60.242.134 [0m[32m[0229 14:41:56 @trainer.py:198][0m Epoch[20] Batch[300] Speed: 413.921544 samples/sec loss: -31.10598 acc: 0.53820 ce: 1.27072 lat: -16.18835
[33mIP:10.60.242.134 [0m[32m[0229 14:42:11 @trainer.py:198][0m Epoch[20] Batch[400] Speed: 425.759589 samples/sec loss: -31.10829 acc: 0.53914 ce: 1.26842 lat: -16.18835
[33mIP:10.60.242.134 [0m[32m[0229 14:42:26 @trainer.py:198][0m Epoch[20] Batch[500] Speed: 419.695149 samples/sec loss: -31.11063 acc: 0.54006 ce: 1.26608 lat: -16.18836
[33mIP:10.60.242.134 [0m[32m[0229 14:42:41 @trainer.py:198][0m Epoch[20] Batch[600] Speed: 411.891138 samples/sec loss: -31.11268 acc: 0.54086 ce: 1.26404 lat: -16.18836
[33mIP:10.60.242.134 [0m[32m[0229 14:42:45 @trainer.py:173][0m Change temperature from 2.22440 to 2.12652
[33mIP:10.60.242.134 [0m[32m[0229 14:42:48 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:42:48 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389]
[33mIP:10.60.242.134 [0m[32m[0229 14:42:48 @trainer.py:234][0m acc 0.6389
[33mIP:10.60.242.134 [0m[32m[0229 14:42:48 @trainer.py:235][0m max_acc 0.6389
[33mIP:10.60.242.134 [0m[32m[0229 14:42:48 @trainer.py:217][0m Start to train w for epoch 21
[33mIP:10.60.242.134 [0m[32m[0229 14:42:48 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:43:04 @trainer.py:198][0m Epoch[21] Batch[100] Speed: 279.033581 samples/sec loss: -31.11564 acc: 0.54203 ce: 1.26109 lat: -16.18837
[33mIP:10.60.242.134 [0m[32m[0229 14:43:20 @trainer.py:198][0m Epoch[21] Batch[200] Speed: 402.862763 samples/sec loss: -31.11777 acc: 0.54285 ce: 1.25896 lat: -16.18837
[33mIP:10.60.242.134 [0m[32m[0229 14:43:36 @trainer.py:198][0m Epoch[21] Batch[300] Speed: 410.766833 samples/sec loss: -31.12015 acc: 0.54377 ce: 1.25659 lat: -16.18837
[33mIP:10.60.242.134 [0m[32m[0229 14:43:51 @trainer.py:198][0m Epoch[21] Batch[400] Speed: 421.509178 samples/sec loss: -31.12247 acc: 0.54467 ce: 1.25427 lat: -16.18837
[33mIP:10.60.242.134 [0m[32m[0229 14:44:06 @trainer.py:198][0m Epoch[21] Batch[500] Speed: 420.130705 samples/sec loss: -31.12482 acc: 0.54557 ce: 1.25194 lat: -16.18838
[33mIP:10.60.242.134 [0m[32m[0229 14:44:22 @trainer.py:198][0m Epoch[21] Batch[600] Speed: 411.900916 samples/sec loss: -31.12705 acc: 0.54647 ce: 1.24972 lat: -16.18838
[33mIP:10.60.242.134 [0m[32m[0229 14:44:25 @trainer.py:173][0m Change temperature from 2.12652 to 2.03296
[33mIP:10.60.242.134 [0m[32m[0229 14:44:29 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:44:29 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494]
[33mIP:10.60.242.134 [0m[32m[0229 14:44:29 @trainer.py:234][0m acc 0.6494
[33mIP:10.60.242.134 [0m[32m[0229 14:44:29 @trainer.py:235][0m max_acc 0.6494
[33mIP:10.60.242.134 [0m[32m[0229 14:44:29 @trainer.py:217][0m Start to train w for epoch 22
[33mIP:10.60.242.134 [0m[32m[0229 14:44:29 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:44:45 @trainer.py:198][0m Epoch[22] Batch[100] Speed: 279.648351 samples/sec loss: -31.13009 acc: 0.54766 ce: 1.24668 lat: -16.18838
[33mIP:10.60.242.134 [0m[32m[0229 14:45:00 @trainer.py:198][0m Epoch[22] Batch[200] Speed: 412.553577 samples/sec loss: -31.13246 acc: 0.54855 ce: 1.24432 lat: -16.18839
[33mIP:10.60.242.134 [0m[32m[0229 14:45:16 @trainer.py:198][0m Epoch[22] Batch[300] Speed: 408.517922 samples/sec loss: -31.13490 acc: 0.54952 ce: 1.24188 lat: -16.18839
[33mIP:10.60.242.134 [0m[32m[0229 14:45:31 @trainer.py:198][0m Epoch[22] Batch[400] Speed: 413.810932 samples/sec loss: -31.13698 acc: 0.55033 ce: 1.23980 lat: -16.18839
[33mIP:10.60.242.134 [0m[32m[0229 14:45:47 @trainer.py:198][0m Epoch[22] Batch[500] Speed: 411.128212 samples/sec loss: -31.13925 acc: 0.55122 ce: 1.23754 lat: -16.18840
[33mIP:10.60.242.134 [0m[32m[0229 14:46:02 @trainer.py:198][0m Epoch[22] Batch[600] Speed: 410.843306 samples/sec loss: -31.14140 acc: 0.55208 ce: 1.23540 lat: -16.18840
[33mIP:10.60.242.134 [0m[32m[0229 14:46:06 @trainer.py:173][0m Change temperature from 2.03296 to 1.94351
[33mIP:10.60.242.134 [0m[32m[0229 14:46:09 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:46:09 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441]
[33mIP:10.60.242.134 [0m[32m[0229 14:46:09 @trainer.py:234][0m acc 0.6441
[33mIP:10.60.242.134 [0m[32m[0229 14:46:09 @trainer.py:235][0m max_acc 0.6494
[33mIP:10.60.242.134 [0m[32m[0229 14:46:09 @trainer.py:217][0m Start to train w for epoch 23
[33mIP:10.60.242.134 [0m[32m[0229 14:46:09 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:46:26 @trainer.py:198][0m Epoch[23] Batch[100] Speed: 275.078345 samples/sec loss: -31.14439 acc: 0.55325 ce: 1.23242 lat: -16.18840
[33mIP:10.60.242.134 [0m[32m[0229 14:46:41 @trainer.py:198][0m Epoch[23] Batch[200] Speed: 410.244776 samples/sec loss: -31.14686 acc: 0.55419 ce: 1.22996 lat: -16.18841
[33mIP:10.60.242.134 [0m[32m[0229 14:46:57 @trainer.py:198][0m Epoch[23] Batch[300] Speed: 407.215105 samples/sec loss: -31.14908 acc: 0.55507 ce: 1.22774 lat: -16.18841
[33mIP:10.60.242.134 [0m[32m[0229 14:47:12 @trainer.py:198][0m Epoch[23] Batch[400] Speed: 418.849338 samples/sec loss: -31.15142 acc: 0.55598 ce: 1.22541 lat: -16.18842
[33mIP:10.60.242.134 [0m[32m[0229 14:47:28 @trainer.py:198][0m Epoch[23] Batch[500] Speed: 417.267818 samples/sec loss: -31.15347 acc: 0.55675 ce: 1.22337 lat: -16.18842
[33mIP:10.60.242.134 [0m[32m[0229 14:47:43 @trainer.py:198][0m Epoch[23] Batch[600] Speed: 422.058512 samples/sec loss: -31.15578 acc: 0.55767 ce: 1.22106 lat: -16.18842
[33mIP:10.60.242.134 [0m[32m[0229 14:47:46 @trainer.py:173][0m Change temperature from 1.94351 to 1.85799
[33mIP:10.60.242.134 [0m[32m[0229 14:47:50 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:47:50 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533]
[33mIP:10.60.242.134 [0m[32m[0229 14:47:50 @trainer.py:234][0m acc 0.6533
[33mIP:10.60.242.134 [0m[32m[0229 14:47:50 @trainer.py:235][0m max_acc 0.6533
[33mIP:10.60.242.134 [0m[32m[0229 14:47:50 @trainer.py:217][0m Start to train w for epoch 24
[33mIP:10.60.242.134 [0m[32m[0229 14:47:50 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:48:06 @trainer.py:198][0m Epoch[24] Batch[100] Speed: 278.983930 samples/sec loss: -31.15872 acc: 0.55878 ce: 1.21814 lat: -16.18843
[33mIP:10.60.242.134 [0m[32m[0229 14:48:21 @trainer.py:198][0m Epoch[24] Batch[200] Speed: 429.335966 samples/sec loss: -31.16082 acc: 0.55959 ce: 1.21604 lat: -16.18843
[33mIP:10.60.242.134 [0m[32m[0229 14:48:36 @trainer.py:198][0m Epoch[24] Batch[300] Speed: 427.261734 samples/sec loss: -31.16319 acc: 0.56049 ce: 1.21368 lat: -16.18843
[33mIP:10.60.242.134 [0m[32m[0229 14:48:51 @trainer.py:198][0m Epoch[24] Batch[400] Speed: 423.681307 samples/sec loss: -31.16551 acc: 0.56141 ce: 1.21136 lat: -16.18844
[33mIP:10.60.242.134 [0m[32m[0229 14:49:06 @trainer.py:198][0m Epoch[24] Batch[500] Speed: 419.107831 samples/sec loss: -31.16782 acc: 0.56227 ce: 1.20906 lat: -16.18844
[33mIP:10.60.242.134 [0m[32m[0229 14:49:21 @trainer.py:198][0m Epoch[24] Batch[600] Speed: 419.242167 samples/sec loss: -31.16998 acc: 0.56310 ce: 1.20690 lat: -16.18844
[33mIP:10.60.242.134 [0m[32m[0229 14:49:25 @trainer.py:173][0m Change temperature from 1.85799 to 1.77624
[33mIP:10.60.242.134 [0m[32m[0229 14:49:28 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:49:28 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646]
[33mIP:10.60.242.134 [0m[32m[0229 14:49:28 @trainer.py:234][0m acc 0.6646
[33mIP:10.60.242.134 [0m[32m[0229 14:49:28 @trainer.py:235][0m max_acc 0.6646
[33mIP:10.60.242.134 [0m[32m[0229 14:49:28 @trainer.py:217][0m Start to train w for epoch 25
[33mIP:10.60.242.134 [0m[32m[0229 14:49:28 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:49:43 @trainer.py:198][0m Epoch[25] Batch[100] Speed: 295.510894 samples/sec loss: -31.17280 acc: 0.56422 ce: 1.20410 lat: -16.18845
[33mIP:10.60.242.134 [0m[32m[0229 14:49:55 @trainer.py:198][0m Epoch[25] Batch[200] Speed: 538.234238 samples/sec loss: -31.17490 acc: 0.56499 ce: 1.20200 lat: -16.18845
[33mIP:10.60.242.134 [0m[32m[0229 14:50:10 @trainer.py:198][0m Epoch[25] Batch[300] Speed: 430.409853 samples/sec loss: -31.17707 acc: 0.56584 ce: 1.19983 lat: -16.18845
[33mIP:10.60.242.134 [0m[32m[0229 14:50:25 @trainer.py:198][0m Epoch[25] Batch[400] Speed: 406.735425 samples/sec loss: -31.17946 acc: 0.56671 ce: 1.19745 lat: -16.18845
[33mIP:10.60.242.134 [0m[32m[0229 14:50:41 @trainer.py:198][0m Epoch[25] Batch[500] Speed: 414.467085 samples/sec loss: -31.18165 acc: 0.56755 ce: 1.19526 lat: -16.18846
[33mIP:10.60.242.134 [0m[32m[0229 14:50:56 @trainer.py:198][0m Epoch[25] Batch[600] Speed: 410.741177 samples/sec loss: -31.18395 acc: 0.56840 ce: 1.19296 lat: -16.18846
[33mIP:10.60.242.134 [0m[32m[0229 14:51:00 @trainer.py:173][0m Change temperature from 1.77624 to 1.69808
[33mIP:10.60.242.134 [0m[32m[0229 14:51:03 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:51:03 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589]
[33mIP:10.60.242.134 [0m[32m[0229 14:51:03 @trainer.py:234][0m acc 0.6589
[33mIP:10.60.242.134 [0m[32m[0229 14:51:03 @trainer.py:235][0m max_acc 0.6646
[33mIP:10.60.242.134 [0m[32m[0229 14:51:03 @trainer.py:217][0m Start to train w for epoch 26
[33mIP:10.60.242.134 [0m[32m[0229 14:51:03 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:51:19 @trainer.py:198][0m Epoch[26] Batch[100] Speed: 285.391222 samples/sec loss: -31.18676 acc: 0.56947 ce: 1.19016 lat: -16.18846
[33mIP:10.60.242.134 [0m[32m[0229 14:51:34 @trainer.py:198][0m Epoch[26] Batch[200] Speed: 415.892403 samples/sec loss: -31.18897 acc: 0.57027 ce: 1.18796 lat: -16.18846
[33mIP:10.60.242.134 [0m[32m[0229 14:51:50 @trainer.py:198][0m Epoch[26] Batch[300] Speed: 411.798525 samples/sec loss: -31.19118 acc: 0.57109 ce: 1.18575 lat: -16.18847
[33mIP:10.60.242.134 [0m[32m[0229 14:52:05 @trainer.py:198][0m Epoch[26] Batch[400] Speed: 423.680063 samples/sec loss: -31.19329 acc: 0.57189 ce: 1.18365 lat: -16.18847
[33mIP:10.60.242.134 [0m[32m[0229 14:52:19 @trainer.py:198][0m Epoch[26] Batch[500] Speed: 465.787177 samples/sec loss: -31.19548 acc: 0.57266 ce: 1.18146 lat: -16.18847
[33mIP:10.60.242.134 [0m[32m[0229 14:52:33 @trainer.py:198][0m Epoch[26] Batch[600] Speed: 437.547506 samples/sec loss: -31.19774 acc: 0.57349 ce: 1.17921 lat: -16.18848
[33mIP:10.60.242.134 [0m[32m[0229 14:52:37 @trainer.py:173][0m Change temperature from 1.69808 to 1.62337
[33mIP:10.60.242.134 [0m[32m[0229 14:52:41 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:52:41 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685]
[33mIP:10.60.242.134 [0m[32m[0229 14:52:41 @trainer.py:234][0m acc 0.6685
[33mIP:10.60.242.134 [0m[32m[0229 14:52:41 @trainer.py:235][0m max_acc 0.6685
[33mIP:10.60.242.134 [0m[32m[0229 14:52:41 @trainer.py:217][0m Start to train w for epoch 27
[33mIP:10.60.242.134 [0m[32m[0229 14:52:41 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:52:56 @trainer.py:198][0m Epoch[27] Batch[100] Speed: 276.069407 samples/sec loss: -31.20046 acc: 0.57450 ce: 1.17649 lat: -16.18848
[33mIP:10.60.242.134 [0m[32m[0229 14:53:11 @trainer.py:198][0m Epoch[27] Batch[200] Speed: 440.996384 samples/sec loss: -31.20252 acc: 0.57525 ce: 1.17444 lat: -16.18848
[33mIP:10.60.242.134 [0m[32m[0229 14:53:27 @trainer.py:198][0m Epoch[27] Batch[300] Speed: 409.241551 samples/sec loss: -31.20458 acc: 0.57602 ce: 1.17239 lat: -16.18848
[33mIP:10.60.242.134 [0m[32m[0229 14:53:41 @trainer.py:198][0m Epoch[27] Batch[400] Speed: 431.440691 samples/sec loss: -31.20674 acc: 0.57683 ce: 1.17023 lat: -16.18849
[33mIP:10.60.242.134 [0m[32m[0229 14:53:57 @trainer.py:198][0m Epoch[27] Batch[500] Speed: 424.468771 samples/sec loss: -31.20887 acc: 0.57763 ce: 1.16810 lat: -16.18849
[33mIP:10.60.242.134 [0m[32m[0229 14:54:12 @trainer.py:198][0m Epoch[27] Batch[600] Speed: 427.174812 samples/sec loss: -31.21097 acc: 0.57838 ce: 1.16601 lat: -16.18849
[33mIP:10.60.242.134 [0m[32m[0229 14:54:15 @trainer.py:173][0m Change temperature from 1.62337 to 1.55194
[33mIP:10.60.242.134 [0m[32m[0229 14:54:19 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:54:19 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709]
[33mIP:10.60.242.134 [0m[32m[0229 14:54:19 @trainer.py:234][0m acc 0.6709
[33mIP:10.60.242.134 [0m[32m[0229 14:54:19 @trainer.py:235][0m max_acc 0.6709
[33mIP:10.60.242.134 [0m[32m[0229 14:54:19 @trainer.py:217][0m Start to train w for epoch 28
[33mIP:10.60.242.134 [0m[32m[0229 14:54:19 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:54:36 @trainer.py:198][0m Epoch[28] Batch[100] Speed: 264.093970 samples/sec loss: -31.21378 acc: 0.57943 ce: 1.16320 lat: -16.18849
[33mIP:10.60.242.134 [0m[32m[0229 14:54:51 @trainer.py:198][0m Epoch[28] Batch[200] Speed: 413.427383 samples/sec loss: -31.21591 acc: 0.58026 ce: 1.16108 lat: -16.18850
[33mIP:10.60.242.134 [0m[32m[0229 14:55:07 @trainer.py:198][0m Epoch[28] Batch[300] Speed: 416.597201 samples/sec loss: -31.21799 acc: 0.58102 ce: 1.15900 lat: -16.18850
[33mIP:10.60.242.134 [0m[32m[0229 14:55:22 @trainer.py:198][0m Epoch[28] Batch[400] Speed: 417.563863 samples/sec loss: -31.21995 acc: 0.58172 ce: 1.15705 lat: -16.18850
[33mIP:10.60.242.134 [0m[32m[0229 14:55:38 @trainer.py:198][0m Epoch[28] Batch[500] Speed: 400.573180 samples/sec loss: -31.22192 acc: 0.58250 ce: 1.15509 lat: -16.18850
[33mIP:10.60.242.134 [0m[32m[0229 14:55:53 @trainer.py:198][0m Epoch[28] Batch[600] Speed: 412.109671 samples/sec loss: -31.22390 acc: 0.58323 ce: 1.15311 lat: -16.18851
[33mIP:10.60.242.134 [0m[32m[0229 14:55:57 @trainer.py:173][0m Change temperature from 1.55194 to 1.48366
[33mIP:10.60.242.134 [0m[32m[0229 14:56:01 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:56:01 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681]
[33mIP:10.60.242.134 [0m[32m[0229 14:56:01 @trainer.py:234][0m acc 0.6681
[33mIP:10.60.242.134 [0m[32m[0229 14:56:01 @trainer.py:235][0m max_acc 0.6709
[33mIP:10.60.242.134 [0m[32m[0229 14:56:01 @trainer.py:217][0m Start to train w for epoch 29
[33mIP:10.60.242.134 [0m[32m[0229 14:56:01 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:56:17 @trainer.py:198][0m Epoch[29] Batch[100] Speed: 268.107534 samples/sec loss: -31.22637 acc: 0.58416 ce: 1.15065 lat: -16.18851
[33mIP:10.60.242.134 [0m[32m[0229 14:56:33 @trainer.py:198][0m Epoch[29] Batch[200] Speed: 398.041893 samples/sec loss: -31.22829 acc: 0.58488 ce: 1.14874 lat: -16.18851
[33mIP:10.60.242.134 [0m[32m[0229 14:56:49 @trainer.py:198][0m Epoch[29] Batch[300] Speed: 405.411505 samples/sec loss: -31.23022 acc: 0.58559 ce: 1.14680 lat: -16.18851
[33mIP:10.60.242.134 [0m[32m[0229 14:57:05 @trainer.py:198][0m Epoch[29] Batch[400] Speed: 405.106187 samples/sec loss: -31.23217 acc: 0.58631 ce: 1.14486 lat: -16.18852
[33mIP:10.60.242.134 [0m[32m[0229 14:57:21 @trainer.py:198][0m Epoch[29] Batch[500] Speed: 406.821822 samples/sec loss: -31.23403 acc: 0.58697 ce: 1.14300 lat: -16.18852
[33mIP:10.60.242.134 [0m[32m[0229 14:57:36 @trainer.py:198][0m Epoch[29] Batch[600] Speed: 413.733784 samples/sec loss: -31.23596 acc: 0.58769 ce: 1.14108 lat: -16.18852
[33mIP:10.60.242.134 [0m[32m[0229 14:57:40 @trainer.py:173][0m Change temperature from 1.48366 to 1.41837
[33mIP:10.60.242.134 [0m[32m[0229 14:57:43 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:57:43 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704]
[33mIP:10.60.242.134 [0m[32m[0229 14:57:43 @trainer.py:234][0m acc 0.6704
[33mIP:10.60.242.134 [0m[32m[0229 14:57:43 @trainer.py:235][0m max_acc 0.6709
[33mIP:10.60.242.134 [0m[32m[0229 14:57:43 @trainer.py:217][0m Start to train w for epoch 30
[33mIP:10.60.242.134 [0m[32m[0229 14:57:43 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:57:59 @trainer.py:198][0m Epoch[30] Batch[100] Speed: 276.412605 samples/sec loss: -31.23835 acc: 0.58856 ce: 1.13869 lat: -16.18852
[33mIP:10.60.242.134 [0m[32m[0229 14:58:15 @trainer.py:198][0m Epoch[30] Batch[200] Speed: 417.125689 samples/sec loss: -31.24024 acc: 0.58925 ce: 1.13681 lat: -16.18852
[33mIP:10.60.242.134 [0m[32m[0229 14:58:30 @trainer.py:198][0m Epoch[30] Batch[300] Speed: 419.454394 samples/sec loss: -31.24218 acc: 0.58998 ce: 1.13487 lat: -16.18853
[33mIP:10.60.242.134 [0m[32m[0229 14:58:45 @trainer.py:198][0m Epoch[30] Batch[400] Speed: 417.849428 samples/sec loss: -31.24387 acc: 0.59063 ce: 1.13318 lat: -16.18853
[33mIP:10.60.242.134 [0m[32m[0229 14:59:01 @trainer.py:198][0m Epoch[30] Batch[500] Speed: 403.124626 samples/sec loss: -31.24568 acc: 0.59130 ce: 1.13138 lat: -16.18853
[33mIP:10.60.242.134 [0m[32m[0229 14:59:16 @trainer.py:198][0m Epoch[30] Batch[600] Speed: 426.811518 samples/sec loss: -31.24744 acc: 0.59196 ce: 1.12962 lat: -16.18853
[33mIP:10.60.242.134 [0m[32m[0229 14:59:20 @trainer.py:173][0m Change temperature from 1.41837 to 1.35597
[33mIP:10.60.242.134 [0m[32m[0229 14:59:23 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 14:59:23 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586]
[33mIP:10.60.242.134 [0m[32m[0229 14:59:23 @trainer.py:234][0m acc 0.6586
[33mIP:10.60.242.134 [0m[32m[0229 14:59:23 @trainer.py:235][0m max_acc 0.6709
[33mIP:10.60.242.134 [0m[32m[0229 14:59:23 @trainer.py:217][0m Start to train w for epoch 31
[33mIP:10.60.242.134 [0m[32m[0229 14:59:23 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 14:59:38 @trainer.py:198][0m Epoch[31] Batch[100] Speed: 286.801299 samples/sec loss: -31.24923 acc: 0.59265 ce: 1.12784 lat: -16.18853
[33mIP:10.60.242.134 [0m[32m[0229 14:59:53 @trainer.py:198][0m Epoch[31] Batch[200] Speed: 440.454866 samples/sec loss: -31.25034 acc: 0.59309 ce: 1.12673 lat: -16.18854
[33mIP:10.60.242.134 [0m[32m[0229 15:00:08 @trainer.py:198][0m Epoch[31] Batch[300] Speed: 440.042420 samples/sec loss: -31.25141 acc: 0.59351 ce: 1.12566 lat: -16.18854
[33mIP:10.60.242.134 [0m[32m[0229 15:00:23 @trainer.py:198][0m Epoch[31] Batch[400] Speed: 420.457486 samples/sec loss: -31.25259 acc: 0.59396 ce: 1.12449 lat: -16.18854
[33mIP:10.60.242.134 [0m[32m[0229 15:00:39 @trainer.py:198][0m Epoch[31] Batch[500] Speed: 395.916697 samples/sec loss: -31.25349 acc: 0.59431 ce: 1.12359 lat: -16.18854
[33mIP:10.60.242.134 [0m[32m[0229 15:00:54 @trainer.py:198][0m Epoch[31] Batch[600] Speed: 425.523174 samples/sec loss: -31.25457 acc: 0.59475 ce: 1.12252 lat: -16.18854
[33mIP:10.60.242.134 [0m[32m[0229 15:00:58 @trainer.py:173][0m Change temperature from 1.35597 to 1.29630
[33mIP:10.60.242.134 [0m[32m[0229 15:01:02 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:01:02 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369]
[33mIP:10.60.242.134 [0m[32m[0229 15:01:02 @trainer.py:234][0m acc 0.6369
[33mIP:10.60.242.134 [0m[32m[0229 15:01:02 @trainer.py:235][0m max_acc 0.6709
[33mIP:10.60.242.134 [0m[32m[0229 15:01:02 @trainer.py:217][0m Start to train w for epoch 32
[33mIP:10.60.242.134 [0m[32m[0229 15:01:02 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:01:17 @trainer.py:198][0m Epoch[32] Batch[100] Speed: 278.024332 samples/sec loss: -31.25599 acc: 0.59529 ce: 1.12111 lat: -16.18855
[33mIP:10.60.242.134 [0m[32m[0229 15:01:32 @trainer.py:198][0m Epoch[32] Batch[200] Speed: 422.033861 samples/sec loss: -31.25711 acc: 0.59574 ce: 1.11999 lat: -16.18855
[33mIP:10.60.242.134 [0m[32m[0229 15:01:47 @trainer.py:198][0m Epoch[32] Batch[300] Speed: 425.842490 samples/sec loss: -31.25819 acc: 0.59618 ce: 1.11892 lat: -16.18855
[33mIP:10.60.242.134 [0m[32m[0229 15:02:02 @trainer.py:198][0m Epoch[32] Batch[400] Speed: 422.255892 samples/sec loss: -31.25922 acc: 0.59657 ce: 1.11790 lat: -16.18856
[33mIP:10.60.242.134 [0m[32m[0229 15:02:17 @trainer.py:198][0m Epoch[32] Batch[500] Speed: 423.586211 samples/sec loss: -31.26036 acc: 0.59700 ce: 1.11676 lat: -16.18856
[33mIP:10.60.242.134 [0m[32m[0229 15:02:33 @trainer.py:198][0m Epoch[32] Batch[600] Speed: 422.939916 samples/sec loss: -31.26142 acc: 0.59740 ce: 1.11570 lat: -16.18856
[33mIP:10.60.242.134 [0m[32m[0229 15:02:36 @trainer.py:173][0m Change temperature from 1.29630 to 1.23927
[33mIP:10.60.242.134 [0m[32m[0229 15:02:39 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:02:39 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706]
[33mIP:10.60.242.134 [0m[32m[0229 15:02:39 @trainer.py:234][0m acc 0.6706
[33mIP:10.60.242.134 [0m[32m[0229 15:02:39 @trainer.py:235][0m max_acc 0.6709
[33mIP:10.60.242.134 [0m[32m[0229 15:02:39 @trainer.py:217][0m Start to train w for epoch 33
[33mIP:10.60.242.134 [0m[32m[0229 15:02:39 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:02:55 @trainer.py:198][0m Epoch[33] Batch[100] Speed: 286.188758 samples/sec loss: -31.26300 acc: 0.59800 ce: 1.11413 lat: -16.18856
[33mIP:10.60.242.134 [0m[32m[0229 15:03:10 @trainer.py:198][0m Epoch[33] Batch[200] Speed: 420.800942 samples/sec loss: -31.26415 acc: 0.59846 ce: 1.11298 lat: -16.18857
[33mIP:10.60.242.134 [0m[32m[0229 15:03:25 @trainer.py:198][0m Epoch[33] Batch[300] Speed: 427.460499 samples/sec loss: -31.26518 acc: 0.59884 ce: 1.11195 lat: -16.18857
[33mIP:10.60.242.134 [0m[32m[0229 15:03:40 @trainer.py:198][0m Epoch[33] Batch[400] Speed: 418.758770 samples/sec loss: -31.26627 acc: 0.59930 ce: 1.11087 lat: -16.18857
[33mIP:10.60.242.134 [0m[32m[0229 15:03:56 @trainer.py:198][0m Epoch[33] Batch[500] Speed: 421.066824 samples/sec loss: -31.26730 acc: 0.59969 ce: 1.10985 lat: -16.18857
[33mIP:10.60.242.134 [0m[32m[0229 15:04:11 @trainer.py:198][0m Epoch[33] Batch[600] Speed: 411.569203 samples/sec loss: -31.26843 acc: 0.60016 ce: 1.10873 lat: -16.18858
[33mIP:10.60.242.134 [0m[32m[0229 15:04:15 @trainer.py:173][0m Change temperature from 1.23927 to 1.18474
[33mIP:10.60.242.134 [0m[32m[0229 15:04:18 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:04:18 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694]
[33mIP:10.60.242.134 [0m[32m[0229 15:04:18 @trainer.py:234][0m acc 0.6694
[33mIP:10.60.242.134 [0m[32m[0229 15:04:18 @trainer.py:235][0m max_acc 0.6709
[33mIP:10.60.242.134 [0m[32m[0229 15:04:18 @trainer.py:217][0m Start to train w for epoch 34
[33mIP:10.60.242.134 [0m[32m[0229 15:04:18 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:04:35 @trainer.py:198][0m Epoch[34] Batch[100] Speed: 268.300911 samples/sec loss: -31.26995 acc: 0.60074 ce: 1.10721 lat: -16.18858
[33mIP:10.60.242.134 [0m[32m[0229 15:04:50 @trainer.py:198][0m Epoch[34] Batch[200] Speed: 421.097452 samples/sec loss: -31.27109 acc: 0.60118 ce: 1.10607 lat: -16.18858
[33mIP:10.60.242.134 [0m[32m[0229 15:05:05 @trainer.py:198][0m Epoch[34] Batch[300] Speed: 440.025022 samples/sec loss: -31.27214 acc: 0.60160 ce: 1.10502 lat: -16.18858
[33mIP:10.60.242.134 [0m[32m[0229 15:05:19 @trainer.py:198][0m Epoch[34] Batch[400] Speed: 433.850029 samples/sec loss: -31.27324 acc: 0.60202 ce: 1.10394 lat: -16.18859
[33mIP:10.60.242.134 [0m[32m[0229 15:05:34 @trainer.py:198][0m Epoch[34] Batch[500] Speed: 451.083394 samples/sec loss: -31.27440 acc: 0.60246 ce: 1.10278 lat: -16.18859
[33mIP:10.60.242.134 [0m[32m[0229 15:05:49 @trainer.py:198][0m Epoch[34] Batch[600] Speed: 427.830832 samples/sec loss: -31.27546 acc: 0.60290 ce: 1.10172 lat: -16.18859
[33mIP:10.60.242.134 [0m[32m[0229 15:05:52 @trainer.py:173][0m Change temperature from 1.18474 to 1.13261
[33mIP:10.60.242.134 [0m[32m[0229 15:05:56 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:05:56 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772]
[33mIP:10.60.242.134 [0m[32m[0229 15:05:56 @trainer.py:234][0m acc 0.6772
[33mIP:10.60.242.134 [0m[32m[0229 15:05:56 @trainer.py:235][0m max_acc 0.6772
[33mIP:10.60.242.134 [0m[32m[0229 15:05:56 @trainer.py:217][0m Start to train w for epoch 35
[33mIP:10.60.242.134 [0m[32m[0229 15:05:56 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:06:12 @trainer.py:198][0m Epoch[35] Batch[100] Speed: 268.750313 samples/sec loss: -31.27699 acc: 0.60345 ce: 1.10021 lat: -16.18860
[33mIP:10.60.242.134 [0m[32m[0229 15:06:28 @trainer.py:198][0m Epoch[35] Batch[200] Speed: 400.834887 samples/sec loss: -31.27812 acc: 0.60390 ce: 1.09908 lat: -16.18860
[33mIP:10.60.242.134 [0m[32m[0229 15:06:44 @trainer.py:198][0m Epoch[35] Batch[300] Speed: 402.853561 samples/sec loss: -31.27929 acc: 0.60437 ce: 1.09792 lat: -16.18860
[33mIP:10.60.242.134 [0m[32m[0229 15:06:59 @trainer.py:198][0m Epoch[35] Batch[400] Speed: 423.039035 samples/sec loss: -31.28045 acc: 0.60478 ce: 1.09676 lat: -16.18861
[33mIP:10.60.242.134 [0m[32m[0229 15:07:15 @trainer.py:198][0m Epoch[35] Batch[500] Speed: 424.934705 samples/sec loss: -31.28163 acc: 0.60524 ce: 1.09559 lat: -16.18861
[33mIP:10.60.242.134 [0m[32m[0229 15:07:30 @trainer.py:198][0m Epoch[35] Batch[600] Speed: 421.064182 samples/sec loss: -31.28266 acc: 0.60564 ce: 1.09456 lat: -16.18861
[33mIP:10.60.242.134 [0m[32m[0229 15:07:33 @trainer.py:173][0m Change temperature from 1.13261 to 1.08278
[33mIP:10.60.242.134 [0m[32m[0229 15:07:38 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:07:38 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771]
[33mIP:10.60.242.134 [0m[32m[0229 15:07:38 @trainer.py:234][0m acc 0.6771
[33mIP:10.60.242.134 [0m[32m[0229 15:07:38 @trainer.py:235][0m max_acc 0.6772
[33mIP:10.60.242.134 [0m[32m[0229 15:07:38 @trainer.py:217][0m Start to train w for epoch 36
[33mIP:10.60.242.134 [0m[32m[0229 15:07:38 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:07:54 @trainer.py:198][0m Epoch[36] Batch[100] Speed: 263.875645 samples/sec loss: -31.28406 acc: 0.60618 ce: 1.09317 lat: -16.18862
[33mIP:10.60.242.134 [0m[32m[0229 15:08:10 @trainer.py:198][0m Epoch[36] Batch[200] Speed: 407.247558 samples/sec loss: -31.28525 acc: 0.60664 ce: 1.09199 lat: -16.18862
[33mIP:10.60.242.134 [0m[32m[0229 15:08:25 @trainer.py:198][0m Epoch[36] Batch[300] Speed: 405.535113 samples/sec loss: -31.28640 acc: 0.60709 ce: 1.09084 lat: -16.18862
[33mIP:10.60.242.134 [0m[32m[0229 15:08:41 @trainer.py:198][0m Epoch[36] Batch[400] Speed: 404.678143 samples/sec loss: -31.28756 acc: 0.60752 ce: 1.08969 lat: -16.18862
[33mIP:10.60.242.134 [0m[32m[0229 15:08:57 @trainer.py:198][0m Epoch[36] Batch[500] Speed: 413.694959 samples/sec loss: -31.28869 acc: 0.60797 ce: 1.08857 lat: -16.18863
[33mIP:10.60.242.134 [0m[32m[0229 15:09:12 @trainer.py:198][0m Epoch[36] Batch[600] Speed: 415.396498 samples/sec loss: -31.28976 acc: 0.60838 ce: 1.08751 lat: -16.18863
[33mIP:10.60.242.134 [0m[32m[0229 15:09:16 @trainer.py:173][0m Change temperature from 1.08278 to 1.03513
[33mIP:10.60.242.134 [0m[32m[0229 15:09:19 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:09:19 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953]
[33mIP:10.60.242.134 [0m[32m[0229 15:09:19 @trainer.py:234][0m acc 0.6953
[33mIP:10.60.242.134 [0m[32m[0229 15:09:19 @trainer.py:235][0m max_acc 0.6953
[33mIP:10.60.242.134 [0m[32m[0229 15:09:19 @trainer.py:217][0m Start to train w for epoch 37
[33mIP:10.60.242.134 [0m[32m[0229 15:09:19 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:09:34 @trainer.py:198][0m Epoch[37] Batch[100] Speed: 288.358626 samples/sec loss: -31.29123 acc: 0.60894 ce: 1.08604 lat: -16.18863
[33mIP:10.60.242.134 [0m[32m[0229 15:09:49 @trainer.py:198][0m Epoch[37] Batch[200] Speed: 425.874027 samples/sec loss: -31.29243 acc: 0.60942 ce: 1.08484 lat: -16.18864
[33mIP:10.60.242.134 [0m[32m[0229 15:10:04 @trainer.py:198][0m Epoch[37] Batch[300] Speed: 446.909593 samples/sec loss: -31.29356 acc: 0.60985 ce: 1.08372 lat: -16.18864
[33mIP:10.60.242.134 [0m[32m[0229 15:10:18 @trainer.py:198][0m Epoch[37] Batch[400] Speed: 448.541350 samples/sec loss: -31.29472 acc: 0.61028 ce: 1.08256 lat: -16.18864
[33mIP:10.60.242.134 [0m[32m[0229 15:10:33 @trainer.py:198][0m Epoch[37] Batch[500] Speed: 425.166400 samples/sec loss: -31.29586 acc: 0.61073 ce: 1.08143 lat: -16.18865
[33mIP:10.60.242.134 [0m[32m[0229 15:10:48 @trainer.py:198][0m Epoch[37] Batch[600] Speed: 434.371532 samples/sec loss: -31.29689 acc: 0.61109 ce: 1.08041 lat: -16.18865
[33mIP:10.60.242.134 [0m[32m[0229 15:10:51 @trainer.py:173][0m Change temperature from 1.03513 to 0.98959
[33mIP:10.60.242.134 [0m[32m[0229 15:10:55 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:10:55 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887]
[33mIP:10.60.242.134 [0m[32m[0229 15:10:55 @trainer.py:234][0m acc 0.6887
[33mIP:10.60.242.134 [0m[32m[0229 15:10:55 @trainer.py:235][0m max_acc 0.6953
[33mIP:10.60.242.134 [0m[32m[0229 15:10:55 @trainer.py:217][0m Start to train w for epoch 38
[33mIP:10.60.242.134 [0m[32m[0229 15:10:55 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:11:11 @trainer.py:198][0m Epoch[38] Batch[100] Speed: 277.293451 samples/sec loss: -31.29834 acc: 0.61165 ce: 1.07897 lat: -16.18865
[33mIP:10.60.242.134 [0m[32m[0229 15:11:27 @trainer.py:198][0m Epoch[38] Batch[200] Speed: 408.679312 samples/sec loss: -31.29951 acc: 0.61208 ce: 1.07780 lat: -16.18865
[33mIP:10.60.242.134 [0m[32m[0229 15:11:42 @trainer.py:198][0m Epoch[38] Batch[300] Speed: 424.145479 samples/sec loss: -31.30062 acc: 0.61249 ce: 1.07669 lat: -16.18866
[33mIP:10.60.242.134 [0m[32m[0229 15:11:57 @trainer.py:198][0m Epoch[38] Batch[400] Speed: 425.572826 samples/sec loss: -31.30168 acc: 0.61290 ce: 1.07565 lat: -16.18866
[33mIP:10.60.242.134 [0m[32m[0229 15:12:11 @trainer.py:198][0m Epoch[38] Batch[500] Speed: 440.865400 samples/sec loss: -31.30284 acc: 0.61334 ce: 1.07448 lat: -16.18866
[33mIP:10.60.242.134 [0m[32m[0229 15:12:26 @trainer.py:198][0m Epoch[38] Batch[600] Speed: 444.422911 samples/sec loss: -31.30397 acc: 0.61376 ce: 1.07336 lat: -16.18867
[33mIP:10.60.242.134 [0m[32m[0229 15:12:29 @trainer.py:173][0m Change temperature from 0.98959 to 0.94605
[33mIP:10.60.242.134 [0m[32m[0229 15:12:32 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:12:32 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963]
[33mIP:10.60.242.134 [0m[32m[0229 15:12:32 @trainer.py:234][0m acc 0.6963
[33mIP:10.60.242.134 [0m[32m[0229 15:12:32 @trainer.py:235][0m max_acc 0.6963
[33mIP:10.60.242.134 [0m[32m[0229 15:12:32 @trainer.py:217][0m Start to train w for epoch 39
[33mIP:10.60.242.134 [0m[32m[0229 15:12:32 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:12:48 @trainer.py:198][0m Epoch[39] Batch[100] Speed: 280.314322 samples/sec loss: -31.30555 acc: 0.61435 ce: 1.07179 lat: -16.18867
[33mIP:10.60.242.134 [0m[32m[0229 15:13:04 @trainer.py:198][0m Epoch[39] Batch[200] Speed: 413.745536 samples/sec loss: -31.30678 acc: 0.61482 ce: 1.07056 lat: -16.18867
[33mIP:10.60.242.134 [0m[32m[0229 15:13:19 @trainer.py:198][0m Epoch[39] Batch[300] Speed: 426.484717 samples/sec loss: -31.30788 acc: 0.61525 ce: 1.06947 lat: -16.18867
[33mIP:10.60.242.134 [0m[32m[0229 15:13:34 @trainer.py:198][0m Epoch[39] Batch[400] Speed: 422.431738 samples/sec loss: -31.30899 acc: 0.61566 ce: 1.06837 lat: -16.18868
[33mIP:10.60.242.134 [0m[32m[0229 15:13:49 @trainer.py:198][0m Epoch[39] Batch[500] Speed: 436.994692 samples/sec loss: -31.31015 acc: 0.61610 ce: 1.06722 lat: -16.18868
[33mIP:10.60.242.134 [0m[32m[0229 15:14:03 @trainer.py:198][0m Epoch[39] Batch[600] Speed: 445.313082 samples/sec loss: -31.31133 acc: 0.61654 ce: 1.06604 lat: -16.18868
[33mIP:10.60.242.134 [0m[32m[0229 15:14:06 @trainer.py:173][0m Change temperature from 0.94605 to 0.90442
[33mIP:10.60.242.134 [0m[32m[0229 15:14:10 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:14:10 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942]
[33mIP:10.60.242.134 [0m[32m[0229 15:14:10 @trainer.py:234][0m acc 0.6942
[33mIP:10.60.242.134 [0m[32m[0229 15:14:10 @trainer.py:235][0m max_acc 0.6963
[33mIP:10.60.242.134 [0m[32m[0229 15:14:10 @trainer.py:217][0m Start to train w for epoch 40
[33mIP:10.60.242.134 [0m[32m[0229 15:14:10 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:14:26 @trainer.py:198][0m Epoch[40] Batch[100] Speed: 272.799387 samples/sec loss: -31.31288 acc: 0.61713 ce: 1.06450 lat: -16.18869
[33mIP:10.60.242.134 [0m[32m[0229 15:14:41 @trainer.py:198][0m Epoch[40] Batch[200] Speed: 443.906716 samples/sec loss: -31.31404 acc: 0.61755 ce: 1.06334 lat: -16.18869
[33mIP:10.60.242.134 [0m[32m[0229 15:14:56 @trainer.py:198][0m Epoch[40] Batch[300] Speed: 412.492717 samples/sec loss: -31.31524 acc: 0.61800 ce: 1.06215 lat: -16.18869
[33mIP:10.60.242.134 [0m[32m[0229 15:15:11 @trainer.py:198][0m Epoch[40] Batch[400] Speed: 428.172758 samples/sec loss: -31.31649 acc: 0.61847 ce: 1.06091 lat: -16.18870
[33mIP:10.60.242.134 [0m[32m[0229 15:15:26 @trainer.py:198][0m Epoch[40] Batch[500] Speed: 428.123549 samples/sec loss: -31.31763 acc: 0.61891 ce: 1.05977 lat: -16.18870
[33mIP:10.60.242.134 [0m[32m[0229 15:15:41 @trainer.py:198][0m Epoch[40] Batch[600] Speed: 448.327234 samples/sec loss: -31.31879 acc: 0.61935 ce: 1.05862 lat: -16.18870
[33mIP:10.60.242.134 [0m[32m[0229 15:15:44 @trainer.py:173][0m Change temperature from 0.90442 to 0.86463
[33mIP:10.60.242.134 [0m[32m[0229 15:15:48 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:15:48 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867]
[33mIP:10.60.242.134 [0m[32m[0229 15:15:48 @trainer.py:234][0m acc 0.6867
[33mIP:10.60.242.134 [0m[32m[0229 15:15:48 @trainer.py:235][0m max_acc 0.6963
[33mIP:10.60.242.134 [0m[32m[0229 15:15:48 @trainer.py:217][0m Start to train w for epoch 41
[33mIP:10.60.242.134 [0m[32m[0229 15:15:48 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:16:04 @trainer.py:198][0m Epoch[41] Batch[100] Speed: 271.783068 samples/sec loss: -31.32032 acc: 0.61993 ce: 1.05709 lat: -16.18871
[33mIP:10.60.242.134 [0m[32m[0229 15:16:20 @trainer.py:198][0m Epoch[41] Batch[200] Speed: 410.811661 samples/sec loss: -31.32155 acc: 0.62039 ce: 1.05587 lat: -16.18871
[33mIP:10.60.242.134 [0m[32m[0229 15:16:35 @trainer.py:198][0m Epoch[41] Batch[300] Speed: 407.935802 samples/sec loss: -31.32277 acc: 0.62084 ce: 1.05465 lat: -16.18871
[33mIP:10.60.242.134 [0m[32m[0229 15:16:51 @trainer.py:198][0m Epoch[41] Batch[400] Speed: 417.929283 samples/sec loss: -31.32392 acc: 0.62128 ce: 1.05350 lat: -16.18871
[33mIP:10.60.242.134 [0m[32m[0229 15:17:06 @trainer.py:198][0m Epoch[41] Batch[500] Speed: 413.726699 samples/sec loss: -31.32510 acc: 0.62172 ce: 1.05232 lat: -16.18871
[33mIP:10.60.242.134 [0m[32m[0229 15:17:21 @trainer.py:198][0m Epoch[41] Batch[600] Speed: 422.434743 samples/sec loss: -31.32624 acc: 0.62213 ce: 1.05120 lat: -16.18872
[33mIP:10.60.242.134 [0m[32m[0229 15:17:25 @trainer.py:173][0m Change temperature from 0.86463 to 0.82658
[33mIP:10.60.242.134 [0m[32m[0229 15:17:29 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:17:29 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054]
[33mIP:10.60.242.134 [0m[32m[0229 15:17:29 @trainer.py:234][0m acc 0.7054
[33mIP:10.60.242.134 [0m[32m[0229 15:17:29 @trainer.py:235][0m max_acc 0.7054
[33mIP:10.60.242.134 [0m[32m[0229 15:17:29 @trainer.py:217][0m Start to train w for epoch 42
[33mIP:10.60.242.134 [0m[32m[0229 15:17:29 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:17:45 @trainer.py:198][0m Epoch[42] Batch[100] Speed: 270.031458 samples/sec loss: -31.32777 acc: 0.62270 ce: 1.04967 lat: -16.18872
[33mIP:10.60.242.134 [0m[32m[0229 15:18:01 @trainer.py:198][0m Epoch[42] Batch[200] Speed: 409.588075 samples/sec loss: -31.32906 acc: 0.62320 ce: 1.04838 lat: -16.18872
[33mIP:10.60.242.134 [0m[32m[0229 15:18:16 @trainer.py:198][0m Epoch[42] Batch[300] Speed: 406.542193 samples/sec loss: -31.33021 acc: 0.62362 ce: 1.04724 lat: -16.18873
[33mIP:10.60.242.134 [0m[32m[0229 15:18:32 @trainer.py:198][0m Epoch[42] Batch[400] Speed: 416.710401 samples/sec loss: -31.33130 acc: 0.62402 ce: 1.04616 lat: -16.18873
[33mIP:10.60.242.134 [0m[32m[0229 15:18:47 @trainer.py:198][0m Epoch[42] Batch[500] Speed: 434.264825 samples/sec loss: -31.33246 acc: 0.62448 ce: 1.04500 lat: -16.18873
[33mIP:10.60.242.134 [0m[32m[0229 15:19:02 @trainer.py:198][0m Epoch[42] Batch[600] Speed: 418.373125 samples/sec loss: -31.33359 acc: 0.62489 ce: 1.04387 lat: -16.18873
[33mIP:10.60.242.134 [0m[32m[0229 15:19:05 @trainer.py:173][0m Change temperature from 0.82658 to 0.79021
[33mIP:10.60.242.134 [0m[32m[0229 15:19:09 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:19:09 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105]
[33mIP:10.60.242.134 [0m[32m[0229 15:19:09 @trainer.py:234][0m acc 0.7105
[33mIP:10.60.242.134 [0m[32m[0229 15:19:09 @trainer.py:235][0m max_acc 0.7105
[33mIP:10.60.242.134 [0m[32m[0229 15:19:09 @trainer.py:217][0m Start to train w for epoch 43
[33mIP:10.60.242.134 [0m[32m[0229 15:19:09 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:19:25 @trainer.py:198][0m Epoch[43] Batch[100] Speed: 281.640917 samples/sec loss: -31.33510 acc: 0.62545 ce: 1.04238 lat: -16.18874
[33mIP:10.60.242.134 [0m[32m[0229 15:19:40 @trainer.py:198][0m Epoch[43] Batch[200] Speed: 421.582698 samples/sec loss: -31.33632 acc: 0.62593 ce: 1.04116 lat: -16.18874
[33mIP:10.60.242.134 [0m[32m[0229 15:19:55 @trainer.py:198][0m Epoch[43] Batch[300] Speed: 407.247236 samples/sec loss: -31.33755 acc: 0.62638 ce: 1.03993 lat: -16.18874
[33mIP:10.60.242.134 [0m[32m[0229 15:20:11 @trainer.py:198][0m Epoch[43] Batch[400] Speed: 414.778209 samples/sec loss: -31.33870 acc: 0.62683 ce: 1.03879 lat: -16.18874
[33mIP:10.60.242.134 [0m[32m[0229 15:20:27 @trainer.py:198][0m Epoch[43] Batch[500] Speed: 397.228034 samples/sec loss: -31.33985 acc: 0.62726 ce: 1.03764 lat: -16.18875
[33mIP:10.60.242.134 [0m[32m[0229 15:20:43 @trainer.py:198][0m Epoch[43] Batch[600] Speed: 388.316442 samples/sec loss: -31.34097 acc: 0.62771 ce: 1.03653 lat: -16.18875
[33mIP:10.60.242.134 [0m[32m[0229 15:20:47 @trainer.py:173][0m Change temperature from 0.79021 to 0.75544
[33mIP:10.60.242.134 [0m[32m[0229 15:20:51 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:20:51 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138]
[33mIP:10.60.242.134 [0m[32m[0229 15:20:51 @trainer.py:234][0m acc 0.7138
[33mIP:10.60.242.134 [0m[32m[0229 15:20:51 @trainer.py:235][0m max_acc 0.7138
[33mIP:10.60.242.134 [0m[32m[0229 15:20:51 @trainer.py:217][0m Start to train w for epoch 44
[33mIP:10.60.242.134 [0m[32m[0229 15:20:51 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:21:08 @trainer.py:198][0m Epoch[44] Batch[100] Speed: 265.331510 samples/sec loss: -31.34244 acc: 0.62827 ce: 1.03507 lat: -16.18875
[33mIP:10.60.242.134 [0m[32m[0229 15:21:23 @trainer.py:198][0m Epoch[44] Batch[200] Speed: 408.743215 samples/sec loss: -31.34376 acc: 0.62877 ce: 1.03375 lat: -16.18876
[33mIP:10.60.242.134 [0m[32m[0229 15:21:39 @trainer.py:198][0m Epoch[44] Batch[300] Speed: 395.875528 samples/sec loss: -31.34488 acc: 0.62919 ce: 1.03264 lat: -16.18876
[33mIP:10.60.242.134 [0m[32m[0229 15:21:55 @trainer.py:198][0m Epoch[44] Batch[400] Speed: 409.494408 samples/sec loss: -31.34607 acc: 0.62961 ce: 1.03145 lat: -16.18876
[33mIP:10.60.242.134 [0m[32m[0229 15:22:11 @trainer.py:198][0m Epoch[44] Batch[500] Speed: 404.920089 samples/sec loss: -31.34721 acc: 0.63006 ce: 1.03032 lat: -16.18876
[33mIP:10.60.242.134 [0m[32m[0229 15:22:27 @trainer.py:198][0m Epoch[44] Batch[600] Speed: 404.023665 samples/sec loss: -31.34838 acc: 0.63050 ce: 1.02915 lat: -16.18877
[33mIP:10.60.242.134 [0m[32m[0229 15:22:30 @trainer.py:173][0m Change temperature from 0.75544 to 0.72220
[33mIP:10.60.242.134 [0m[32m[0229 15:22:34 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:22:34 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257]
[33mIP:10.60.242.134 [0m[32m[0229 15:22:34 @trainer.py:234][0m acc 0.7257
[33mIP:10.60.242.134 [0m[32m[0229 15:22:34 @trainer.py:235][0m max_acc 0.7257
[33mIP:10.60.242.134 [0m[32m[0229 15:22:34 @trainer.py:217][0m Start to train w for epoch 45
[33mIP:10.60.242.134 [0m[32m[0229 15:22:34 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:22:51 @trainer.py:198][0m Epoch[45] Batch[100] Speed: 266.605553 samples/sec loss: -31.34987 acc: 0.63104 ce: 1.02767 lat: -16.18877
[33mIP:10.60.242.134 [0m[32m[0229 15:23:06 @trainer.py:198][0m Epoch[45] Batch[200] Speed: 407.566564 samples/sec loss: -31.35108 acc: 0.63150 ce: 1.02646 lat: -16.18877
[33mIP:10.60.242.134 [0m[32m[0229 15:23:22 @trainer.py:198][0m Epoch[45] Batch[300] Speed: 419.041058 samples/sec loss: -31.35226 acc: 0.63194 ce: 1.02529 lat: -16.18877
[33mIP:10.60.242.134 [0m[32m[0229 15:23:37 @trainer.py:198][0m Epoch[45] Batch[400] Speed: 405.602694 samples/sec loss: -31.35349 acc: 0.63240 ce: 1.02406 lat: -16.18878
[33mIP:10.60.242.134 [0m[32m[0229 15:23:53 @trainer.py:198][0m Epoch[45] Batch[500] Speed: 411.420865 samples/sec loss: -31.35471 acc: 0.63285 ce: 1.02285 lat: -16.18878
[33mIP:10.60.242.134 [0m[32m[0229 15:24:09 @trainer.py:198][0m Epoch[45] Batch[600] Speed: 401.696269 samples/sec loss: -31.35593 acc: 0.63330 ce: 1.02163 lat: -16.18878
[33mIP:10.60.242.134 [0m[32m[0229 15:24:13 @trainer.py:173][0m Change temperature from 0.72220 to 0.69043
[33mIP:10.60.242.134 [0m[32m[0229 15:24:17 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:24:17 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391]
[33mIP:10.60.242.134 [0m[32m[0229 15:24:17 @trainer.py:234][0m acc 0.7391
[33mIP:10.60.242.134 [0m[32m[0229 15:24:17 @trainer.py:235][0m max_acc 0.7391
[33mIP:10.60.242.134 [0m[32m[0229 15:24:17 @trainer.py:217][0m Start to train w for epoch 46
[33mIP:10.60.242.134 [0m[32m[0229 15:24:17 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:24:34 @trainer.py:198][0m Epoch[46] Batch[100] Speed: 259.323658 samples/sec loss: -31.35743 acc: 0.63387 ce: 1.02014 lat: -16.18878
[33mIP:10.60.242.134 [0m[32m[0229 15:24:50 @trainer.py:198][0m Epoch[46] Batch[200] Speed: 397.129124 samples/sec loss: -31.35866 acc: 0.63432 ce: 1.01891 lat: -16.18879
[33mIP:10.60.242.134 [0m[32m[0229 15:25:06 @trainer.py:198][0m Epoch[46] Batch[300] Speed: 391.399294 samples/sec loss: -31.35987 acc: 0.63477 ce: 1.01771 lat: -16.18879
[33mIP:10.60.242.134 [0m[32m[0229 15:25:22 @trainer.py:198][0m Epoch[46] Batch[400] Speed: 399.555980 samples/sec loss: -31.36096 acc: 0.63520 ce: 1.01662 lat: -16.18879
[33mIP:10.60.242.134 [0m[32m[0229 15:25:39 @trainer.py:198][0m Epoch[46] Batch[500] Speed: 382.034108 samples/sec loss: -31.36202 acc: 0.63559 ce: 1.01556 lat: -16.18879
[33mIP:10.60.242.134 [0m[32m[0229 15:25:55 @trainer.py:198][0m Epoch[46] Batch[600] Speed: 392.017121 samples/sec loss: -31.36315 acc: 0.63601 ce: 1.01444 lat: -16.18879
[33mIP:10.60.242.134 [0m[32m[0229 15:25:59 @trainer.py:173][0m Change temperature from 0.69043 to 0.66005
[33mIP:10.60.242.134 [0m[32m[0229 15:26:03 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:26:03 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733]
[33mIP:10.60.242.134 [0m[32m[0229 15:26:03 @trainer.py:234][0m acc 0.733
[33mIP:10.60.242.134 [0m[32m[0229 15:26:03 @trainer.py:235][0m max_acc 0.7391
[33mIP:10.60.242.134 [0m[32m[0229 15:26:03 @trainer.py:217][0m Start to train w for epoch 47
[33mIP:10.60.242.134 [0m[32m[0229 15:26:03 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:26:19 @trainer.py:198][0m Epoch[47] Batch[100] Speed: 272.659616 samples/sec loss: -31.36469 acc: 0.63658 ce: 1.01291 lat: -16.18880
[33mIP:10.60.242.134 [0m[32m[0229 15:26:34 @trainer.py:198][0m Epoch[47] Batch[200] Speed: 413.071449 samples/sec loss: -31.36591 acc: 0.63703 ce: 1.01169 lat: -16.18880
[33mIP:10.60.242.134 [0m[32m[0229 15:26:50 @trainer.py:198][0m Epoch[47] Batch[300] Speed: 396.494208 samples/sec loss: -31.36710 acc: 0.63747 ce: 1.01050 lat: -16.18880
[33mIP:10.60.242.134 [0m[32m[0229 15:27:06 @trainer.py:198][0m Epoch[47] Batch[400] Speed: 406.131466 samples/sec loss: -31.36827 acc: 0.63789 ce: 1.00934 lat: -16.18880
[33mIP:10.60.242.134 [0m[32m[0229 15:27:22 @trainer.py:198][0m Epoch[47] Batch[500] Speed: 404.477560 samples/sec loss: -31.36948 acc: 0.63834 ce: 1.00814 lat: -16.18881
[33mIP:10.60.242.134 [0m[32m[0229 15:27:37 @trainer.py:198][0m Epoch[47] Batch[600] Speed: 430.724142 samples/sec loss: -31.37063 acc: 0.63877 ce: 1.00699 lat: -16.18881
[33mIP:10.60.242.134 [0m[32m[0229 15:27:40 @trainer.py:173][0m Change temperature from 0.66005 to 0.63101
[33mIP:10.60.242.134 [0m[32m[0229 15:27:44 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:27:44 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309]
[33mIP:10.60.242.134 [0m[32m[0229 15:27:44 @trainer.py:234][0m acc 0.7309
[33mIP:10.60.242.134 [0m[32m[0229 15:27:44 @trainer.py:235][0m max_acc 0.7391
[33mIP:10.60.242.134 [0m[32m[0229 15:27:44 @trainer.py:217][0m Start to train w for epoch 48
[33mIP:10.60.242.134 [0m[32m[0229 15:27:44 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:28:00 @trainer.py:198][0m Epoch[48] Batch[100] Speed: 278.214596 samples/sec loss: -31.37215 acc: 0.63934 ce: 1.00547 lat: -16.18881
[33mIP:10.60.242.134 [0m[32m[0229 15:28:16 @trainer.py:198][0m Epoch[48] Batch[200] Speed: 399.166596 samples/sec loss: -31.37331 acc: 0.63978 ce: 1.00431 lat: -16.18881
[33mIP:10.60.242.134 [0m[32m[0229 15:28:31 @trainer.py:198][0m Epoch[48] Batch[300] Speed: 409.938035 samples/sec loss: -31.37450 acc: 0.64021 ce: 1.00313 lat: -16.18882
[33mIP:10.60.242.134 [0m[32m[0229 15:28:47 @trainer.py:198][0m Epoch[48] Batch[400] Speed: 422.900770 samples/sec loss: -31.37572 acc: 0.64066 ce: 1.00192 lat: -16.18882
[33mIP:10.60.242.134 [0m[32m[0229 15:29:02 @trainer.py:198][0m Epoch[48] Batch[500] Speed: 417.921182 samples/sec loss: -31.37692 acc: 0.64108 ce: 1.00072 lat: -16.18882
[33mIP:10.60.242.134 [0m[32m[0229 15:29:17 @trainer.py:198][0m Epoch[48] Batch[600] Speed: 426.489094 samples/sec loss: -31.37813 acc: 0.64153 ce: 0.99951 lat: -16.18882
[33mIP:10.60.242.134 [0m[32m[0229 15:29:20 @trainer.py:173][0m Change temperature from 0.63101 to 0.60324
[33mIP:10.60.242.134 [0m[32m[0229 15:29:24 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:29:24 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371]
[33mIP:10.60.242.134 [0m[32m[0229 15:29:24 @trainer.py:234][0m acc 0.7371
[33mIP:10.60.242.134 [0m[32m[0229 15:29:24 @trainer.py:235][0m max_acc 0.7391
[33mIP:10.60.242.134 [0m[32m[0229 15:29:24 @trainer.py:217][0m Start to train w for epoch 49
[33mIP:10.60.242.134 [0m[32m[0229 15:29:24 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:29:39 @trainer.py:198][0m Epoch[49] Batch[100] Speed: 283.861636 samples/sec loss: -31.37967 acc: 0.64209 ce: 0.99798 lat: -16.18882
[33mIP:10.60.242.134 [0m[32m[0229 15:29:54 @trainer.py:198][0m Epoch[49] Batch[200] Speed: 435.002842 samples/sec loss: -31.38088 acc: 0.64252 ce: 0.99678 lat: -16.18883
[33mIP:10.60.242.134 [0m[32m[0229 15:30:09 @trainer.py:198][0m Epoch[49] Batch[300] Speed: 431.905560 samples/sec loss: -31.38207 acc: 0.64296 ce: 0.99559 lat: -16.18883
[33mIP:10.60.242.134 [0m[32m[0229 15:30:24 @trainer.py:198][0m Epoch[49] Batch[400] Speed: 418.034023 samples/sec loss: -31.38325 acc: 0.64339 ce: 0.99441 lat: -16.18883
[33mIP:10.60.242.134 [0m[32m[0229 15:30:40 @trainer.py:198][0m Epoch[49] Batch[500] Speed: 408.132750 samples/sec loss: -31.38450 acc: 0.64384 ce: 0.99317 lat: -16.18883
[33mIP:10.60.242.134 [0m[32m[0229 15:30:55 @trainer.py:198][0m Epoch[49] Batch[600] Speed: 412.365078 samples/sec loss: -31.38558 acc: 0.64422 ce: 0.99209 lat: -16.18883
[33mIP:10.60.242.134 [0m[32m[0229 15:30:59 @trainer.py:173][0m Change temperature from 0.60324 to 0.57670
[33mIP:10.60.242.134 [0m[32m[0229 15:31:02 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:31:02 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337]
[33mIP:10.60.242.134 [0m[32m[0229 15:31:02 @trainer.py:234][0m acc 0.7337
[33mIP:10.60.242.134 [0m[32m[0229 15:31:02 @trainer.py:235][0m max_acc 0.7391
[33mIP:10.60.242.134 [0m[32m[0229 15:31:02 @trainer.py:217][0m Start to train w for epoch 50
[33mIP:10.60.242.134 [0m[32m[0229 15:31:02 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:31:19 @trainer.py:198][0m Epoch[50] Batch[100] Speed: 277.747192 samples/sec loss: -31.38706 acc: 0.64477 ce: 0.99062 lat: -16.18884
[33mIP:10.60.242.134 [0m[32m[0229 15:31:34 @trainer.py:198][0m Epoch[50] Batch[200] Speed: 418.409363 samples/sec loss: -31.38831 acc: 0.64524 ce: 0.98936 lat: -16.18884
[33mIP:10.60.242.134 [0m[32m[0229 15:31:49 @trainer.py:198][0m Epoch[50] Batch[300] Speed: 412.211514 samples/sec loss: -31.38949 acc: 0.64567 ce: 0.98819 lat: -16.18884
[33mIP:10.60.242.134 [0m[32m[0229 15:32:04 @trainer.py:198][0m Epoch[50] Batch[400] Speed: 428.455350 samples/sec loss: -31.39066 acc: 0.64608 ce: 0.98702 lat: -16.18884
[33mIP:10.60.242.134 [0m[32m[0229 15:32:20 @trainer.py:198][0m Epoch[50] Batch[500] Speed: 416.982161 samples/sec loss: -31.39174 acc: 0.64647 ce: 0.98595 lat: -16.18884
[33mIP:10.60.242.134 [0m[32m[0229 15:32:35 @trainer.py:198][0m Epoch[50] Batch[600] Speed: 406.627381 samples/sec loss: -31.39294 acc: 0.64691 ce: 0.98475 lat: -16.18885
[33mIP:10.60.242.134 [0m[32m[0229 15:32:39 @trainer.py:173][0m Change temperature from 0.57670 to 0.55132
[33mIP:10.60.242.134 [0m[32m[0229 15:32:42 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:32:42 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327]
[33mIP:10.60.242.134 [0m[32m[0229 15:32:42 @trainer.py:234][0m acc 0.7327
[33mIP:10.60.242.134 [0m[32m[0229 15:32:42 @trainer.py:235][0m max_acc 0.7391
[33mIP:10.60.242.134 [0m[32m[0229 15:32:42 @trainer.py:217][0m Start to train w for epoch 51
[33mIP:10.60.242.134 [0m[32m[0229 15:32:42 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:32:58 @trainer.py:198][0m Epoch[51] Batch[100] Speed: 278.853278 samples/sec loss: -31.39437 acc: 0.64742 ce: 0.98333 lat: -16.18885
[33mIP:10.60.242.134 [0m[32m[0229 15:33:14 @trainer.py:198][0m Epoch[51] Batch[200] Speed: 411.321700 samples/sec loss: -31.39549 acc: 0.64782 ce: 0.98221 lat: -16.18885
[33mIP:10.60.242.134 [0m[32m[0229 15:33:29 @trainer.py:198][0m Epoch[51] Batch[300] Speed: 419.980949 samples/sec loss: -31.39666 acc: 0.64825 ce: 0.98104 lat: -16.18885
[33mIP:10.60.242.134 [0m[32m[0229 15:33:44 @trainer.py:198][0m Epoch[51] Batch[400] Speed: 426.915021 samples/sec loss: -31.39784 acc: 0.64866 ce: 0.97987 lat: -16.18886
[33mIP:10.60.242.134 [0m[32m[0229 15:34:00 @trainer.py:198][0m Epoch[51] Batch[500] Speed: 412.611746 samples/sec loss: -31.39896 acc: 0.64908 ce: 0.97875 lat: -16.18886
[33mIP:10.60.242.134 [0m[32m[0229 15:34:15 @trainer.py:198][0m Epoch[51] Batch[600] Speed: 426.411652 samples/sec loss: -31.40016 acc: 0.64952 ce: 0.97756 lat: -16.18886
[33mIP:10.60.242.134 [0m[32m[0229 15:34:18 @trainer.py:173][0m Change temperature from 0.55132 to 0.52707
[33mIP:10.60.242.134 [0m[32m[0229 15:34:22 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:34:22 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473]
[33mIP:10.60.242.134 [0m[32m[0229 15:34:22 @trainer.py:234][0m acc 0.7473
[33mIP:10.60.242.134 [0m[32m[0229 15:34:22 @trainer.py:235][0m max_acc 0.7473
[33mIP:10.60.242.134 [0m[32m[0229 15:34:22 @trainer.py:217][0m Start to train w for epoch 52
[33mIP:10.60.242.134 [0m[32m[0229 15:34:22 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:34:38 @trainer.py:198][0m Epoch[52] Batch[100] Speed: 269.719033 samples/sec loss: -31.40160 acc: 0.65005 ce: 0.97612 lat: -16.18886
[33mIP:10.60.242.134 [0m[32m[0229 15:34:54 @trainer.py:198][0m Epoch[52] Batch[200] Speed: 412.702022 samples/sec loss: -31.40283 acc: 0.65049 ce: 0.97490 lat: -16.18886
[33mIP:10.60.242.134 [0m[32m[0229 15:35:09 @trainer.py:198][0m Epoch[52] Batch[300] Speed: 415.940793 samples/sec loss: -31.40403 acc: 0.65094 ce: 0.97370 lat: -16.18887
[33mIP:10.60.242.134 [0m[32m[0229 15:35:25 @trainer.py:198][0m Epoch[52] Batch[400] Speed: 415.126749 samples/sec loss: -31.40514 acc: 0.65136 ce: 0.97259 lat: -16.18887
[33mIP:10.60.242.134 [0m[32m[0229 15:35:40 @trainer.py:198][0m Epoch[52] Batch[500] Speed: 429.045093 samples/sec loss: -31.40626 acc: 0.65176 ce: 0.97148 lat: -16.18887
[33mIP:10.60.242.134 [0m[32m[0229 15:35:54 @trainer.py:198][0m Epoch[52] Batch[600] Speed: 438.119167 samples/sec loss: -31.40737 acc: 0.65218 ce: 0.97037 lat: -16.18887
[33mIP:10.60.242.134 [0m[32m[0229 15:35:58 @trainer.py:173][0m Change temperature from 0.52707 to 0.50387
[33mIP:10.60.242.134 [0m[32m[0229 15:36:01 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:36:01 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418]
[33mIP:10.60.242.134 [0m[32m[0229 15:36:01 @trainer.py:234][0m acc 0.7418
[33mIP:10.60.242.134 [0m[32m[0229 15:36:01 @trainer.py:235][0m max_acc 0.7473
[33mIP:10.60.242.134 [0m[32m[0229 15:36:01 @trainer.py:217][0m Start to train w for epoch 53
[33mIP:10.60.242.134 [0m[32m[0229 15:36:01 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:36:16 @trainer.py:198][0m Epoch[53] Batch[100] Speed: 293.287792 samples/sec loss: -31.40883 acc: 0.65270 ce: 0.96891 lat: -16.18887
[33mIP:10.60.242.134 [0m[32m[0229 15:36:31 @trainer.py:198][0m Epoch[53] Batch[200] Speed: 425.334259 samples/sec loss: -31.40998 acc: 0.65312 ce: 0.96777 lat: -16.18888
[33mIP:10.60.242.134 [0m[32m[0229 15:36:46 @trainer.py:198][0m Epoch[53] Batch[300] Speed: 419.081691 samples/sec loss: -31.41112 acc: 0.65353 ce: 0.96663 lat: -16.18888
[33mIP:10.60.242.134 [0m[32m[0229 15:37:02 @trainer.py:198][0m Epoch[53] Batch[400] Speed: 422.049242 samples/sec loss: -31.41231 acc: 0.65397 ce: 0.96545 lat: -16.18888
[33mIP:10.60.242.134 [0m[32m[0229 15:37:17 @trainer.py:198][0m Epoch[53] Batch[500] Speed: 403.370445 samples/sec loss: -31.41343 acc: 0.65438 ce: 0.96433 lat: -16.18888
[33mIP:10.60.242.134 [0m[32m[0229 15:37:33 @trainer.py:198][0m Epoch[53] Batch[600] Speed: 398.489633 samples/sec loss: -31.41459 acc: 0.65479 ce: 0.96317 lat: -16.18888
[33mIP:10.60.242.134 [0m[32m[0229 15:37:37 @trainer.py:173][0m Change temperature from 0.50387 to 0.48170
[33mIP:10.60.242.134 [0m[32m[0229 15:37:40 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:37:40 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427]
[33mIP:10.60.242.134 [0m[32m[0229 15:37:40 @trainer.py:234][0m acc 0.7427
[33mIP:10.60.242.134 [0m[32m[0229 15:37:40 @trainer.py:235][0m max_acc 0.7473
[33mIP:10.60.242.134 [0m[32m[0229 15:37:40 @trainer.py:217][0m Start to train w for epoch 54
[33mIP:10.60.242.134 [0m[32m[0229 15:37:40 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:37:56 @trainer.py:198][0m Epoch[54] Batch[100] Speed: 279.813338 samples/sec loss: -31.41599 acc: 0.65531 ce: 0.96178 lat: -16.18888
[33mIP:10.60.242.134 [0m[32m[0229 15:38:11 @trainer.py:198][0m Epoch[54] Batch[200] Speed: 421.629719 samples/sec loss: -31.41709 acc: 0.65572 ce: 0.96068 lat: -16.18889
[33mIP:10.60.242.134 [0m[32m[0229 15:38:26 @trainer.py:198][0m Epoch[54] Batch[300] Speed: 431.874666 samples/sec loss: -31.41825 acc: 0.65615 ce: 0.95953 lat: -16.18889
[33mIP:10.60.242.134 [0m[32m[0229 15:38:41 @trainer.py:198][0m Epoch[54] Batch[400] Speed: 427.386412 samples/sec loss: -31.41937 acc: 0.65657 ce: 0.95841 lat: -16.18889
[33mIP:10.60.242.134 [0m[32m[0229 15:38:56 @trainer.py:198][0m Epoch[54] Batch[500] Speed: 426.580570 samples/sec loss: -31.42046 acc: 0.65697 ce: 0.95732 lat: -16.18889
[33mIP:10.60.242.134 [0m[32m[0229 15:39:11 @trainer.py:198][0m Epoch[54] Batch[600] Speed: 421.005401 samples/sec loss: -31.42158 acc: 0.65737 ce: 0.95620 lat: -16.18889
[33mIP:10.60.242.134 [0m[32m[0229 15:39:15 @trainer.py:173][0m Change temperature from 0.48170 to 0.46051
[33mIP:10.60.242.134 [0m[32m[0229 15:39:19 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:39:19 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448]
[33mIP:10.60.242.134 [0m[32m[0229 15:39:19 @trainer.py:234][0m acc 0.7448
[33mIP:10.60.242.134 [0m[32m[0229 15:39:19 @trainer.py:235][0m max_acc 0.7473
[33mIP:10.60.242.134 [0m[32m[0229 15:39:19 @trainer.py:217][0m Start to train w for epoch 55
[33mIP:10.60.242.134 [0m[32m[0229 15:39:19 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:39:35 @trainer.py:198][0m Epoch[55] Batch[100] Speed: 272.056975 samples/sec loss: -31.42307 acc: 0.65790 ce: 0.95472 lat: -16.18889
[33mIP:10.60.242.134 [0m[32m[0229 15:39:50 @trainer.py:198][0m Epoch[55] Batch[200] Speed: 418.365738 samples/sec loss: -31.42424 acc: 0.65833 ce: 0.95355 lat: -16.18889
[33mIP:10.60.242.134 [0m[32m[0229 15:40:05 @trainer.py:198][0m Epoch[55] Batch[300] Speed: 423.529871 samples/sec loss: -31.42535 acc: 0.65874 ce: 0.95245 lat: -16.18890
[33mIP:10.60.242.134 [0m[32m[0229 15:40:21 @trainer.py:198][0m Epoch[55] Batch[400] Speed: 418.855031 samples/sec loss: -31.42643 acc: 0.65914 ce: 0.95136 lat: -16.18890
[33mIP:10.60.242.134 [0m[32m[0229 15:40:36 @trainer.py:198][0m Epoch[55] Batch[500] Speed: 415.342495 samples/sec loss: -31.42753 acc: 0.65955 ce: 0.95027 lat: -16.18890
[33mIP:10.60.242.134 [0m[32m[0229 15:40:52 @trainer.py:198][0m Epoch[55] Batch[600] Speed: 408.678136 samples/sec loss: -31.42862 acc: 0.65994 ce: 0.94918 lat: -16.18890
[33mIP:10.60.242.134 [0m[32m[0229 15:40:55 @trainer.py:173][0m Change temperature from 0.46051 to 0.44025
[33mIP:10.60.242.134 [0m[32m[0229 15:41:00 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:41:00 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469]
[33mIP:10.60.242.134 [0m[32m[0229 15:41:00 @trainer.py:234][0m acc 0.7469
[33mIP:10.60.242.134 [0m[32m[0229 15:41:00 @trainer.py:235][0m max_acc 0.7473
[33mIP:10.60.242.134 [0m[32m[0229 15:41:00 @trainer.py:217][0m Start to train w for epoch 56
[33mIP:10.60.242.134 [0m[32m[0229 15:41:00 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:41:16 @trainer.py:198][0m Epoch[56] Batch[100] Speed: 267.817379 samples/sec loss: -31.42998 acc: 0.66043 ce: 0.94782 lat: -16.18890
[33mIP:10.60.242.134 [0m[32m[0229 15:41:31 @trainer.py:198][0m Epoch[56] Batch[200] Speed: 415.854029 samples/sec loss: -31.43111 acc: 0.66085 ce: 0.94670 lat: -16.18890
[33mIP:10.60.242.134 [0m[32m[0229 15:41:46 @trainer.py:198][0m Epoch[56] Batch[300] Speed: 427.510659 samples/sec loss: -31.43220 acc: 0.66123 ce: 0.94561 lat: -16.18891
[33mIP:10.60.242.134 [0m[32m[0229 15:42:02 @trainer.py:198][0m Epoch[56] Batch[400] Speed: 405.331409 samples/sec loss: -31.43329 acc: 0.66161 ce: 0.94453 lat: -16.18891
[33mIP:10.60.242.134 [0m[32m[0229 15:42:17 @trainer.py:198][0m Epoch[56] Batch[500] Speed: 424.293647 samples/sec loss: -31.43440 acc: 0.66201 ce: 0.94342 lat: -16.18891
[33mIP:10.60.242.134 [0m[32m[0229 15:42:32 @trainer.py:198][0m Epoch[56] Batch[600] Speed: 428.944613 samples/sec loss: -31.43546 acc: 0.66239 ce: 0.94236 lat: -16.18891
[33mIP:10.60.242.134 [0m[32m[0229 15:42:36 @trainer.py:173][0m Change temperature from 0.44025 to 0.42088
[33mIP:10.60.242.134 [0m[32m[0229 15:42:40 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:42:40 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747]
[33mIP:10.60.242.134 [0m[32m[0229 15:42:40 @trainer.py:234][0m acc 0.747
[33mIP:10.60.242.134 [0m[32m[0229 15:42:40 @trainer.py:235][0m max_acc 0.7473
[33mIP:10.60.242.134 [0m[32m[0229 15:42:40 @trainer.py:217][0m Start to train w for epoch 57
[33mIP:10.60.242.134 [0m[32m[0229 15:42:40 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:42:56 @trainer.py:198][0m Epoch[57] Batch[100] Speed: 270.165849 samples/sec loss: -31.43683 acc: 0.66287 ce: 0.94099 lat: -16.18891
[33mIP:10.60.242.134 [0m[32m[0229 15:43:10 @trainer.py:198][0m Epoch[57] Batch[200] Speed: 428.333984 samples/sec loss: -31.43793 acc: 0.66329 ce: 0.93990 lat: -16.18891
[33mIP:10.60.242.134 [0m[32m[0229 15:43:25 @trainer.py:198][0m Epoch[57] Batch[300] Speed: 426.203716 samples/sec loss: -31.43902 acc: 0.66370 ce: 0.93881 lat: -16.18892
[33mIP:10.60.242.134 [0m[32m[0229 15:43:41 @trainer.py:198][0m Epoch[57] Batch[400] Speed: 424.044461 samples/sec loss: -31.44012 acc: 0.66409 ce: 0.93772 lat: -16.18892
[33mIP:10.60.242.134 [0m[32m[0229 15:43:55 @trainer.py:198][0m Epoch[57] Batch[500] Speed: 430.710140 samples/sec loss: -31.44117 acc: 0.66448 ce: 0.93667 lat: -16.18892
[33mIP:10.60.242.134 [0m[32m[0229 15:44:10 @trainer.py:198][0m Epoch[57] Batch[600] Speed: 426.157963 samples/sec loss: -31.44223 acc: 0.66485 ce: 0.93561 lat: -16.18892
[33mIP:10.60.242.134 [0m[32m[0229 15:44:14 @trainer.py:173][0m Change temperature from 0.42088 to 0.40236
[33mIP:10.60.242.134 [0m[32m[0229 15:44:17 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:44:17 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487]
[33mIP:10.60.242.134 [0m[32m[0229 15:44:17 @trainer.py:234][0m acc 0.7487
[33mIP:10.60.242.134 [0m[32m[0229 15:44:17 @trainer.py:235][0m max_acc 0.7487
[33mIP:10.60.242.134 [0m[32m[0229 15:44:17 @trainer.py:217][0m Start to train w for epoch 58
[33mIP:10.60.242.134 [0m[32m[0229 15:44:17 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:44:34 @trainer.py:198][0m Epoch[58] Batch[100] Speed: 274.597020 samples/sec loss: -31.44349 acc: 0.66530 ce: 0.93435 lat: -16.18892
[33mIP:10.60.242.134 [0m[32m[0229 15:44:49 @trainer.py:198][0m Epoch[58] Batch[200] Speed: 415.436575 samples/sec loss: -31.44454 acc: 0.66568 ce: 0.93330 lat: -16.18892
[33mIP:10.60.242.134 [0m[32m[0229 15:45:05 @trainer.py:198][0m Epoch[58] Batch[300] Speed: 413.813987 samples/sec loss: -31.44558 acc: 0.66604 ce: 0.93227 lat: -16.18892
[33mIP:10.60.242.134 [0m[32m[0229 15:45:20 @trainer.py:198][0m Epoch[58] Batch[400] Speed: 417.597239 samples/sec loss: -31.44668 acc: 0.66645 ce: 0.93117 lat: -16.18892
[33mIP:10.60.242.134 [0m[32m[0229 15:45:36 @trainer.py:198][0m Epoch[58] Batch[500] Speed: 410.233428 samples/sec loss: -31.44777 acc: 0.66684 ce: 0.93008 lat: -16.18893
[33mIP:10.60.242.134 [0m[32m[0229 15:45:51 @trainer.py:198][0m Epoch[58] Batch[600] Speed: 420.949436 samples/sec loss: -31.44880 acc: 0.66722 ce: 0.92905 lat: -16.18893
[33mIP:10.60.242.134 [0m[32m[0229 15:45:54 @trainer.py:173][0m Change temperature from 0.40236 to 0.38465
[33mIP:10.60.242.134 [0m[32m[0229 15:45:58 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:45:58 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744]
[33mIP:10.60.242.134 [0m[32m[0229 15:45:58 @trainer.py:234][0m acc 0.744
[33mIP:10.60.242.134 [0m[32m[0229 15:45:58 @trainer.py:235][0m max_acc 0.7487
[33mIP:10.60.242.134 [0m[32m[0229 15:45:58 @trainer.py:217][0m Start to train w for epoch 59
[33mIP:10.60.242.134 [0m[32m[0229 15:45:58 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:46:13 @trainer.py:198][0m Epoch[59] Batch[100] Speed: 283.230455 samples/sec loss: -31.45014 acc: 0.66769 ce: 0.92772 lat: -16.18893
[33mIP:10.60.242.134 [0m[32m[0229 15:46:28 @trainer.py:198][0m Epoch[59] Batch[200] Speed: 430.500754 samples/sec loss: -31.45117 acc: 0.66807 ce: 0.92669 lat: -16.18893
[33mIP:10.60.242.134 [0m[32m[0229 15:46:43 @trainer.py:198][0m Epoch[59] Batch[300] Speed: 427.452665 samples/sec loss: -31.45217 acc: 0.66843 ce: 0.92570 lat: -16.18893
[33mIP:10.60.242.134 [0m[32m[0229 15:46:58 @trainer.py:198][0m Epoch[59] Batch[400] Speed: 431.092877 samples/sec loss: -31.45322 acc: 0.66882 ce: 0.92464 lat: -16.18893
[33mIP:10.60.242.134 [0m[32m[0229 15:47:13 @trainer.py:198][0m Epoch[59] Batch[500] Speed: 418.775291 samples/sec loss: -31.45422 acc: 0.66917 ce: 0.92365 lat: -16.18893
[33mIP:10.60.242.134 [0m[32m[0229 15:47:28 @trainer.py:198][0m Epoch[59] Batch[600] Speed: 427.787926 samples/sec loss: -31.45518 acc: 0.66951 ce: 0.92268 lat: -16.18893
[33mIP:10.60.242.134 [0m[32m[0229 15:47:32 @trainer.py:173][0m Change temperature from 0.38465 to 0.36773
[33mIP:10.60.242.134 [0m[32m[0229 15:47:35 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:47:35 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481]
[33mIP:10.60.242.134 [0m[32m[0229 15:47:35 @trainer.py:234][0m acc 0.7481
[33mIP:10.60.242.134 [0m[32m[0229 15:47:35 @trainer.py:235][0m max_acc 0.7487
[33mIP:10.60.242.134 [0m[32m[0229 15:47:35 @trainer.py:217][0m Start to train w for epoch 60
[33mIP:10.60.242.134 [0m[32m[0229 15:47:35 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:47:51 @trainer.py:198][0m Epoch[60] Batch[100] Speed: 283.502922 samples/sec loss: -31.45647 acc: 0.66999 ce: 0.92140 lat: -16.18894
[33mIP:10.60.242.134 [0m[32m[0229 15:48:06 @trainer.py:198][0m Epoch[60] Batch[200] Speed: 417.387588 samples/sec loss: -31.45746 acc: 0.67034 ce: 0.92041 lat: -16.18894
[33mIP:10.60.242.134 [0m[32m[0229 15:48:21 @trainer.py:198][0m Epoch[60] Batch[300] Speed: 434.218133 samples/sec loss: -31.45846 acc: 0.67071 ce: 0.91942 lat: -16.18894
[33mIP:10.60.242.134 [0m[32m[0229 15:48:35 @trainer.py:198][0m Epoch[60] Batch[400] Speed: 447.374606 samples/sec loss: -31.45942 acc: 0.67105 ce: 0.91846 lat: -16.18894
[33mIP:10.60.242.134 [0m[32m[0229 15:48:50 @trainer.py:198][0m Epoch[60] Batch[500] Speed: 432.432218 samples/sec loss: -31.46044 acc: 0.67142 ce: 0.91745 lat: -16.18894
[33mIP:10.60.242.134 [0m[32m[0229 15:49:05 @trainer.py:198][0m Epoch[60] Batch[600] Speed: 417.522180 samples/sec loss: -31.46145 acc: 0.67177 ce: 0.91644 lat: -16.18894
[33mIP:10.60.242.134 [0m[32m[0229 15:49:09 @trainer.py:173][0m Change temperature from 0.36773 to 0.35155
[33mIP:10.60.242.134 [0m[32m[0229 15:49:13 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:49:13 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433]
[33mIP:10.60.242.134 [0m[32m[0229 15:49:13 @trainer.py:234][0m acc 0.7433
[33mIP:10.60.242.134 [0m[32m[0229 15:49:13 @trainer.py:235][0m max_acc 0.7487
[33mIP:10.60.242.134 [0m[32m[0229 15:49:13 @trainer.py:217][0m Start to train w for epoch 61
[33mIP:10.60.242.134 [0m[32m[0229 15:49:13 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:49:30 @trainer.py:198][0m Epoch[61] Batch[100] Speed: 263.823245 samples/sec loss: -31.46270 acc: 0.67221 ce: 0.91518 lat: -16.18894
[33mIP:10.60.242.134 [0m[32m[0229 15:49:46 @trainer.py:198][0m Epoch[61] Batch[200] Speed: 401.301162 samples/sec loss: -31.46368 acc: 0.67255 ce: 0.91421 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:50:01 @trainer.py:198][0m Epoch[61] Batch[300] Speed: 410.701423 samples/sec loss: -31.46463 acc: 0.67291 ce: 0.91326 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:50:16 @trainer.py:198][0m Epoch[61] Batch[400] Speed: 419.139321 samples/sec loss: -31.46564 acc: 0.67326 ce: 0.91225 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:50:32 @trainer.py:198][0m Epoch[61] Batch[500] Speed: 410.526039 samples/sec loss: -31.46662 acc: 0.67361 ce: 0.91128 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:50:48 @trainer.py:198][0m Epoch[61] Batch[600] Speed: 405.550663 samples/sec loss: -31.46756 acc: 0.67396 ce: 0.91033 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:50:52 @trainer.py:173][0m Change temperature from 0.35155 to 0.33608
[33mIP:10.60.242.134 [0m[32m[0229 15:50:55 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:50:55 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495]
[33mIP:10.60.242.134 [0m[32m[0229 15:50:55 @trainer.py:234][0m acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 15:50:55 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 15:50:55 @trainer.py:217][0m Start to train w for epoch 62
[33mIP:10.60.242.134 [0m[32m[0229 15:50:55 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:51:11 @trainer.py:198][0m Epoch[62] Batch[100] Speed: 278.045152 samples/sec loss: -31.46875 acc: 0.67441 ce: 0.90915 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:51:26 @trainer.py:198][0m Epoch[62] Batch[200] Speed: 420.180402 samples/sec loss: -31.46970 acc: 0.67475 ce: 0.90820 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:51:41 @trainer.py:198][0m Epoch[62] Batch[300] Speed: 418.720695 samples/sec loss: -31.47061 acc: 0.67506 ce: 0.90730 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:51:57 @trainer.py:198][0m Epoch[62] Batch[400] Speed: 412.645122 samples/sec loss: -31.47154 acc: 0.67538 ce: 0.90637 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:52:12 @trainer.py:198][0m Epoch[62] Batch[500] Speed: 424.637195 samples/sec loss: -31.47238 acc: 0.67569 ce: 0.90553 lat: -16.18895
[33mIP:10.60.242.134 [0m[32m[0229 15:52:26 @trainer.py:198][0m Epoch[62] Batch[600] Speed: 443.788333 samples/sec loss: -31.47335 acc: 0.67604 ce: 0.90456 lat: -16.18896
[33mIP:10.60.242.134 [0m[32m[0229 15:52:30 @trainer.py:173][0m Change temperature from 0.33608 to 0.32129
[33mIP:10.60.242.134 [0m[32m[0229 15:52:34 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:52:34 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493]
[33mIP:10.60.242.134 [0m[32m[0229 15:52:34 @trainer.py:234][0m acc 0.7493
[33mIP:10.60.242.134 [0m[32m[0229 15:52:34 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 15:52:34 @trainer.py:217][0m Start to train w for epoch 63
[33mIP:10.60.242.134 [0m[32m[0229 15:52:34 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:52:50 @trainer.py:198][0m Epoch[63] Batch[100] Speed: 275.321641 samples/sec loss: -31.47422 acc: 0.67635 ce: 0.90369 lat: -16.18896
[33mIP:10.60.242.134 [0m[32m[0229 15:53:05 @trainer.py:198][0m Epoch[63] Batch[200] Speed: 421.250234 samples/sec loss: -31.47475 acc: 0.67656 ce: 0.90316 lat: -16.18896
[33mIP:10.60.242.134 [0m[32m[0229 15:53:20 @trainer.py:198][0m Epoch[63] Batch[300] Speed: 415.082425 samples/sec loss: -31.47532 acc: 0.67677 ce: 0.90260 lat: -16.18896
[33mIP:10.60.242.134 [0m[32m[0229 15:53:36 @trainer.py:198][0m Epoch[63] Batch[400] Speed: 403.084353 samples/sec loss: -31.47587 acc: 0.67699 ce: 0.90205 lat: -16.18896
[33mIP:10.60.242.134 [0m[32m[0229 15:53:51 @trainer.py:198][0m Epoch[63] Batch[500] Speed: 417.634376 samples/sec loss: -31.47640 acc: 0.67720 ce: 0.90152 lat: -16.18896
[33mIP:10.60.242.134 [0m[32m[0229 15:54:07 @trainer.py:198][0m Epoch[63] Batch[600] Speed: 409.981655 samples/sec loss: -31.47697 acc: 0.67742 ce: 0.90096 lat: -16.18896
[33mIP:10.60.242.134 [0m[32m[0229 15:54:11 @trainer.py:173][0m Change temperature from 0.32129 to 0.30716
[33mIP:10.60.242.134 [0m[32m[0229 15:54:14 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:54:14 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283]
[33mIP:10.60.242.134 [0m[32m[0229 15:54:14 @trainer.py:234][0m acc 0.7283
[33mIP:10.60.242.134 [0m[32m[0229 15:54:14 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 15:54:14 @trainer.py:217][0m Start to train w for epoch 64
[33mIP:10.60.242.134 [0m[32m[0229 15:54:14 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:54:30 @trainer.py:198][0m Epoch[64] Batch[100] Speed: 281.618089 samples/sec loss: -31.47769 acc: 0.67768 ce: 0.90024 lat: -16.18896
[33mIP:10.60.242.134 [0m[32m[0229 15:54:45 @trainer.py:198][0m Epoch[64] Batch[200] Speed: 415.555932 samples/sec loss: -31.47828 acc: 0.67791 ce: 0.89966 lat: -16.18897
[33mIP:10.60.242.134 [0m[32m[0229 15:55:00 @trainer.py:198][0m Epoch[64] Batch[300] Speed: 420.571825 samples/sec loss: -31.47879 acc: 0.67810 ce: 0.89915 lat: -16.18897
[33mIP:10.60.242.134 [0m[32m[0229 15:55:15 @trainer.py:198][0m Epoch[64] Batch[400] Speed: 423.985214 samples/sec loss: -31.47928 acc: 0.67829 ce: 0.89866 lat: -16.18897
[33mIP:10.60.242.134 [0m[32m[0229 15:55:31 @trainer.py:198][0m Epoch[64] Batch[500] Speed: 419.591733 samples/sec loss: -31.47984 acc: 0.67850 ce: 0.89810 lat: -16.18897
[33mIP:10.60.242.134 [0m[32m[0229 15:55:46 @trainer.py:198][0m Epoch[64] Batch[600] Speed: 417.695047 samples/sec loss: -31.48035 acc: 0.67870 ce: 0.89759 lat: -16.18897
[33mIP:10.60.242.134 [0m[32m[0229 15:55:50 @trainer.py:173][0m Change temperature from 0.30716 to 0.29364
[33mIP:10.60.242.134 [0m[32m[0229 15:55:53 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:55:53 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322]
[33mIP:10.60.242.134 [0m[32m[0229 15:55:53 @trainer.py:234][0m acc 0.7322
[33mIP:10.60.242.134 [0m[32m[0229 15:55:53 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 15:55:53 @trainer.py:217][0m Start to train w for epoch 65
[33mIP:10.60.242.134 [0m[32m[0229 15:55:53 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:56:09 @trainer.py:198][0m Epoch[65] Batch[100] Speed: 281.057372 samples/sec loss: -31.48109 acc: 0.67896 ce: 0.89686 lat: -16.18897
[33mIP:10.60.242.134 [0m[32m[0229 15:56:23 @trainer.py:198][0m Epoch[65] Batch[200] Speed: 456.991798 samples/sec loss: -31.48156 acc: 0.67913 ce: 0.89639 lat: -16.18898
[33mIP:10.60.242.134 [0m[32m[0229 15:56:38 @trainer.py:198][0m Epoch[65] Batch[300] Speed: 435.605480 samples/sec loss: -31.48207 acc: 0.67932 ce: 0.89589 lat: -16.18898
[33mIP:10.60.242.134 [0m[32m[0229 15:56:53 @trainer.py:198][0m Epoch[65] Batch[400] Speed: 422.873116 samples/sec loss: -31.48263 acc: 0.67953 ce: 0.89533 lat: -16.18898
[33mIP:10.60.242.134 [0m[32m[0229 15:57:08 @trainer.py:198][0m Epoch[65] Batch[500] Speed: 429.388304 samples/sec loss: -31.48315 acc: 0.67972 ce: 0.89481 lat: -16.18898
[33mIP:10.60.242.134 [0m[32m[0229 15:57:22 @trainer.py:198][0m Epoch[65] Batch[600] Speed: 434.643225 samples/sec loss: -31.48370 acc: 0.67993 ce: 0.89426 lat: -16.18898
[33mIP:10.60.242.134 [0m[32m[0229 15:57:26 @trainer.py:173][0m Change temperature from 0.29364 to 0.28072
[33mIP:10.60.242.134 [0m[32m[0229 15:57:29 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:57:29 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713]
[33mIP:10.60.242.134 [0m[32m[0229 15:57:29 @trainer.py:234][0m acc 0.713
[33mIP:10.60.242.134 [0m[32m[0229 15:57:29 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 15:57:29 @trainer.py:217][0m Start to train w for epoch 66
[33mIP:10.60.242.134 [0m[32m[0229 15:57:29 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:57:45 @trainer.py:198][0m Epoch[66] Batch[100] Speed: 278.477011 samples/sec loss: -31.48443 acc: 0.68019 ce: 0.89354 lat: -16.18898
[33mIP:10.60.242.134 [0m[32m[0229 15:58:00 @trainer.py:198][0m Epoch[66] Batch[200] Speed: 431.435067 samples/sec loss: -31.48496 acc: 0.68039 ce: 0.89302 lat: -16.18899
[33mIP:10.60.242.134 [0m[32m[0229 15:58:15 @trainer.py:198][0m Epoch[66] Batch[300] Speed: 418.610878 samples/sec loss: -31.48544 acc: 0.68056 ce: 0.89254 lat: -16.18899
[33mIP:10.60.242.134 [0m[32m[0229 15:58:31 @trainer.py:198][0m Epoch[66] Batch[400] Speed: 413.636624 samples/sec loss: -31.48591 acc: 0.68073 ce: 0.89207 lat: -16.18899
[33mIP:10.60.242.134 [0m[32m[0229 15:58:46 @trainer.py:198][0m Epoch[66] Batch[500] Speed: 428.040194 samples/sec loss: -31.48644 acc: 0.68092 ce: 0.89155 lat: -16.18899
[33mIP:10.60.242.134 [0m[32m[0229 15:59:01 @trainer.py:198][0m Epoch[66] Batch[600] Speed: 430.197449 samples/sec loss: -31.48693 acc: 0.68111 ce: 0.89106 lat: -16.18899
[33mIP:10.60.242.134 [0m[32m[0229 15:59:04 @trainer.py:173][0m Change temperature from 0.28072 to 0.26837
[33mIP:10.60.242.134 [0m[32m[0229 15:59:07 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 15:59:07 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345]
[33mIP:10.60.242.134 [0m[32m[0229 15:59:07 @trainer.py:234][0m acc 0.7345
[33mIP:10.60.242.134 [0m[32m[0229 15:59:07 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 15:59:07 @trainer.py:217][0m Start to train w for epoch 67
[33mIP:10.60.242.134 [0m[32m[0229 15:59:07 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 15:59:24 @trainer.py:198][0m Epoch[67] Batch[100] Speed: 280.068697 samples/sec loss: -31.48762 acc: 0.68136 ce: 0.89038 lat: -16.18900
[33mIP:10.60.242.134 [0m[32m[0229 15:59:39 @trainer.py:198][0m Epoch[67] Batch[200] Speed: 407.375404 samples/sec loss: -31.48814 acc: 0.68154 ce: 0.88985 lat: -16.18900
[33mIP:10.60.242.134 [0m[32m[0229 15:59:54 @trainer.py:198][0m Epoch[67] Batch[300] Speed: 422.008954 samples/sec loss: -31.48863 acc: 0.68172 ce: 0.88937 lat: -16.18900
[33mIP:10.60.242.134 [0m[32m[0229 16:00:10 @trainer.py:198][0m Epoch[67] Batch[400] Speed: 413.949253 samples/sec loss: -31.48915 acc: 0.68193 ce: 0.88885 lat: -16.18900
[33mIP:10.60.242.134 [0m[32m[0229 16:00:25 @trainer.py:198][0m Epoch[67] Batch[500] Speed: 411.644277 samples/sec loss: -31.48969 acc: 0.68213 ce: 0.88831 lat: -16.18900
[33mIP:10.60.242.134 [0m[32m[0229 16:00:41 @trainer.py:198][0m Epoch[67] Batch[600] Speed: 422.914429 samples/sec loss: -31.49019 acc: 0.68231 ce: 0.88782 lat: -16.18900
[33mIP:10.60.242.134 [0m[32m[0229 16:00:44 @trainer.py:173][0m Change temperature from 0.26837 to 0.25656
[33mIP:10.60.242.134 [0m[32m[0229 16:00:48 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:00:48 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736]
[33mIP:10.60.242.134 [0m[32m[0229 16:00:48 @trainer.py:234][0m acc 0.736
[33mIP:10.60.242.134 [0m[32m[0229 16:00:48 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 16:00:48 @trainer.py:217][0m Start to train w for epoch 68
[33mIP:10.60.242.134 [0m[32m[0229 16:00:48 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:01:04 @trainer.py:198][0m Epoch[68] Batch[100] Speed: 274.631820 samples/sec loss: -31.49092 acc: 0.68258 ce: 0.88710 lat: -16.18901
[33mIP:10.60.242.134 [0m[32m[0229 16:01:19 @trainer.py:198][0m Epoch[68] Batch[200] Speed: 414.636951 samples/sec loss: -31.49147 acc: 0.68278 ce: 0.88655 lat: -16.18901
[33mIP:10.60.242.134 [0m[32m[0229 16:01:35 @trainer.py:198][0m Epoch[68] Batch[300] Speed: 416.906966 samples/sec loss: -31.49200 acc: 0.68298 ce: 0.88602 lat: -16.18901
[33mIP:10.60.242.134 [0m[32m[0229 16:01:50 @trainer.py:198][0m Epoch[68] Batch[400] Speed: 414.811205 samples/sec loss: -31.49256 acc: 0.68318 ce: 0.88546 lat: -16.18901
[33mIP:10.60.242.134 [0m[32m[0229 16:02:05 @trainer.py:198][0m Epoch[68] Batch[500] Speed: 418.145830 samples/sec loss: -31.49310 acc: 0.68338 ce: 0.88493 lat: -16.18901
[33mIP:10.60.242.134 [0m[32m[0229 16:02:21 @trainer.py:198][0m Epoch[68] Batch[600] Speed: 416.073319 samples/sec loss: -31.49359 acc: 0.68356 ce: 0.88445 lat: -16.18902
[33mIP:10.60.242.134 [0m[32m[0229 16:02:24 @trainer.py:173][0m Change temperature from 0.25656 to 0.24527
[33mIP:10.60.242.134 [0m[32m[0229 16:02:28 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:02:28 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368]
[33mIP:10.60.242.134 [0m[32m[0229 16:02:28 @trainer.py:234][0m acc 0.7368
[33mIP:10.60.242.134 [0m[32m[0229 16:02:28 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 16:02:28 @trainer.py:217][0m Start to train w for epoch 69
[33mIP:10.60.242.134 [0m[32m[0229 16:02:28 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:02:43 @trainer.py:198][0m Epoch[69] Batch[100] Speed: 282.856996 samples/sec loss: -31.49430 acc: 0.68384 ce: 0.88374 lat: -16.18902
[33mIP:10.60.242.134 [0m[32m[0229 16:02:59 @trainer.py:198][0m Epoch[69] Batch[200] Speed: 415.386348 samples/sec loss: -31.49487 acc: 0.68406 ce: 0.88317 lat: -16.18902
[33mIP:10.60.242.134 [0m[32m[0229 16:03:14 @trainer.py:198][0m Epoch[69] Batch[300] Speed: 416.816770 samples/sec loss: -31.49537 acc: 0.68426 ce: 0.88267 lat: -16.18902
[33mIP:10.60.242.134 [0m[32m[0229 16:03:30 @trainer.py:198][0m Epoch[69] Batch[400] Speed: 410.059634 samples/sec loss: -31.49584 acc: 0.68445 ce: 0.88220 lat: -16.18902
[33mIP:10.60.242.134 [0m[32m[0229 16:03:45 @trainer.py:198][0m Epoch[69] Batch[500] Speed: 429.672655 samples/sec loss: -31.49638 acc: 0.68465 ce: 0.88168 lat: -16.18903
[33mIP:10.60.242.134 [0m[32m[0229 16:03:59 @trainer.py:198][0m Epoch[69] Batch[600] Speed: 444.985862 samples/sec loss: -31.49686 acc: 0.68484 ce: 0.88120 lat: -16.18903
[33mIP:10.60.242.134 [0m[32m[0229 16:04:03 @trainer.py:173][0m Change temperature from 0.24527 to 0.23448
[33mIP:10.60.242.134 [0m[32m[0229 16:04:06 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:04:06 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73]
[33mIP:10.60.242.134 [0m[32m[0229 16:04:06 @trainer.py:234][0m acc 0.73
[33mIP:10.60.242.134 [0m[32m[0229 16:04:06 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 16:04:06 @trainer.py:217][0m Start to train w for epoch 70
[33mIP:10.60.242.134 [0m[32m[0229 16:04:06 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:04:22 @trainer.py:198][0m Epoch[70] Batch[100] Speed: 279.372263 samples/sec loss: -31.49755 acc: 0.68508 ce: 0.88051 lat: -16.18903
[33mIP:10.60.242.134 [0m[32m[0229 16:04:37 @trainer.py:198][0m Epoch[70] Batch[200] Speed: 414.104697 samples/sec loss: -31.49809 acc: 0.68529 ce: 0.87997 lat: -16.18903
[33mIP:10.60.242.134 [0m[32m[0229 16:04:53 @trainer.py:198][0m Epoch[70] Batch[300] Speed: 414.183351 samples/sec loss: -31.49861 acc: 0.68548 ce: 0.87945 lat: -16.18903
[33mIP:10.60.242.134 [0m[32m[0229 16:05:08 @trainer.py:198][0m Epoch[70] Batch[400] Speed: 419.527508 samples/sec loss: -31.49912 acc: 0.68567 ce: 0.87895 lat: -16.18903
[33mIP:10.60.242.134 [0m[32m[0229 16:05:23 @trainer.py:198][0m Epoch[70] Batch[500] Speed: 421.535588 samples/sec loss: -31.49964 acc: 0.68587 ce: 0.87844 lat: -16.18904
[33mIP:10.60.242.134 [0m[32m[0229 16:05:38 @trainer.py:198][0m Epoch[70] Batch[600] Speed: 423.031622 samples/sec loss: -31.50015 acc: 0.68606 ce: 0.87792 lat: -16.18904
[33mIP:10.60.242.134 [0m[32m[0229 16:05:42 @trainer.py:173][0m Change temperature from 0.23448 to 0.22416
[33mIP:10.60.242.134 [0m[32m[0229 16:05:46 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:05:46 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353]
[33mIP:10.60.242.134 [0m[32m[0229 16:05:46 @trainer.py:234][0m acc 0.7353
[33mIP:10.60.242.134 [0m[32m[0229 16:05:46 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 16:05:46 @trainer.py:217][0m Start to train w for epoch 71
[33mIP:10.60.242.134 [0m[32m[0229 16:05:46 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:06:02 @trainer.py:198][0m Epoch[71] Batch[100] Speed: 275.225111 samples/sec loss: -31.50088 acc: 0.68634 ce: 0.87720 lat: -16.18904
[33mIP:10.60.242.134 [0m[32m[0229 16:06:17 @trainer.py:198][0m Epoch[71] Batch[200] Speed: 425.373641 samples/sec loss: -31.50148 acc: 0.68656 ce: 0.87661 lat: -16.18904
[33mIP:10.60.242.134 [0m[32m[0229 16:06:32 @trainer.py:198][0m Epoch[71] Batch[300] Speed: 424.081588 samples/sec loss: -31.50201 acc: 0.68676 ce: 0.87608 lat: -16.18904
[33mIP:10.60.242.134 [0m[32m[0229 16:06:46 @trainer.py:198][0m Epoch[71] Batch[400] Speed: 450.082329 samples/sec loss: -31.50246 acc: 0.68694 ce: 0.87563 lat: -16.18905
[33mIP:10.60.242.134 [0m[32m[0229 16:07:01 @trainer.py:198][0m Epoch[71] Batch[500] Speed: 432.180174 samples/sec loss: -31.50299 acc: 0.68714 ce: 0.87511 lat: -16.18905
[33mIP:10.60.242.134 [0m[32m[0229 16:07:16 @trainer.py:198][0m Epoch[71] Batch[600] Speed: 421.880000 samples/sec loss: -31.50352 acc: 0.68735 ce: 0.87458 lat: -16.18905
[33mIP:10.60.242.134 [0m[32m[0229 16:07:20 @trainer.py:173][0m Change temperature from 0.22416 to 0.21430
[33mIP:10.60.242.134 [0m[32m[0229 16:07:24 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:07:24 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446]
[33mIP:10.60.242.134 [0m[32m[0229 16:07:24 @trainer.py:234][0m acc 0.7446
[33mIP:10.60.242.134 [0m[32m[0229 16:07:24 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 16:07:24 @trainer.py:217][0m Start to train w for epoch 72
[33mIP:10.60.242.134 [0m[32m[0229 16:07:24 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:07:40 @trainer.py:198][0m Epoch[72] Batch[100] Speed: 269.701998 samples/sec loss: -31.50420 acc: 0.68760 ce: 0.87390 lat: -16.18905
[33mIP:10.60.242.134 [0m[32m[0229 16:07:55 @trainer.py:198][0m Epoch[72] Batch[200] Speed: 411.877241 samples/sec loss: -31.50473 acc: 0.68779 ce: 0.87337 lat: -16.18905
[33mIP:10.60.242.134 [0m[32m[0229 16:08:11 @trainer.py:198][0m Epoch[72] Batch[300] Speed: 412.078779 samples/sec loss: -31.50527 acc: 0.68798 ce: 0.87284 lat: -16.18906
[33mIP:10.60.242.134 [0m[32m[0229 16:08:26 @trainer.py:198][0m Epoch[72] Batch[400] Speed: 415.557244 samples/sec loss: -31.50581 acc: 0.68818 ce: 0.87231 lat: -16.18906
[33mIP:10.60.242.134 [0m[32m[0229 16:08:42 @trainer.py:198][0m Epoch[72] Batch[500] Speed: 406.976734 samples/sec loss: -31.50635 acc: 0.68839 ce: 0.87176 lat: -16.18906
[33mIP:10.60.242.134 [0m[32m[0229 16:08:57 @trainer.py:198][0m Epoch[72] Batch[600] Speed: 424.107604 samples/sec loss: -31.50687 acc: 0.68859 ce: 0.87125 lat: -16.18906
[33mIP:10.60.242.134 [0m[32m[0229 16:09:01 @trainer.py:173][0m Change temperature from 0.21430 to 0.20487
[33mIP:10.60.242.134 [0m[32m[0229 16:09:04 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:09:04 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389]
[33mIP:10.60.242.134 [0m[32m[0229 16:09:04 @trainer.py:234][0m acc 0.7389
[33mIP:10.60.242.134 [0m[32m[0229 16:09:04 @trainer.py:235][0m max_acc 0.7495
[33mIP:10.60.242.134 [0m[32m[0229 16:09:04 @trainer.py:217][0m Start to train w for epoch 73
[33mIP:10.60.242.134 [0m[32m[0229 16:09:04 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:09:20 @trainer.py:198][0m Epoch[73] Batch[100] Speed: 275.718618 samples/sec loss: -31.50761 acc: 0.68886 ce: 0.87052 lat: -16.18906
[33mIP:10.60.242.134 [0m[32m[0229 16:09:36 @trainer.py:198][0m Epoch[73] Batch[200] Speed: 407.809870 samples/sec loss: -31.50818 acc: 0.68906 ce: 0.86995 lat: -16.18906
[33mIP:10.60.242.134 [0m[32m[0229 16:09:51 @trainer.py:198][0m Epoch[73] Batch[300] Speed: 419.514336 samples/sec loss: -31.50875 acc: 0.68928 ce: 0.86938 lat: -16.18906
[33mIP:10.60.242.134 [0m[32m[0229 16:10:06 @trainer.py:198][0m Epoch[73] Batch[400] Speed: 421.672638 samples/sec loss: -31.50928 acc: 0.68948 ce: 0.86885 lat: -16.18907
[33mIP:10.60.242.134 [0m[32m[0229 16:10:22 @trainer.py:198][0m Epoch[73] Batch[500] Speed: 416.429318 samples/sec loss: -31.50981 acc: 0.68967 ce: 0.86833 lat: -16.18907
[33mIP:10.60.242.134 [0m[32m[0229 16:10:37 @trainer.py:198][0m Epoch[73] Batch[600] Speed: 431.102708 samples/sec loss: -31.51030 acc: 0.68984 ce: 0.86784 lat: -16.18907
[33mIP:10.60.242.134 [0m[32m[0229 16:10:40 @trainer.py:173][0m Change temperature from 0.20487 to 0.19586
[33mIP:10.60.242.134 [0m[32m[0229 16:10:44 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:10:44 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754]
[33mIP:10.60.242.134 [0m[32m[0229 16:10:44 @trainer.py:234][0m acc 0.754
[33mIP:10.60.242.134 [0m[32m[0229 16:10:44 @trainer.py:235][0m max_acc 0.754
[33mIP:10.60.242.134 [0m[32m[0229 16:10:44 @trainer.py:217][0m Start to train w for epoch 74
[33mIP:10.60.242.134 [0m[32m[0229 16:10:44 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:11:00 @trainer.py:198][0m Epoch[74] Batch[100] Speed: 269.795999 samples/sec loss: -31.51101 acc: 0.69010 ce: 0.86713 lat: -16.18907
[33mIP:10.60.242.134 [0m[32m[0229 16:11:16 @trainer.py:198][0m Epoch[74] Batch[200] Speed: 399.266981 samples/sec loss: -31.51156 acc: 0.69031 ce: 0.86659 lat: -16.18907
[33mIP:10.60.242.134 [0m[32m[0229 16:11:32 @trainer.py:198][0m Epoch[74] Batch[300] Speed: 418.976838 samples/sec loss: -31.51212 acc: 0.69053 ce: 0.86603 lat: -16.18908
[33mIP:10.60.242.134 [0m[32m[0229 16:11:47 @trainer.py:198][0m Epoch[74] Batch[400] Speed: 416.823585 samples/sec loss: -31.51267 acc: 0.69073 ce: 0.86549 lat: -16.18908
[33mIP:10.60.242.134 [0m[32m[0229 16:12:03 @trainer.py:198][0m Epoch[74] Batch[500] Speed: 411.767813 samples/sec loss: -31.51321 acc: 0.69093 ce: 0.86495 lat: -16.18908
[33mIP:10.60.242.134 [0m[32m[0229 16:12:17 @trainer.py:198][0m Epoch[74] Batch[600] Speed: 428.758469 samples/sec loss: -31.51373 acc: 0.69113 ce: 0.86443 lat: -16.18908
[33mIP:10.60.242.134 [0m[32m[0229 16:12:21 @trainer.py:173][0m Change temperature from 0.19586 to 0.18724
[33mIP:10.60.242.134 [0m[32m[0229 16:12:24 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:12:24 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431]
[33mIP:10.60.242.134 [0m[32m[0229 16:12:24 @trainer.py:234][0m acc 0.7431
[33mIP:10.60.242.134 [0m[32m[0229 16:12:24 @trainer.py:235][0m max_acc 0.754
[33mIP:10.60.242.134 [0m[32m[0229 16:12:24 @trainer.py:217][0m Start to train w for epoch 75
[33mIP:10.60.242.134 [0m[32m[0229 16:12:24 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:12:40 @trainer.py:198][0m Epoch[75] Batch[100] Speed: 280.894539 samples/sec loss: -31.51443 acc: 0.69139 ce: 0.86373 lat: -16.18908
[33mIP:10.60.242.134 [0m[32m[0229 16:12:56 @trainer.py:198][0m Epoch[75] Batch[200] Speed: 410.446377 samples/sec loss: -31.51499 acc: 0.69160 ce: 0.86318 lat: -16.18908
[33mIP:10.60.242.134 [0m[32m[0229 16:13:11 @trainer.py:198][0m Epoch[75] Batch[300] Speed: 423.737312 samples/sec loss: -31.51557 acc: 0.69181 ce: 0.86260 lat: -16.18909
[33mIP:10.60.242.134 [0m[32m[0229 16:13:26 @trainer.py:198][0m Epoch[75] Batch[400] Speed: 431.854871 samples/sec loss: -31.51612 acc: 0.69203 ce: 0.86205 lat: -16.18909
[33mIP:10.60.242.134 [0m[32m[0229 16:13:40 @trainer.py:198][0m Epoch[75] Batch[500] Speed: 435.895742 samples/sec loss: -31.51666 acc: 0.69223 ce: 0.86152 lat: -16.18909
[33mIP:10.60.242.134 [0m[32m[0229 16:13:55 @trainer.py:198][0m Epoch[75] Batch[600] Speed: 428.105585 samples/sec loss: -31.51719 acc: 0.69243 ce: 0.86099 lat: -16.18909
[33mIP:10.60.242.134 [0m[32m[0229 16:13:59 @trainer.py:173][0m Change temperature from 0.18724 to 0.17900
[33mIP:10.60.242.134 [0m[32m[0229 16:14:02 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:14:02 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572]
[33mIP:10.60.242.134 [0m[32m[0229 16:14:02 @trainer.py:234][0m acc 0.7572
[33mIP:10.60.242.134 [0m[32m[0229 16:14:02 @trainer.py:235][0m max_acc 0.7572
[33mIP:10.60.242.134 [0m[32m[0229 16:14:02 @trainer.py:217][0m Start to train w for epoch 76
[33mIP:10.60.242.134 [0m[32m[0229 16:14:02 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:14:19 @trainer.py:198][0m Epoch[76] Batch[100] Speed: 272.766192 samples/sec loss: -31.51794 acc: 0.69271 ce: 0.86024 lat: -16.18909
[33mIP:10.60.242.134 [0m[32m[0229 16:14:35 @trainer.py:198][0m Epoch[76] Batch[200] Speed: 396.428216 samples/sec loss: -31.51846 acc: 0.69291 ce: 0.85973 lat: -16.18909
[33mIP:10.60.242.134 [0m[32m[0229 16:14:50 @trainer.py:198][0m Epoch[76] Batch[300] Speed: 421.899488 samples/sec loss: -31.51900 acc: 0.69312 ce: 0.85920 lat: -16.18910
[33mIP:10.60.242.134 [0m[32m[0229 16:15:06 @trainer.py:198][0m Epoch[76] Batch[400] Speed: 415.718134 samples/sec loss: -31.51954 acc: 0.69332 ce: 0.85866 lat: -16.18910
[33mIP:10.60.242.134 [0m[32m[0229 16:15:21 @trainer.py:198][0m Epoch[76] Batch[500] Speed: 428.766735 samples/sec loss: -31.52011 acc: 0.69353 ce: 0.85809 lat: -16.18910
[33mIP:10.60.242.134 [0m[32m[0229 16:15:35 @trainer.py:198][0m Epoch[76] Batch[600] Speed: 446.503973 samples/sec loss: -31.52064 acc: 0.69373 ce: 0.85756 lat: -16.18910
[33mIP:10.60.242.134 [0m[32m[0229 16:15:38 @trainer.py:173][0m Change temperature from 0.17900 to 0.17112
[33mIP:10.60.242.134 [0m[32m[0229 16:15:43 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:15:43 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488]
[33mIP:10.60.242.134 [0m[32m[0229 16:15:43 @trainer.py:234][0m acc 0.7488
[33mIP:10.60.242.134 [0m[32m[0229 16:15:43 @trainer.py:235][0m max_acc 0.7572
[33mIP:10.60.242.134 [0m[32m[0229 16:15:43 @trainer.py:217][0m Start to train w for epoch 77
[33mIP:10.60.242.134 [0m[32m[0229 16:15:43 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:15:59 @trainer.py:198][0m Epoch[77] Batch[100] Speed: 262.177497 samples/sec loss: -31.52139 acc: 0.69400 ce: 0.85682 lat: -16.18910
[33mIP:10.60.242.134 [0m[32m[0229 16:16:15 @trainer.py:198][0m Epoch[77] Batch[200] Speed: 407.603690 samples/sec loss: -31.52195 acc: 0.69422 ce: 0.85626 lat: -16.18910
[33mIP:10.60.242.134 [0m[32m[0229 16:16:30 @trainer.py:198][0m Epoch[77] Batch[300] Speed: 415.027926 samples/sec loss: -31.52251 acc: 0.69443 ce: 0.85570 lat: -16.18911
[33mIP:10.60.242.134 [0m[32m[0229 16:16:46 @trainer.py:198][0m Epoch[77] Batch[400] Speed: 416.885613 samples/sec loss: -31.52307 acc: 0.69463 ce: 0.85515 lat: -16.18911
[33mIP:10.60.242.134 [0m[32m[0229 16:17:01 @trainer.py:198][0m Epoch[77] Batch[500] Speed: 414.076265 samples/sec loss: -31.52359 acc: 0.69483 ce: 0.85462 lat: -16.18911
[33mIP:10.60.242.134 [0m[32m[0229 16:17:16 @trainer.py:198][0m Epoch[77] Batch[600] Speed: 425.517885 samples/sec loss: -31.52407 acc: 0.69501 ce: 0.85415 lat: -16.18911
[33mIP:10.60.242.134 [0m[32m[0229 16:17:20 @trainer.py:173][0m Change temperature from 0.17112 to 0.16359
[33mIP:10.60.242.134 [0m[32m[0229 16:17:23 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:17:23 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606]
[33mIP:10.60.242.134 [0m[32m[0229 16:17:23 @trainer.py:234][0m acc 0.7606
[33mIP:10.60.242.134 [0m[32m[0229 16:17:23 @trainer.py:235][0m max_acc 0.7606
[33mIP:10.60.242.134 [0m[32m[0229 16:17:23 @trainer.py:217][0m Start to train w for epoch 78
[33mIP:10.60.242.134 [0m[32m[0229 16:17:23 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:17:40 @trainer.py:198][0m Epoch[78] Batch[100] Speed: 273.638983 samples/sec loss: -31.52480 acc: 0.69529 ce: 0.85342 lat: -16.18911
[33mIP:10.60.242.134 [0m[32m[0229 16:17:55 @trainer.py:198][0m Epoch[78] Batch[200] Speed: 410.615763 samples/sec loss: -31.52536 acc: 0.69549 ce: 0.85287 lat: -16.18911
[33mIP:10.60.242.134 [0m[32m[0229 16:18:11 @trainer.py:198][0m Epoch[78] Batch[300] Speed: 412.754839 samples/sec loss: -31.52593 acc: 0.69569 ce: 0.85230 lat: -16.18912
[33mIP:10.60.242.134 [0m[32m[0229 16:18:27 @trainer.py:198][0m Epoch[78] Batch[400] Speed: 405.569829 samples/sec loss: -31.52644 acc: 0.69588 ce: 0.85179 lat: -16.18912
[33mIP:10.60.242.134 [0m[32m[0229 16:18:41 @trainer.py:198][0m Epoch[78] Batch[500] Speed: 431.197005 samples/sec loss: -31.52696 acc: 0.69608 ce: 0.85127 lat: -16.18912
[33mIP:10.60.242.134 [0m[32m[0229 16:18:56 @trainer.py:198][0m Epoch[78] Batch[600] Speed: 433.627920 samples/sec loss: -31.52750 acc: 0.69627 ce: 0.85074 lat: -16.18912
[33mIP:10.60.242.134 [0m[32m[0229 16:19:00 @trainer.py:173][0m Change temperature from 0.16359 to 0.15640
[33mIP:10.60.242.134 [0m[32m[0229 16:19:03 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:19:03 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447]
[33mIP:10.60.242.134 [0m[32m[0229 16:19:03 @trainer.py:234][0m acc 0.7447
[33mIP:10.60.242.134 [0m[32m[0229 16:19:03 @trainer.py:235][0m max_acc 0.7606
[33mIP:10.60.242.134 [0m[32m[0229 16:19:03 @trainer.py:217][0m Start to train w for epoch 79
[33mIP:10.60.242.134 [0m[32m[0229 16:19:03 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:19:19 @trainer.py:198][0m Epoch[79] Batch[100] Speed: 279.801065 samples/sec loss: -31.52820 acc: 0.69652 ce: 0.85004 lat: -16.18912
[33mIP:10.60.242.134 [0m[32m[0229 16:19:34 @trainer.py:198][0m Epoch[79] Batch[200] Speed: 433.020861 samples/sec loss: -31.52876 acc: 0.69673 ce: 0.84949 lat: -16.18912
[33mIP:10.60.242.134 [0m[32m[0229 16:19:48 @trainer.py:198][0m Epoch[79] Batch[300] Speed: 446.039996 samples/sec loss: -31.52933 acc: 0.69694 ce: 0.84892 lat: -16.18912
[33mIP:10.60.242.134 [0m[32m[0229 16:20:03 @trainer.py:198][0m Epoch[79] Batch[400] Speed: 429.264096 samples/sec loss: -31.52989 acc: 0.69715 ce: 0.84836 lat: -16.18913
[33mIP:10.60.242.134 [0m[32m[0229 16:20:18 @trainer.py:198][0m Epoch[79] Batch[500] Speed: 426.058512 samples/sec loss: -31.53042 acc: 0.69736 ce: 0.84784 lat: -16.18913
[33mIP:10.60.242.134 [0m[32m[0229 16:20:33 @trainer.py:198][0m Epoch[79] Batch[600] Speed: 414.941395 samples/sec loss: -31.53097 acc: 0.69755 ce: 0.84729 lat: -16.18913
[33mIP:10.60.242.134 [0m[32m[0229 16:20:37 @trainer.py:173][0m Change temperature from 0.15640 to 0.14952
[33mIP:10.60.242.134 [0m[32m[0229 16:20:41 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:20:41 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76]
[33mIP:10.60.242.134 [0m[32m[0229 16:20:41 @trainer.py:234][0m acc 0.76
[33mIP:10.60.242.134 [0m[32m[0229 16:20:41 @trainer.py:235][0m max_acc 0.7606
[33mIP:10.60.242.134 [0m[32m[0229 16:20:41 @trainer.py:217][0m Start to train w for epoch 80
[33mIP:10.60.242.134 [0m[32m[0229 16:20:41 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:20:56 @trainer.py:198][0m Epoch[80] Batch[100] Speed: 278.678499 samples/sec loss: -31.53162 acc: 0.69779 ce: 0.84664 lat: -16.18913
[33mIP:10.60.242.134 [0m[32m[0229 16:21:12 @trainer.py:198][0m Epoch[80] Batch[200] Speed: 407.498401 samples/sec loss: -31.53217 acc: 0.69799 ce: 0.84610 lat: -16.18913
[33mIP:10.60.242.134 [0m[32m[0229 16:21:28 @trainer.py:198][0m Epoch[80] Batch[300] Speed: 401.215576 samples/sec loss: -31.53273 acc: 0.69820 ce: 0.84554 lat: -16.18913
[33mIP:10.60.242.134 [0m[32m[0229 16:21:43 @trainer.py:198][0m Epoch[80] Batch[400] Speed: 415.727991 samples/sec loss: -31.53330 acc: 0.69841 ce: 0.84497 lat: -16.18913
[33mIP:10.60.242.134 [0m[32m[0229 16:21:58 @trainer.py:198][0m Epoch[80] Batch[500] Speed: 445.124414 samples/sec loss: -31.53385 acc: 0.69861 ce: 0.84442 lat: -16.18914
[33mIP:10.60.242.134 [0m[32m[0229 16:22:13 @trainer.py:198][0m Epoch[80] Batch[600] Speed: 434.938859 samples/sec loss: -31.53443 acc: 0.69881 ce: 0.84385 lat: -16.18914
[33mIP:10.60.242.134 [0m[32m[0229 16:22:16 @trainer.py:173][0m Change temperature from 0.14952 to 0.14294
[33mIP:10.60.242.134 [0m[32m[0229 16:22:21 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:22:21 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588]
[33mIP:10.60.242.134 [0m[32m[0229 16:22:21 @trainer.py:234][0m acc 0.7588
[33mIP:10.60.242.134 [0m[32m[0229 16:22:21 @trainer.py:235][0m max_acc 0.7606
[33mIP:10.60.242.134 [0m[32m[0229 16:22:21 @trainer.py:217][0m Start to train w for epoch 81
[33mIP:10.60.242.134 [0m[32m[0229 16:22:21 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:22:36 @trainer.py:198][0m Epoch[81] Batch[100] Speed: 276.707411 samples/sec loss: -31.53514 acc: 0.69907 ce: 0.84314 lat: -16.18914
[33mIP:10.60.242.134 [0m[32m[0229 16:22:51 @trainer.py:198][0m Epoch[81] Batch[200] Speed: 421.385715 samples/sec loss: -31.53574 acc: 0.69930 ce: 0.84254 lat: -16.18914
[33mIP:10.60.242.134 [0m[32m[0229 16:23:06 @trainer.py:198][0m Epoch[81] Batch[300] Speed: 411.109990 samples/sec loss: -31.53629 acc: 0.69950 ce: 0.84199 lat: -16.18914
[33mIP:10.60.242.134 [0m[32m[0229 16:23:22 @trainer.py:198][0m Epoch[81] Batch[400] Speed: 405.455771 samples/sec loss: -31.53682 acc: 0.69969 ce: 0.84147 lat: -16.18914
[33mIP:10.60.242.134 [0m[32m[0229 16:23:38 @trainer.py:198][0m Epoch[81] Batch[500] Speed: 407.358292 samples/sec loss: -31.53733 acc: 0.69987 ce: 0.84096 lat: -16.18915
[33mIP:10.60.242.134 [0m[32m[0229 16:23:54 @trainer.py:198][0m Epoch[81] Batch[600] Speed: 408.193683 samples/sec loss: -31.53787 acc: 0.70006 ce: 0.84042 lat: -16.18915
[33mIP:10.60.242.134 [0m[32m[0229 16:23:57 @trainer.py:173][0m Change temperature from 0.14294 to 0.13665
[33mIP:10.60.242.134 [0m[32m[0229 16:24:01 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:24:01 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646]
[33mIP:10.60.242.134 [0m[32m[0229 16:24:01 @trainer.py:234][0m acc 0.7646
[33mIP:10.60.242.134 [0m[32m[0229 16:24:01 @trainer.py:235][0m max_acc 0.7646
[33mIP:10.60.242.134 [0m[32m[0229 16:24:01 @trainer.py:217][0m Start to train w for epoch 82
[33mIP:10.60.242.134 [0m[32m[0229 16:24:01 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:24:16 @trainer.py:198][0m Epoch[82] Batch[100] Speed: 282.155742 samples/sec loss: -31.53859 acc: 0.70032 ce: 0.83971 lat: -16.18915
[33mIP:10.60.242.134 [0m[32m[0229 16:24:30 @trainer.py:198][0m Epoch[82] Batch[200] Speed: 456.847658 samples/sec loss: -31.53914 acc: 0.70052 ce: 0.83916 lat: -16.18915
[33mIP:10.60.242.134 [0m[32m[0229 16:24:46 @trainer.py:198][0m Epoch[82] Batch[300] Speed: 420.872203 samples/sec loss: -31.53972 acc: 0.70073 ce: 0.83859 lat: -16.18915
[33mIP:10.60.242.134 [0m[32m[0229 16:25:01 @trainer.py:198][0m Epoch[82] Batch[400] Speed: 416.056049 samples/sec loss: -31.54027 acc: 0.70093 ce: 0.83804 lat: -16.18915
[33mIP:10.60.242.134 [0m[32m[0229 16:25:16 @trainer.py:198][0m Epoch[82] Batch[500] Speed: 428.345843 samples/sec loss: -31.54082 acc: 0.70113 ce: 0.83749 lat: -16.18915
[33mIP:10.60.242.134 [0m[32m[0229 16:25:31 @trainer.py:198][0m Epoch[82] Batch[600] Speed: 436.009519 samples/sec loss: -31.54138 acc: 0.70133 ce: 0.83693 lat: -16.18916
[33mIP:10.60.242.134 [0m[32m[0229 16:25:34 @trainer.py:173][0m Change temperature from 0.13665 to 0.13063
[33mIP:10.60.242.134 [0m[32m[0229 16:25:39 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:25:39 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638]
[33mIP:10.60.242.134 [0m[32m[0229 16:25:39 @trainer.py:234][0m acc 0.7638
[33mIP:10.60.242.134 [0m[32m[0229 16:25:39 @trainer.py:235][0m max_acc 0.7646
[33mIP:10.60.242.134 [0m[32m[0229 16:25:39 @trainer.py:217][0m Start to train w for epoch 83
[33mIP:10.60.242.134 [0m[32m[0229 16:25:39 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:25:55 @trainer.py:198][0m Epoch[83] Batch[100] Speed: 261.961394 samples/sec loss: -31.54207 acc: 0.70158 ce: 0.83625 lat: -16.18916
[33mIP:10.60.242.134 [0m[32m[0229 16:26:11 @trainer.py:198][0m Epoch[83] Batch[200] Speed: 410.106789 samples/sec loss: -31.54264 acc: 0.70179 ce: 0.83567 lat: -16.18916
[33mIP:10.60.242.134 [0m[32m[0229 16:26:26 @trainer.py:198][0m Epoch[83] Batch[300] Speed: 409.904783 samples/sec loss: -31.54320 acc: 0.70199 ce: 0.83512 lat: -16.18916
[33mIP:10.60.242.134 [0m[32m[0229 16:26:41 @trainer.py:198][0m Epoch[83] Batch[400] Speed: 419.359450 samples/sec loss: -31.54375 acc: 0.70220 ce: 0.83457 lat: -16.18916
[33mIP:10.60.242.134 [0m[32m[0229 16:26:57 @trainer.py:198][0m Epoch[83] Batch[500] Speed: 405.618611 samples/sec loss: -31.54430 acc: 0.70239 ce: 0.83402 lat: -16.18916
[33mIP:10.60.242.134 [0m[32m[0229 16:27:12 @trainer.py:198][0m Epoch[83] Batch[600] Speed: 444.034725 samples/sec loss: -31.54483 acc: 0.70259 ce: 0.83350 lat: -16.18916
[33mIP:10.60.242.134 [0m[32m[0229 16:27:15 @trainer.py:173][0m Change temperature from 0.13063 to 0.12489
[33mIP:10.60.242.134 [0m[32m[0229 16:27:19 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:27:19 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648]
[33mIP:10.60.242.134 [0m[32m[0229 16:27:19 @trainer.py:234][0m acc 0.7648
[33mIP:10.60.242.134 [0m[32m[0229 16:27:19 @trainer.py:235][0m max_acc 0.7648
[33mIP:10.60.242.134 [0m[32m[0229 16:27:19 @trainer.py:217][0m Start to train w for epoch 84
[33mIP:10.60.242.134 [0m[32m[0229 16:27:19 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:27:36 @trainer.py:198][0m Epoch[84] Batch[100] Speed: 265.209993 samples/sec loss: -31.54557 acc: 0.70286 ce: 0.83276 lat: -16.18917
[33mIP:10.60.242.134 [0m[32m[0229 16:27:52 @trainer.py:198][0m Epoch[84] Batch[200] Speed: 400.449220 samples/sec loss: -31.54609 acc: 0.70304 ce: 0.83224 lat: -16.18917
[33mIP:10.60.242.134 [0m[32m[0229 16:28:08 @trainer.py:198][0m Epoch[84] Batch[300] Speed: 405.491050 samples/sec loss: -31.54664 acc: 0.70324 ce: 0.83169 lat: -16.18917
[33mIP:10.60.242.134 [0m[32m[0229 16:28:23 @trainer.py:198][0m Epoch[84] Batch[400] Speed: 402.710894 samples/sec loss: -31.54721 acc: 0.70346 ce: 0.83113 lat: -16.18917
[33mIP:10.60.242.134 [0m[32m[0229 16:28:39 @trainer.py:198][0m Epoch[84] Batch[500] Speed: 421.837431 samples/sec loss: -31.54778 acc: 0.70367 ce: 0.83057 lat: -16.18917
[33mIP:10.60.242.134 [0m[32m[0229 16:28:54 @trainer.py:198][0m Epoch[84] Batch[600] Speed: 423.598283 samples/sec loss: -31.54829 acc: 0.70385 ce: 0.83005 lat: -16.18917
[33mIP:10.60.242.134 [0m[32m[0229 16:28:57 @trainer.py:173][0m Change temperature from 0.12489 to 0.11939
[33mIP:10.60.242.134 [0m[32m[0229 16:29:01 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:29:01 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761]
[33mIP:10.60.242.134 [0m[32m[0229 16:29:01 @trainer.py:234][0m acc 0.761
[33mIP:10.60.242.134 [0m[32m[0229 16:29:01 @trainer.py:235][0m max_acc 0.7648
[33mIP:10.60.242.134 [0m[32m[0229 16:29:01 @trainer.py:217][0m Start to train w for epoch 85
[33mIP:10.60.242.134 [0m[32m[0229 16:29:01 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:29:16 @trainer.py:198][0m Epoch[85] Batch[100] Speed: 289.400387 samples/sec loss: -31.54901 acc: 0.70410 ce: 0.82934 lat: -16.18917
[33mIP:10.60.242.134 [0m[32m[0229 16:29:31 @trainer.py:198][0m Epoch[85] Batch[200] Speed: 411.725491 samples/sec loss: -31.54959 acc: 0.70432 ce: 0.82876 lat: -16.18918
[33mIP:10.60.242.134 [0m[32m[0229 16:29:47 @trainer.py:198][0m Epoch[85] Batch[300] Speed: 417.802895 samples/sec loss: -31.55016 acc: 0.70453 ce: 0.82820 lat: -16.18918
[33mIP:10.60.242.134 [0m[32m[0229 16:30:03 @trainer.py:198][0m Epoch[85] Batch[400] Speed: 405.104500 samples/sec loss: -31.55071 acc: 0.70472 ce: 0.82765 lat: -16.18918
[33mIP:10.60.242.134 [0m[32m[0229 16:30:17 @trainer.py:198][0m Epoch[85] Batch[500] Speed: 431.897784 samples/sec loss: -31.55125 acc: 0.70493 ce: 0.82711 lat: -16.18918
[33mIP:10.60.242.134 [0m[32m[0229 16:30:33 @trainer.py:198][0m Epoch[85] Batch[600] Speed: 413.391098 samples/sec loss: -31.55176 acc: 0.70512 ce: 0.82660 lat: -16.18918
[33mIP:10.60.242.134 [0m[32m[0229 16:30:37 @trainer.py:173][0m Change temperature from 0.11939 to 0.11414
[33mIP:10.60.242.134 [0m[32m[0229 16:30:40 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:30:40 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77]
[33mIP:10.60.242.134 [0m[32m[0229 16:30:40 @trainer.py:234][0m acc 0.77
[33mIP:10.60.242.134 [0m[32m[0229 16:30:40 @trainer.py:235][0m max_acc 0.77
[33mIP:10.60.242.134 [0m[32m[0229 16:30:40 @trainer.py:217][0m Start to train w for epoch 86
[33mIP:10.60.242.134 [0m[32m[0229 16:30:40 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:30:57 @trainer.py:198][0m Epoch[86] Batch[100] Speed: 269.016542 samples/sec loss: -31.55247 acc: 0.70537 ce: 0.82589 lat: -16.18918
[33mIP:10.60.242.134 [0m[32m[0229 16:31:13 @trainer.py:198][0m Epoch[86] Batch[200] Speed: 402.508677 samples/sec loss: -31.55305 acc: 0.70559 ce: 0.82532 lat: -16.18918
[33mIP:10.60.242.134 [0m[32m[0229 16:31:28 @trainer.py:198][0m Epoch[86] Batch[300] Speed: 405.314530 samples/sec loss: -31.55358 acc: 0.70578 ce: 0.82479 lat: -16.18919
[33mIP:10.60.242.134 [0m[32m[0229 16:31:44 @trainer.py:198][0m Epoch[86] Batch[400] Speed: 406.944892 samples/sec loss: -31.55413 acc: 0.70599 ce: 0.82425 lat: -16.18919
[33mIP:10.60.242.134 [0m[32m[0229 16:31:59 @trainer.py:198][0m Epoch[86] Batch[500] Speed: 419.329649 samples/sec loss: -31.55472 acc: 0.70621 ce: 0.82365 lat: -16.18919
[33mIP:10.60.242.134 [0m[32m[0229 16:32:14 @trainer.py:198][0m Epoch[86] Batch[600] Speed: 438.051397 samples/sec loss: -31.55525 acc: 0.70641 ce: 0.82313 lat: -16.18919
[33mIP:10.60.242.134 [0m[32m[0229 16:32:18 @trainer.py:173][0m Change temperature from 0.11414 to 0.10912
[33mIP:10.60.242.134 [0m[32m[0229 16:32:21 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:32:21 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652]
[33mIP:10.60.242.134 [0m[32m[0229 16:32:21 @trainer.py:234][0m acc 0.7652
[33mIP:10.60.242.134 [0m[32m[0229 16:32:21 @trainer.py:235][0m max_acc 0.77
[33mIP:10.60.242.134 [0m[32m[0229 16:32:21 @trainer.py:217][0m Start to train w for epoch 87
[33mIP:10.60.242.134 [0m[32m[0229 16:32:21 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:32:37 @trainer.py:198][0m Epoch[87] Batch[100] Speed: 279.696959 samples/sec loss: -31.55595 acc: 0.70665 ce: 0.82243 lat: -16.18919
[33mIP:10.60.242.134 [0m[32m[0229 16:32:53 @trainer.py:198][0m Epoch[87] Batch[200] Speed: 403.301412 samples/sec loss: -31.55654 acc: 0.70687 ce: 0.82185 lat: -16.18919
[33mIP:10.60.242.134 [0m[32m[0229 16:33:09 @trainer.py:198][0m Epoch[87] Batch[300] Speed: 401.949479 samples/sec loss: -31.55708 acc: 0.70707 ce: 0.82131 lat: -16.18919
[33mIP:10.60.242.134 [0m[32m[0229 16:33:24 @trainer.py:198][0m Epoch[87] Batch[400] Speed: 403.230550 samples/sec loss: -31.55760 acc: 0.70725 ce: 0.82078 lat: -16.18919
[33mIP:10.60.242.134 [0m[32m[0229 16:33:40 @trainer.py:198][0m Epoch[87] Batch[500] Speed: 410.108819 samples/sec loss: -31.55815 acc: 0.70745 ce: 0.82024 lat: -16.18920
[33mIP:10.60.242.134 [0m[32m[0229 16:33:55 @trainer.py:198][0m Epoch[87] Batch[600] Speed: 443.453935 samples/sec loss: -31.55871 acc: 0.70766 ce: 0.81968 lat: -16.18920
[33mIP:10.60.242.134 [0m[32m[0229 16:33:58 @trainer.py:173][0m Change temperature from 0.10912 to 0.10432
[33mIP:10.60.242.134 [0m[32m[0229 16:34:02 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:34:02 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698]
[33mIP:10.60.242.134 [0m[32m[0229 16:34:02 @trainer.py:234][0m acc 0.7698
[33mIP:10.60.242.134 [0m[32m[0229 16:34:02 @trainer.py:235][0m max_acc 0.77
[33mIP:10.60.242.134 [0m[32m[0229 16:34:02 @trainer.py:217][0m Start to train w for epoch 88
[33mIP:10.60.242.134 [0m[32m[0229 16:34:02 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:34:18 @trainer.py:198][0m Epoch[88] Batch[100] Speed: 274.058887 samples/sec loss: -31.55941 acc: 0.70791 ce: 0.81899 lat: -16.18920
[33mIP:10.60.242.134 [0m[32m[0229 16:34:33 @trainer.py:198][0m Epoch[88] Batch[200] Speed: 409.444759 samples/sec loss: -31.55997 acc: 0.70812 ce: 0.81842 lat: -16.18920
[33mIP:10.60.242.134 [0m[32m[0229 16:34:49 @trainer.py:198][0m Epoch[88] Batch[300] Speed: 417.320726 samples/sec loss: -31.56054 acc: 0.70832 ce: 0.81786 lat: -16.18920
[33mIP:10.60.242.134 [0m[32m[0229 16:35:04 @trainer.py:198][0m Epoch[88] Batch[400] Speed: 412.977288 samples/sec loss: -31.56110 acc: 0.70852 ce: 0.81730 lat: -16.18920
[33mIP:10.60.242.134 [0m[32m[0229 16:35:20 @trainer.py:198][0m Epoch[88] Batch[500] Speed: 420.435484 samples/sec loss: -31.56164 acc: 0.70871 ce: 0.81676 lat: -16.18920
[33mIP:10.60.242.134 [0m[32m[0229 16:35:35 @trainer.py:198][0m Epoch[88] Batch[600] Speed: 417.767425 samples/sec loss: -31.56219 acc: 0.70891 ce: 0.81622 lat: -16.18920
[33mIP:10.60.242.134 [0m[32m[0229 16:35:38 @trainer.py:173][0m Change temperature from 0.10432 to 0.09973
[33mIP:10.60.242.134 [0m[32m[0229 16:35:43 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:35:43 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774]
[33mIP:10.60.242.134 [0m[32m[0229 16:35:43 @trainer.py:234][0m acc 0.774
[33mIP:10.60.242.134 [0m[32m[0229 16:35:43 @trainer.py:235][0m max_acc 0.774
[33mIP:10.60.242.134 [0m[32m[0229 16:35:43 @trainer.py:217][0m Start to train w for epoch 89
[33mIP:10.60.242.134 [0m[32m[0229 16:35:43 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:35:58 @trainer.py:198][0m Epoch[89] Batch[100] Speed: 271.474713 samples/sec loss: -31.56293 acc: 0.70918 ce: 0.81548 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:36:13 @trainer.py:198][0m Epoch[89] Batch[200] Speed: 439.363779 samples/sec loss: -31.56351 acc: 0.70939 ce: 0.81490 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:36:28 @trainer.py:198][0m Epoch[89] Batch[300] Speed: 417.487738 samples/sec loss: -31.56407 acc: 0.70960 ce: 0.81434 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:36:44 @trainer.py:198][0m Epoch[89] Batch[400] Speed: 414.001067 samples/sec loss: -31.56462 acc: 0.70978 ce: 0.81380 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:37:00 @trainer.py:198][0m Epoch[89] Batch[500] Speed: 406.020495 samples/sec loss: -31.56518 acc: 0.70998 ce: 0.81324 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:37:15 @trainer.py:198][0m Epoch[89] Batch[600] Speed: 426.767724 samples/sec loss: -31.56573 acc: 0.71019 ce: 0.81269 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:37:18 @trainer.py:173][0m Change temperature from 0.09973 to 0.09534
[33mIP:10.60.242.134 [0m[32m[0229 16:37:22 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:37:22 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682]
[33mIP:10.60.242.134 [0m[32m[0229 16:37:22 @trainer.py:234][0m acc 0.7682
[33mIP:10.60.242.134 [0m[32m[0229 16:37:22 @trainer.py:235][0m max_acc 0.774
[33mIP:10.60.242.134 [0m[32m[0229 16:37:22 @trainer.py:217][0m Start to train w for epoch 90
[33mIP:10.60.242.134 [0m[32m[0229 16:37:22 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:37:37 @trainer.py:198][0m Epoch[90] Batch[100] Speed: 281.757598 samples/sec loss: -31.56643 acc: 0.71044 ce: 0.81200 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:37:53 @trainer.py:198][0m Epoch[90] Batch[200] Speed: 418.131572 samples/sec loss: -31.56696 acc: 0.71063 ce: 0.81146 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:38:08 @trainer.py:198][0m Epoch[90] Batch[300] Speed: 416.037923 samples/sec loss: -31.56753 acc: 0.71084 ce: 0.81090 lat: -16.18921
[33mIP:10.60.242.134 [0m[32m[0229 16:38:24 @trainer.py:198][0m Epoch[90] Batch[400] Speed: 409.119277 samples/sec loss: -31.56809 acc: 0.71104 ce: 0.81034 lat: -16.18922
[33mIP:10.60.242.134 [0m[32m[0229 16:38:39 @trainer.py:198][0m Epoch[90] Batch[500] Speed: 422.666047 samples/sec loss: -31.56865 acc: 0.71124 ce: 0.80978 lat: -16.18922
[33mIP:10.60.242.134 [0m[32m[0229 16:38:54 @trainer.py:198][0m Epoch[90] Batch[600] Speed: 433.154403 samples/sec loss: -31.56919 acc: 0.71144 ce: 0.80925 lat: -16.18922
[33mIP:10.60.242.134 [0m[32m[0229 16:38:57 @trainer.py:173][0m Change temperature from 0.09534 to 0.09114
[33mIP:10.60.242.134 [0m[32m[0229 16:39:00 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:39:00 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686]
[33mIP:10.60.242.134 [0m[32m[0229 16:39:00 @trainer.py:234][0m acc 0.7686
[33mIP:10.60.242.134 [0m[32m[0229 16:39:00 @trainer.py:235][0m max_acc 0.774
[33mIP:10.60.242.134 [0m[32m[0229 16:39:00 @trainer.py:217][0m Start to train w for epoch 91
[33mIP:10.60.242.134 [0m[32m[0229 16:39:00 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:39:17 @trainer.py:198][0m Epoch[91] Batch[100] Speed: 276.195889 samples/sec loss: -31.56993 acc: 0.71170 ce: 0.80851 lat: -16.18922
[33mIP:10.60.242.134 [0m[32m[0229 16:39:32 @trainer.py:198][0m Epoch[91] Batch[200] Speed: 408.979921 samples/sec loss: -31.57051 acc: 0.71191 ce: 0.80793 lat: -16.18922
[33mIP:10.60.242.134 [0m[32m[0229 16:39:48 @trainer.py:198][0m Epoch[91] Batch[300] Speed: 413.887898 samples/sec loss: -31.57107 acc: 0.71211 ce: 0.80737 lat: -16.18922
[33mIP:10.60.242.134 [0m[32m[0229 16:40:04 @trainer.py:198][0m Epoch[91] Batch[400] Speed: 395.861575 samples/sec loss: -31.57161 acc: 0.71230 ce: 0.80684 lat: -16.18922
[33mIP:10.60.242.134 [0m[32m[0229 16:40:20 @trainer.py:198][0m Epoch[91] Batch[500] Speed: 403.969995 samples/sec loss: -31.57215 acc: 0.71250 ce: 0.80629 lat: -16.18922
[33mIP:10.60.242.134 [0m[32m[0229 16:40:36 @trainer.py:198][0m Epoch[91] Batch[600] Speed: 403.791650 samples/sec loss: -31.57271 acc: 0.71270 ce: 0.80574 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:40:39 @trainer.py:173][0m Change temperature from 0.09114 to 0.08713
[33mIP:10.60.242.134 [0m[32m[0229 16:40:43 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:40:43 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836]
[33mIP:10.60.242.134 [0m[32m[0229 16:40:43 @trainer.py:234][0m acc 0.7836
[33mIP:10.60.242.134 [0m[32m[0229 16:40:43 @trainer.py:235][0m max_acc 0.7836
[33mIP:10.60.242.134 [0m[32m[0229 16:40:43 @trainer.py:217][0m Start to train w for epoch 92
[33mIP:10.60.242.134 [0m[32m[0229 16:40:43 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:41:00 @trainer.py:198][0m Epoch[92] Batch[100] Speed: 264.084950 samples/sec loss: -31.57342 acc: 0.71296 ce: 0.80504 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:41:16 @trainer.py:198][0m Epoch[92] Batch[200] Speed: 402.678798 samples/sec loss: -31.57402 acc: 0.71318 ce: 0.80444 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:41:31 @trainer.py:198][0m Epoch[92] Batch[300] Speed: 408.880472 samples/sec loss: -31.57457 acc: 0.71338 ce: 0.80388 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:41:47 @trainer.py:198][0m Epoch[92] Batch[400] Speed: 401.814128 samples/sec loss: -31.57512 acc: 0.71357 ce: 0.80334 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:42:03 @trainer.py:198][0m Epoch[92] Batch[500] Speed: 405.083598 samples/sec loss: -31.57569 acc: 0.71379 ce: 0.80277 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:42:19 @trainer.py:198][0m Epoch[92] Batch[600] Speed: 406.585993 samples/sec loss: -31.57624 acc: 0.71398 ce: 0.80222 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:42:23 @trainer.py:173][0m Change temperature from 0.08713 to 0.08330
[33mIP:10.60.242.134 [0m[32m[0229 16:42:26 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:42:26 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773]
[33mIP:10.60.242.134 [0m[32m[0229 16:42:26 @trainer.py:234][0m acc 0.773
[33mIP:10.60.242.134 [0m[32m[0229 16:42:26 @trainer.py:235][0m max_acc 0.7836
[33mIP:10.60.242.134 [0m[32m[0229 16:42:26 @trainer.py:217][0m Start to train w for epoch 93
[33mIP:10.60.242.134 [0m[32m[0229 16:42:26 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:42:42 @trainer.py:198][0m Epoch[93] Batch[100] Speed: 274.955394 samples/sec loss: -31.57696 acc: 0.71424 ce: 0.80150 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:42:58 @trainer.py:198][0m Epoch[93] Batch[200] Speed: 402.435927 samples/sec loss: -31.57755 acc: 0.71445 ce: 0.80092 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:43:14 @trainer.py:198][0m Epoch[93] Batch[300] Speed: 407.869907 samples/sec loss: -31.57809 acc: 0.71465 ce: 0.80038 lat: -16.18923
[33mIP:10.60.242.134 [0m[32m[0229 16:43:30 @trainer.py:198][0m Epoch[93] Batch[400] Speed: 390.753342 samples/sec loss: -31.57865 acc: 0.71486 ce: 0.79982 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:43:46 @trainer.py:198][0m Epoch[93] Batch[500] Speed: 400.140806 samples/sec loss: -31.57916 acc: 0.71505 ce: 0.79932 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:44:02 @trainer.py:198][0m Epoch[93] Batch[600] Speed: 413.174353 samples/sec loss: -31.57968 acc: 0.71524 ce: 0.79879 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:44:06 @trainer.py:173][0m Change temperature from 0.08330 to 0.07963
[33mIP:10.60.242.134 [0m[32m[0229 16:44:09 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:44:09 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832]
[33mIP:10.60.242.134 [0m[32m[0229 16:44:09 @trainer.py:234][0m acc 0.7832
[33mIP:10.60.242.134 [0m[32m[0229 16:44:09 @trainer.py:235][0m max_acc 0.7836
[33mIP:10.60.242.134 [0m[32m[0229 16:44:09 @trainer.py:217][0m Start to train w for epoch 94
[33mIP:10.60.242.134 [0m[32m[0229 16:44:09 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:44:26 @trainer.py:198][0m Epoch[94] Batch[100] Speed: 264.365369 samples/sec loss: -31.58042 acc: 0.71550 ce: 0.79806 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:44:42 @trainer.py:198][0m Epoch[94] Batch[200] Speed: 409.550525 samples/sec loss: -31.58097 acc: 0.71570 ce: 0.79751 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:44:57 @trainer.py:198][0m Epoch[94] Batch[300] Speed: 412.406505 samples/sec loss: -31.58155 acc: 0.71591 ce: 0.79693 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:45:13 @trainer.py:198][0m Epoch[94] Batch[400] Speed: 412.879010 samples/sec loss: -31.58213 acc: 0.71612 ce: 0.79636 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:45:28 @trainer.py:198][0m Epoch[94] Batch[500] Speed: 410.335424 samples/sec loss: -31.58265 acc: 0.71631 ce: 0.79584 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:45:44 @trainer.py:198][0m Epoch[94] Batch[600] Speed: 415.461541 samples/sec loss: -31.58320 acc: 0.71651 ce: 0.79529 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:45:47 @trainer.py:173][0m Change temperature from 0.07963 to 0.07613
[33mIP:10.60.242.134 [0m[32m[0229 16:45:51 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:45:51 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776]
[33mIP:10.60.242.134 [0m[32m[0229 16:45:51 @trainer.py:234][0m acc 0.7776
[33mIP:10.60.242.134 [0m[32m[0229 16:45:51 @trainer.py:235][0m max_acc 0.7836
[33mIP:10.60.242.134 [0m[32m[0229 16:45:51 @trainer.py:217][0m Start to train w for epoch 95
[33mIP:10.60.242.134 [0m[32m[0229 16:45:51 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:46:07 @trainer.py:198][0m Epoch[95] Batch[100] Speed: 273.489977 samples/sec loss: -31.58389 acc: 0.71676 ce: 0.79460 lat: -16.18924
[33mIP:10.60.242.134 [0m[32m[0229 16:46:23 @trainer.py:198][0m Epoch[95] Batch[200] Speed: 402.770974 samples/sec loss: -31.58442 acc: 0.71696 ce: 0.79407 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:46:38 @trainer.py:198][0m Epoch[95] Batch[300] Speed: 423.471576 samples/sec loss: -31.58501 acc: 0.71717 ce: 0.79349 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:46:53 @trainer.py:198][0m Epoch[95] Batch[400] Speed: 417.195211 samples/sec loss: -31.58556 acc: 0.71737 ce: 0.79294 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:47:09 @trainer.py:198][0m Epoch[95] Batch[500] Speed: 417.398712 samples/sec loss: -31.58611 acc: 0.71758 ce: 0.79238 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:47:22 @trainer.py:198][0m Epoch[95] Batch[600] Speed: 468.808784 samples/sec loss: -31.58668 acc: 0.71778 ce: 0.79182 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:47:26 @trainer.py:173][0m Change temperature from 0.07613 to 0.07278
[33mIP:10.60.242.134 [0m[32m[0229 16:47:29 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:47:29 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874]
[33mIP:10.60.242.134 [0m[32m[0229 16:47:29 @trainer.py:234][0m acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:47:29 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:47:29 @trainer.py:217][0m Start to train w for epoch 96
[33mIP:10.60.242.134 [0m[32m[0229 16:47:29 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:47:45 @trainer.py:198][0m Epoch[96] Batch[100] Speed: 284.062847 samples/sec loss: -31.58741 acc: 0.71804 ce: 0.79109 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:47:59 @trainer.py:198][0m Epoch[96] Batch[200] Speed: 453.611309 samples/sec loss: -31.58795 acc: 0.71823 ce: 0.79055 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:48:14 @trainer.py:198][0m Epoch[96] Batch[300] Speed: 425.932114 samples/sec loss: -31.58852 acc: 0.71843 ce: 0.78998 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:48:30 @trainer.py:198][0m Epoch[96] Batch[400] Speed: 408.029538 samples/sec loss: -31.58909 acc: 0.71865 ce: 0.78941 lat: -16.18925
[33mIP:10.60.242.134 [0m[32m[0229 16:48:45 @trainer.py:198][0m Epoch[96] Batch[500] Speed: 422.665049 samples/sec loss: -31.58967 acc: 0.71886 ce: 0.78884 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:49:00 @trainer.py:198][0m Epoch[96] Batch[600] Speed: 426.847495 samples/sec loss: -31.59019 acc: 0.71905 ce: 0.78832 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:49:03 @trainer.py:173][0m Change temperature from 0.07278 to 0.06958
[33mIP:10.60.242.134 [0m[32m[0229 16:49:07 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:49:07 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797]
[33mIP:10.60.242.134 [0m[32m[0229 16:49:07 @trainer.py:234][0m acc 0.7797
[33mIP:10.60.242.134 [0m[32m[0229 16:49:07 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:49:07 @trainer.py:217][0m Start to train w for epoch 97
[33mIP:10.60.242.134 [0m[32m[0229 16:49:07 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:49:22 @trainer.py:198][0m Epoch[97] Batch[100] Speed: 286.185722 samples/sec loss: -31.59091 acc: 0.71930 ce: 0.78760 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:49:38 @trainer.py:198][0m Epoch[97] Batch[200] Speed: 415.018969 samples/sec loss: -31.59148 acc: 0.71950 ce: 0.78703 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:49:53 @trainer.py:198][0m Epoch[97] Batch[300] Speed: 415.911219 samples/sec loss: -31.59206 acc: 0.71971 ce: 0.78646 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:50:09 @trainer.py:198][0m Epoch[97] Batch[400] Speed: 410.933905 samples/sec loss: -31.59259 acc: 0.71991 ce: 0.78592 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:50:24 @trainer.py:198][0m Epoch[97] Batch[500] Speed: 419.575698 samples/sec loss: -31.59315 acc: 0.72011 ce: 0.78537 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:50:39 @trainer.py:198][0m Epoch[97] Batch[600] Speed: 431.618018 samples/sec loss: -31.59370 acc: 0.72031 ce: 0.78482 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:50:42 @trainer.py:173][0m Change temperature from 0.06958 to 0.06652
[33mIP:10.60.242.134 [0m[32m[0229 16:50:46 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:50:46 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829]
[33mIP:10.60.242.134 [0m[32m[0229 16:50:46 @trainer.py:234][0m acc 0.7829
[33mIP:10.60.242.134 [0m[32m[0229 16:50:46 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:50:46 @trainer.py:217][0m Start to train w for epoch 98
[33mIP:10.60.242.134 [0m[32m[0229 16:50:46 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:51:01 @trainer.py:198][0m Epoch[98] Batch[100] Speed: 282.646843 samples/sec loss: -31.59441 acc: 0.72056 ce: 0.78412 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:51:16 @trainer.py:198][0m Epoch[98] Batch[200] Speed: 432.467400 samples/sec loss: -31.59498 acc: 0.72077 ce: 0.78354 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:51:31 @trainer.py:198][0m Epoch[98] Batch[300] Speed: 419.685693 samples/sec loss: -31.59554 acc: 0.72097 ce: 0.78299 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:51:47 @trainer.py:198][0m Epoch[98] Batch[400] Speed: 411.421079 samples/sec loss: -31.59608 acc: 0.72116 ce: 0.78245 lat: -16.18926
[33mIP:10.60.242.134 [0m[32m[0229 16:52:02 @trainer.py:198][0m Epoch[98] Batch[500] Speed: 417.514413 samples/sec loss: -31.59663 acc: 0.72136 ce: 0.78190 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:52:17 @trainer.py:198][0m Epoch[98] Batch[600] Speed: 421.136463 samples/sec loss: -31.59718 acc: 0.72156 ce: 0.78135 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:52:21 @trainer.py:173][0m Change temperature from 0.06652 to 0.06359
[33mIP:10.60.242.134 [0m[32m[0229 16:52:25 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:52:25 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844]
[33mIP:10.60.242.134 [0m[32m[0229 16:52:25 @trainer.py:234][0m acc 0.7844
[33mIP:10.60.242.134 [0m[32m[0229 16:52:25 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:52:25 @trainer.py:217][0m Start to train w for epoch 99
[33mIP:10.60.242.134 [0m[32m[0229 16:52:25 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:52:41 @trainer.py:198][0m Epoch[99] Batch[100] Speed: 266.035739 samples/sec loss: -31.59789 acc: 0.72182 ce: 0.78064 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:52:56 @trainer.py:198][0m Epoch[99] Batch[200] Speed: 431.437633 samples/sec loss: -31.59848 acc: 0.72203 ce: 0.78005 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:53:10 @trainer.py:198][0m Epoch[99] Batch[300] Speed: 458.814021 samples/sec loss: -31.59906 acc: 0.72223 ce: 0.77948 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:53:25 @trainer.py:198][0m Epoch[99] Batch[400] Speed: 424.826406 samples/sec loss: -31.59959 acc: 0.72243 ce: 0.77895 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:53:40 @trainer.py:198][0m Epoch[99] Batch[500] Speed: 422.849795 samples/sec loss: -31.60016 acc: 0.72264 ce: 0.77838 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:53:56 @trainer.py:198][0m Epoch[99] Batch[600] Speed: 424.371356 samples/sec loss: -31.60070 acc: 0.72283 ce: 0.77785 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:53:59 @trainer.py:173][0m Change temperature from 0.06359 to 0.06079
[33mIP:10.60.242.134 [0m[32m[0229 16:54:02 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:54:02 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857]
[33mIP:10.60.242.134 [0m[32m[0229 16:54:02 @trainer.py:234][0m acc 0.7857
[33mIP:10.60.242.134 [0m[32m[0229 16:54:02 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:54:02 @trainer.py:217][0m Start to train w for epoch 100
[33mIP:10.60.242.134 [0m[32m[0229 16:54:02 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:54:19 @trainer.py:198][0m Epoch[100] Batch[100] Speed: 278.146081 samples/sec loss: -31.60139 acc: 0.72307 ce: 0.77715 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:54:35 @trainer.py:198][0m Epoch[100] Batch[200] Speed: 398.700343 samples/sec loss: -31.60198 acc: 0.72328 ce: 0.77656 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:54:50 @trainer.py:198][0m Epoch[100] Batch[300] Speed: 412.263179 samples/sec loss: -31.60253 acc: 0.72348 ce: 0.77602 lat: -16.18927
[33mIP:10.60.242.134 [0m[32m[0229 16:55:05 @trainer.py:198][0m Epoch[100] Batch[400] Speed: 421.868450 samples/sec loss: -31.60309 acc: 0.72368 ce: 0.77546 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:55:21 @trainer.py:198][0m Epoch[100] Batch[500] Speed: 411.037622 samples/sec loss: -31.60362 acc: 0.72387 ce: 0.77493 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:55:36 @trainer.py:198][0m Epoch[100] Batch[600] Speed: 415.977746 samples/sec loss: -31.60419 acc: 0.72407 ce: 0.77437 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:55:40 @trainer.py:173][0m Change temperature from 0.06079 to 0.05812
[33mIP:10.60.242.134 [0m[32m[0229 16:55:43 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:55:43 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775]
[33mIP:10.60.242.134 [0m[32m[0229 16:55:43 @trainer.py:234][0m acc 0.7775
[33mIP:10.60.242.134 [0m[32m[0229 16:55:43 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:55:43 @trainer.py:217][0m Start to train w for epoch 101
[33mIP:10.60.242.134 [0m[32m[0229 16:55:43 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:55:58 @trainer.py:198][0m Epoch[101] Batch[100] Speed: 297.431744 samples/sec loss: -31.60490 acc: 0.72433 ce: 0.77365 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:56:13 @trainer.py:198][0m Epoch[101] Batch[200] Speed: 428.464186 samples/sec loss: -31.60546 acc: 0.72452 ce: 0.77310 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:56:28 @trainer.py:198][0m Epoch[101] Batch[300] Speed: 408.325211 samples/sec loss: -31.60602 acc: 0.72473 ce: 0.77253 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:56:44 @trainer.py:198][0m Epoch[101] Batch[400] Speed: 406.555696 samples/sec loss: -31.60661 acc: 0.72494 ce: 0.77195 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:57:00 @trainer.py:198][0m Epoch[101] Batch[500] Speed: 404.039233 samples/sec loss: -31.60716 acc: 0.72513 ce: 0.77140 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:57:15 @trainer.py:198][0m Epoch[101] Batch[600] Speed: 421.453601 samples/sec loss: -31.60770 acc: 0.72532 ce: 0.77087 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:57:18 @trainer.py:173][0m Change temperature from 0.05812 to 0.05556
[33mIP:10.60.242.134 [0m[32m[0229 16:57:21 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:57:21 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759]
[33mIP:10.60.242.134 [0m[32m[0229 16:57:21 @trainer.py:234][0m acc 0.7759
[33mIP:10.60.242.134 [0m[32m[0229 16:57:21 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:57:21 @trainer.py:217][0m Start to train w for epoch 102
[33mIP:10.60.242.134 [0m[32m[0229 16:57:21 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:57:38 @trainer.py:198][0m Epoch[102] Batch[100] Speed: 281.778390 samples/sec loss: -31.60839 acc: 0.72556 ce: 0.77017 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:57:53 @trainer.py:198][0m Epoch[102] Batch[200] Speed: 412.788948 samples/sec loss: -31.60895 acc: 0.72576 ce: 0.76962 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:58:09 @trainer.py:198][0m Epoch[102] Batch[300] Speed: 405.995931 samples/sec loss: -31.60954 acc: 0.72598 ce: 0.76903 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:58:25 @trainer.py:198][0m Epoch[102] Batch[400] Speed: 411.843831 samples/sec loss: -31.61010 acc: 0.72618 ce: 0.76847 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:58:40 @trainer.py:198][0m Epoch[102] Batch[500] Speed: 414.555198 samples/sec loss: -31.61066 acc: 0.72638 ce: 0.76791 lat: -16.18928
[33mIP:10.60.242.134 [0m[32m[0229 16:58:56 @trainer.py:198][0m Epoch[102] Batch[600] Speed: 412.918647 samples/sec loss: -31.61119 acc: 0.72656 ce: 0.76739 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 16:58:59 @trainer.py:173][0m Change temperature from 0.05556 to 0.05311
[33mIP:10.60.242.134 [0m[32m[0229 16:59:03 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 16:59:03 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868]
[33mIP:10.60.242.134 [0m[32m[0229 16:59:03 @trainer.py:234][0m acc 0.7868
[33mIP:10.60.242.134 [0m[32m[0229 16:59:03 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 16:59:03 @trainer.py:217][0m Start to train w for epoch 103
[33mIP:10.60.242.134 [0m[32m[0229 16:59:03 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 16:59:18 @trainer.py:198][0m Epoch[103] Batch[100] Speed: 282.772252 samples/sec loss: -31.61190 acc: 0.72682 ce: 0.76668 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 16:59:33 @trainer.py:198][0m Epoch[103] Batch[200] Speed: 425.381662 samples/sec loss: -31.61246 acc: 0.72702 ce: 0.76612 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 16:59:49 @trainer.py:198][0m Epoch[103] Batch[300] Speed: 397.911867 samples/sec loss: -31.61304 acc: 0.72722 ce: 0.76554 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:00:05 @trainer.py:198][0m Epoch[103] Batch[400] Speed: 419.209935 samples/sec loss: -31.61357 acc: 0.72742 ce: 0.76500 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:00:20 @trainer.py:198][0m Epoch[103] Batch[500] Speed: 415.748151 samples/sec loss: -31.61412 acc: 0.72762 ce: 0.76446 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:00:36 @trainer.py:198][0m Epoch[103] Batch[600] Speed: 411.821313 samples/sec loss: -31.61464 acc: 0.72780 ce: 0.76394 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:00:39 @trainer.py:173][0m Change temperature from 0.05311 to 0.05078
[33mIP:10.60.242.134 [0m[32m[0229 17:00:42 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:00:42 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827]
[33mIP:10.60.242.134 [0m[32m[0229 17:00:42 @trainer.py:234][0m acc 0.7827
[33mIP:10.60.242.134 [0m[32m[0229 17:00:42 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 17:00:42 @trainer.py:217][0m Start to train w for epoch 104
[33mIP:10.60.242.134 [0m[32m[0229 17:00:42 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:00:59 @trainer.py:198][0m Epoch[104] Batch[100] Speed: 278.865227 samples/sec loss: -31.61535 acc: 0.72806 ce: 0.76323 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:01:14 @trainer.py:198][0m Epoch[104] Batch[200] Speed: 403.292742 samples/sec loss: -31.61591 acc: 0.72826 ce: 0.76267 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:01:30 @trainer.py:198][0m Epoch[104] Batch[300] Speed: 400.369371 samples/sec loss: -31.61649 acc: 0.72846 ce: 0.76210 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:01:46 @trainer.py:198][0m Epoch[104] Batch[400] Speed: 398.216097 samples/sec loss: -31.61706 acc: 0.72866 ce: 0.76153 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:02:02 @trainer.py:198][0m Epoch[104] Batch[500] Speed: 405.525433 samples/sec loss: -31.61761 acc: 0.72887 ce: 0.76098 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:02:18 @trainer.py:198][0m Epoch[104] Batch[600] Speed: 418.165215 samples/sec loss: -31.61813 acc: 0.72906 ce: 0.76046 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:02:21 @trainer.py:173][0m Change temperature from 0.05078 to 0.04854
[33mIP:10.60.242.134 [0m[32m[0229 17:02:24 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:02:24 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794]
[33mIP:10.60.242.134 [0m[32m[0229 17:02:24 @trainer.py:234][0m acc 0.7794
[33mIP:10.60.242.134 [0m[32m[0229 17:02:24 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 17:02:24 @trainer.py:217][0m Start to train w for epoch 105
[33mIP:10.60.242.134 [0m[32m[0229 17:02:24 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:02:42 @trainer.py:198][0m Epoch[105] Batch[100] Speed: 266.356081 samples/sec loss: -31.61884 acc: 0.72931 ce: 0.75975 lat: -16.18929
[33mIP:10.60.242.134 [0m[32m[0229 17:02:58 @trainer.py:198][0m Epoch[105] Batch[200] Speed: 398.490278 samples/sec loss: -31.61940 acc: 0.72951 ce: 0.75919 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:03:13 @trainer.py:198][0m Epoch[105] Batch[300] Speed: 405.581405 samples/sec loss: -31.61996 acc: 0.72971 ce: 0.75863 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:03:30 @trainer.py:198][0m Epoch[105] Batch[400] Speed: 396.446091 samples/sec loss: -31.62052 acc: 0.72991 ce: 0.75808 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:03:45 @trainer.py:198][0m Epoch[105] Batch[500] Speed: 407.603653 samples/sec loss: -31.62107 acc: 0.73011 ce: 0.75753 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:04:01 @trainer.py:198][0m Epoch[105] Batch[600] Speed: 406.228249 samples/sec loss: -31.62161 acc: 0.73031 ce: 0.75698 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:04:05 @trainer.py:173][0m Change temperature from 0.04854 to 0.04641
[33mIP:10.60.242.134 [0m[32m[0229 17:04:09 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:04:09 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831]
[33mIP:10.60.242.134 [0m[32m[0229 17:04:09 @trainer.py:234][0m acc 0.7831
[33mIP:10.60.242.134 [0m[32m[0229 17:04:09 @trainer.py:235][0m max_acc 0.7874
[33mIP:10.60.242.134 [0m[32m[0229 17:04:09 @trainer.py:217][0m Start to train w for epoch 106
[33mIP:10.60.242.134 [0m[32m[0229 17:04:09 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:04:26 @trainer.py:198][0m Epoch[106] Batch[100] Speed: 254.249848 samples/sec loss: -31.62230 acc: 0.73055 ce: 0.75630 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:04:42 @trainer.py:198][0m Epoch[106] Batch[200] Speed: 399.959759 samples/sec loss: -31.62285 acc: 0.73076 ce: 0.75575 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:04:58 @trainer.py:198][0m Epoch[106] Batch[300] Speed: 405.295296 samples/sec loss: -31.62341 acc: 0.73095 ce: 0.75519 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:05:14 @trainer.py:198][0m Epoch[106] Batch[400] Speed: 410.840257 samples/sec loss: -31.62398 acc: 0.73115 ce: 0.75462 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:05:29 @trainer.py:198][0m Epoch[106] Batch[500] Speed: 403.991395 samples/sec loss: -31.62450 acc: 0.73133 ce: 0.75410 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:05:45 @trainer.py:198][0m Epoch[106] Batch[600] Speed: 408.874749 samples/sec loss: -31.62505 acc: 0.73153 ce: 0.75355 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:05:49 @trainer.py:173][0m Change temperature from 0.04641 to 0.04437
[33mIP:10.60.242.134 [0m[32m[0229 17:05:52 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:05:52 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792]
[33mIP:10.60.242.134 [0m[32m[0229 17:05:52 @trainer.py:234][0m acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:05:52 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:05:52 @trainer.py:217][0m Start to train w for epoch 107
[33mIP:10.60.242.134 [0m[32m[0229 17:05:52 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:06:09 @trainer.py:198][0m Epoch[107] Batch[100] Speed: 271.466444 samples/sec loss: -31.62577 acc: 0.73178 ce: 0.75284 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:06:25 @trainer.py:198][0m Epoch[107] Batch[200] Speed: 399.547927 samples/sec loss: -31.62630 acc: 0.73197 ce: 0.75231 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:06:41 @trainer.py:198][0m Epoch[107] Batch[300] Speed: 399.949039 samples/sec loss: -31.62685 acc: 0.73215 ce: 0.75176 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:06:56 @trainer.py:198][0m Epoch[107] Batch[400] Speed: 410.032281 samples/sec loss: -31.62740 acc: 0.73236 ce: 0.75121 lat: -16.18930
[33mIP:10.60.242.134 [0m[32m[0229 17:07:12 @trainer.py:198][0m Epoch[107] Batch[500] Speed: 412.569092 samples/sec loss: -31.62792 acc: 0.73254 ce: 0.75069 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:07:27 @trainer.py:198][0m Epoch[107] Batch[600] Speed: 414.529988 samples/sec loss: -31.62847 acc: 0.73274 ce: 0.75014 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:07:31 @trainer.py:173][0m Change temperature from 0.04437 to 0.04241
[33mIP:10.60.242.134 [0m[32m[0229 17:07:35 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:07:35 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918]
[33mIP:10.60.242.134 [0m[32m[0229 17:07:35 @trainer.py:234][0m acc 0.7918
[33mIP:10.60.242.134 [0m[32m[0229 17:07:35 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:07:35 @trainer.py:217][0m Start to train w for epoch 108
[33mIP:10.60.242.134 [0m[32m[0229 17:07:35 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:07:51 @trainer.py:198][0m Epoch[108] Batch[100] Speed: 267.330949 samples/sec loss: -31.62918 acc: 0.73299 ce: 0.74943 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:08:07 @trainer.py:198][0m Epoch[108] Batch[200] Speed: 409.566090 samples/sec loss: -31.62976 acc: 0.73319 ce: 0.74885 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:08:22 @trainer.py:198][0m Epoch[108] Batch[300] Speed: 409.143029 samples/sec loss: -31.63030 acc: 0.73337 ce: 0.74831 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:08:38 @trainer.py:198][0m Epoch[108] Batch[400] Speed: 414.456495 samples/sec loss: -31.63085 acc: 0.73356 ce: 0.74777 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:08:54 @trainer.py:198][0m Epoch[108] Batch[500] Speed: 405.679831 samples/sec loss: -31.63140 acc: 0.73376 ce: 0.74722 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:09:09 @trainer.py:198][0m Epoch[108] Batch[600] Speed: 414.638910 samples/sec loss: -31.63194 acc: 0.73396 ce: 0.74668 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:09:13 @trainer.py:173][0m Change temperature from 0.04241 to 0.04055
[33mIP:10.60.242.134 [0m[32m[0229 17:09:17 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:09:17 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919]
[33mIP:10.60.242.134 [0m[32m[0229 17:09:17 @trainer.py:234][0m acc 0.7919
[33mIP:10.60.242.134 [0m[32m[0229 17:09:17 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:09:17 @trainer.py:217][0m Start to train w for epoch 109
[33mIP:10.60.242.134 [0m[32m[0229 17:09:17 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:09:32 @trainer.py:198][0m Epoch[109] Batch[100] Speed: 274.293832 samples/sec loss: -31.63263 acc: 0.73421 ce: 0.74599 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:09:48 @trainer.py:198][0m Epoch[109] Batch[200] Speed: 415.371584 samples/sec loss: -31.63318 acc: 0.73440 ce: 0.74544 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:10:02 @trainer.py:198][0m Epoch[109] Batch[300] Speed: 438.325753 samples/sec loss: -31.63374 acc: 0.73460 ce: 0.74488 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:10:18 @trainer.py:198][0m Epoch[109] Batch[400] Speed: 416.409563 samples/sec loss: -31.63428 acc: 0.73479 ce: 0.74435 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:10:33 @trainer.py:198][0m Epoch[109] Batch[500] Speed: 411.073129 samples/sec loss: -31.63482 acc: 0.73498 ce: 0.74380 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:10:49 @trainer.py:198][0m Epoch[109] Batch[600] Speed: 416.544631 samples/sec loss: -31.63537 acc: 0.73517 ce: 0.74326 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:10:52 @trainer.py:173][0m Change temperature from 0.04055 to 0.03876
[33mIP:10.60.242.134 [0m[32m[0229 17:10:56 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:10:56 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875]
[33mIP:10.60.242.134 [0m[32m[0229 17:10:56 @trainer.py:234][0m acc 0.7875
[33mIP:10.60.242.134 [0m[32m[0229 17:10:56 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:10:56 @trainer.py:217][0m Start to train w for epoch 110
[33mIP:10.60.242.134 [0m[32m[0229 17:10:56 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:11:12 @trainer.py:198][0m Epoch[110] Batch[100] Speed: 277.646889 samples/sec loss: -31.63605 acc: 0.73541 ce: 0.74257 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:11:26 @trainer.py:198][0m Epoch[110] Batch[200] Speed: 437.365879 samples/sec loss: -31.63661 acc: 0.73561 ce: 0.74202 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:11:41 @trainer.py:198][0m Epoch[110] Batch[300] Speed: 438.124316 samples/sec loss: -31.63717 acc: 0.73582 ce: 0.74146 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:11:56 @trainer.py:198][0m Epoch[110] Batch[400] Speed: 435.567813 samples/sec loss: -31.63769 acc: 0.73600 ce: 0.74094 lat: -16.18931
[33mIP:10.60.242.134 [0m[32m[0229 17:12:11 @trainer.py:198][0m Epoch[110] Batch[500] Speed: 431.566578 samples/sec loss: -31.63824 acc: 0.73620 ce: 0.74039 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:12:25 @trainer.py:198][0m Epoch[110] Batch[600] Speed: 439.843575 samples/sec loss: -31.63880 acc: 0.73640 ce: 0.73983 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:12:29 @trainer.py:173][0m Change temperature from 0.03876 to 0.03706
[33mIP:10.60.242.134 [0m[32m[0229 17:12:32 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:12:32 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846]
[33mIP:10.60.242.134 [0m[32m[0229 17:12:32 @trainer.py:234][0m acc 0.7846
[33mIP:10.60.242.134 [0m[32m[0229 17:12:32 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:12:32 @trainer.py:217][0m Start to train w for epoch 111
[33mIP:10.60.242.134 [0m[32m[0229 17:12:32 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:12:48 @trainer.py:198][0m Epoch[111] Batch[100] Speed: 285.099478 samples/sec loss: -31.63948 acc: 0.73664 ce: 0.73915 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:13:03 @trainer.py:198][0m Epoch[111] Batch[200] Speed: 410.553916 samples/sec loss: -31.64002 acc: 0.73683 ce: 0.73862 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:13:18 @trainer.py:198][0m Epoch[111] Batch[300] Speed: 417.843652 samples/sec loss: -31.64059 acc: 0.73704 ce: 0.73805 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:13:34 @trainer.py:198][0m Epoch[111] Batch[400] Speed: 401.847043 samples/sec loss: -31.64113 acc: 0.73723 ce: 0.73751 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:13:50 @trainer.py:198][0m Epoch[111] Batch[500] Speed: 409.614719 samples/sec loss: -31.64166 acc: 0.73742 ce: 0.73697 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:14:06 @trainer.py:198][0m Epoch[111] Batch[600] Speed: 408.039357 samples/sec loss: -31.64216 acc: 0.73760 ce: 0.73648 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:14:09 @trainer.py:173][0m Change temperature from 0.03706 to 0.03543
[33mIP:10.60.242.134 [0m[32m[0229 17:14:13 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:14:13 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842]
[33mIP:10.60.242.134 [0m[32m[0229 17:14:13 @trainer.py:234][0m acc 0.7842
[33mIP:10.60.242.134 [0m[32m[0229 17:14:13 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:14:13 @trainer.py:217][0m Start to train w for epoch 112
[33mIP:10.60.242.134 [0m[32m[0229 17:14:13 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:14:29 @trainer.py:198][0m Epoch[112] Batch[100] Speed: 274.071920 samples/sec loss: -31.64283 acc: 0.73784 ce: 0.73581 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:14:44 @trainer.py:198][0m Epoch[112] Batch[200] Speed: 430.787770 samples/sec loss: -31.64337 acc: 0.73804 ce: 0.73527 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:15:00 @trainer.py:198][0m Epoch[112] Batch[300] Speed: 409.459954 samples/sec loss: -31.64392 acc: 0.73823 ce: 0.73472 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:15:15 @trainer.py:198][0m Epoch[112] Batch[400] Speed: 406.445477 samples/sec loss: -31.64446 acc: 0.73843 ce: 0.73418 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:15:31 @trainer.py:198][0m Epoch[112] Batch[500] Speed: 402.514007 samples/sec loss: -31.64500 acc: 0.73862 ce: 0.73364 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:15:46 @trainer.py:198][0m Epoch[112] Batch[600] Speed: 424.357911 samples/sec loss: -31.64552 acc: 0.73880 ce: 0.73312 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:15:50 @trainer.py:173][0m Change temperature from 0.03543 to 0.03387
[33mIP:10.60.242.134 [0m[32m[0229 17:15:53 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:15:53 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897]
[33mIP:10.60.242.134 [0m[32m[0229 17:15:53 @trainer.py:234][0m acc 0.7897
[33mIP:10.60.242.134 [0m[32m[0229 17:15:53 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:15:53 @trainer.py:217][0m Start to train w for epoch 113
[33mIP:10.60.242.134 [0m[32m[0229 17:15:53 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:16:10 @trainer.py:198][0m Epoch[113] Batch[100] Speed: 274.718038 samples/sec loss: -31.64617 acc: 0.73904 ce: 0.73248 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:16:25 @trainer.py:198][0m Epoch[113] Batch[200] Speed: 403.577613 samples/sec loss: -31.64672 acc: 0.73923 ce: 0.73193 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:16:40 @trainer.py:198][0m Epoch[113] Batch[300] Speed: 443.505031 samples/sec loss: -31.64727 acc: 0.73942 ce: 0.73138 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:16:56 @trainer.py:198][0m Epoch[113] Batch[400] Speed: 405.614823 samples/sec loss: -31.64783 acc: 0.73962 ce: 0.73082 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:17:11 @trainer.py:198][0m Epoch[113] Batch[500] Speed: 411.341006 samples/sec loss: -31.64836 acc: 0.73982 ce: 0.73029 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:17:27 @trainer.py:198][0m Epoch[113] Batch[600] Speed: 411.604998 samples/sec loss: -31.64889 acc: 0.74001 ce: 0.72976 lat: -16.18932
[33mIP:10.60.242.134 [0m[32m[0229 17:17:30 @trainer.py:173][0m Change temperature from 0.03387 to 0.03238
[33mIP:10.60.242.134 [0m[32m[0229 17:17:35 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:17:35 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823]
[33mIP:10.60.242.134 [0m[32m[0229 17:17:35 @trainer.py:234][0m acc 0.7823
[33mIP:10.60.242.134 [0m[32m[0229 17:17:35 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:17:35 @trainer.py:217][0m Start to train w for epoch 114
[33mIP:10.60.242.134 [0m[32m[0229 17:17:35 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:17:51 @trainer.py:198][0m Epoch[114] Batch[100] Speed: 265.549940 samples/sec loss: -31.64956 acc: 0.74025 ce: 0.72909 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:18:07 @trainer.py:198][0m Epoch[114] Batch[200] Speed: 407.981986 samples/sec loss: -31.65010 acc: 0.74044 ce: 0.72855 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:18:22 @trainer.py:198][0m Epoch[114] Batch[300] Speed: 414.816410 samples/sec loss: -31.65065 acc: 0.74063 ce: 0.72801 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:18:37 @trainer.py:198][0m Epoch[114] Batch[400] Speed: 417.097385 samples/sec loss: -31.65116 acc: 0.74081 ce: 0.72749 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:18:53 @trainer.py:198][0m Epoch[114] Batch[500] Speed: 419.897359 samples/sec loss: -31.65169 acc: 0.74100 ce: 0.72696 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:19:07 @trainer.py:198][0m Epoch[114] Batch[600] Speed: 431.912794 samples/sec loss: -31.65221 acc: 0.74119 ce: 0.72645 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:19:11 @trainer.py:173][0m Change temperature from 0.03238 to 0.03095
[33mIP:10.60.242.134 [0m[32m[0229 17:19:14 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:19:14 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868]
[33mIP:10.60.242.134 [0m[32m[0229 17:19:14 @trainer.py:234][0m acc 0.7868
[33mIP:10.60.242.134 [0m[32m[0229 17:19:14 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:19:14 @trainer.py:217][0m Start to train w for epoch 115
[33mIP:10.60.242.134 [0m[32m[0229 17:19:14 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:19:30 @trainer.py:198][0m Epoch[115] Batch[100] Speed: 278.640792 samples/sec loss: -31.65286 acc: 0.74141 ce: 0.72579 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:19:46 @trainer.py:198][0m Epoch[115] Batch[200] Speed: 402.428663 samples/sec loss: -31.65342 acc: 0.74161 ce: 0.72524 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:20:01 @trainer.py:198][0m Epoch[115] Batch[300] Speed: 427.485986 samples/sec loss: -31.65394 acc: 0.74179 ce: 0.72472 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:20:17 @trainer.py:198][0m Epoch[115] Batch[400] Speed: 404.041008 samples/sec loss: -31.65446 acc: 0.74198 ce: 0.72420 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:20:33 @trainer.py:198][0m Epoch[115] Batch[500] Speed: 402.512782 samples/sec loss: -31.65498 acc: 0.74216 ce: 0.72368 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:20:49 @trainer.py:198][0m Epoch[115] Batch[600] Speed: 408.528809 samples/sec loss: -31.65551 acc: 0.74235 ce: 0.72315 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:20:52 @trainer.py:173][0m Change temperature from 0.03095 to 0.02959
[33mIP:10.60.242.134 [0m[32m[0229 17:20:55 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:20:55 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788]
[33mIP:10.60.242.134 [0m[32m[0229 17:20:55 @trainer.py:234][0m acc 0.788
[33mIP:10.60.242.134 [0m[32m[0229 17:20:55 @trainer.py:235][0m max_acc 0.792
[33mIP:10.60.242.134 [0m[32m[0229 17:20:55 @trainer.py:217][0m Start to train w for epoch 116
[33mIP:10.60.242.134 [0m[32m[0229 17:20:55 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:21:11 @trainer.py:198][0m Epoch[116] Batch[100] Speed: 288.597696 samples/sec loss: -31.65616 acc: 0.74259 ce: 0.72250 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:21:26 @trainer.py:198][0m Epoch[116] Batch[200] Speed: 426.204948 samples/sec loss: -31.65670 acc: 0.74278 ce: 0.72197 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:21:40 @trainer.py:198][0m Epoch[116] Batch[300] Speed: 453.277609 samples/sec loss: -31.65721 acc: 0.74296 ce: 0.72145 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:21:54 @trainer.py:198][0m Epoch[116] Batch[400] Speed: 443.760440 samples/sec loss: -31.65772 acc: 0.74314 ce: 0.72094 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:22:10 @trainer.py:198][0m Epoch[116] Batch[500] Speed: 416.467707 samples/sec loss: -31.65825 acc: 0.74333 ce: 0.72042 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:22:25 @trainer.py:198][0m Epoch[116] Batch[600] Speed: 422.767036 samples/sec loss: -31.65876 acc: 0.74352 ce: 0.71991 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:22:28 @trainer.py:173][0m Change temperature from 0.02959 to 0.02829
[33mIP:10.60.242.134 [0m[32m[0229 17:22:32 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:22:32 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927]
[33mIP:10.60.242.134 [0m[32m[0229 17:22:32 @trainer.py:234][0m acc 0.7927
[33mIP:10.60.242.134 [0m[32m[0229 17:22:32 @trainer.py:235][0m max_acc 0.7927
[33mIP:10.60.242.134 [0m[32m[0229 17:22:32 @trainer.py:217][0m Start to train w for epoch 117
[33mIP:10.60.242.134 [0m[32m[0229 17:22:32 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:22:48 @trainer.py:198][0m Epoch[117] Batch[100] Speed: 273.226566 samples/sec loss: -31.65941 acc: 0.74375 ce: 0.71926 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:23:04 @trainer.py:198][0m Epoch[117] Batch[200] Speed: 408.844428 samples/sec loss: -31.65994 acc: 0.74395 ce: 0.71873 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:23:20 @trainer.py:198][0m Epoch[117] Batch[300] Speed: 405.872097 samples/sec loss: -31.66047 acc: 0.74413 ce: 0.71819 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:23:35 @trainer.py:198][0m Epoch[117] Batch[400] Speed: 416.969226 samples/sec loss: -31.66097 acc: 0.74431 ce: 0.71769 lat: -16.18933
[33mIP:10.60.242.134 [0m[32m[0229 17:23:51 @trainer.py:198][0m Epoch[117] Batch[500] Speed: 412.138460 samples/sec loss: -31.66150 acc: 0.74449 ce: 0.71717 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:24:06 @trainer.py:198][0m Epoch[117] Batch[600] Speed: 416.029753 samples/sec loss: -31.66199 acc: 0.74467 ce: 0.71668 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:24:10 @trainer.py:173][0m Change temperature from 0.02829 to 0.02704
[33mIP:10.60.242.134 [0m[32m[0229 17:24:13 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:24:13 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872]
[33mIP:10.60.242.134 [0m[32m[0229 17:24:13 @trainer.py:234][0m acc 0.7872
[33mIP:10.60.242.134 [0m[32m[0229 17:24:13 @trainer.py:235][0m max_acc 0.7927
[33mIP:10.60.242.134 [0m[32m[0229 17:24:13 @trainer.py:217][0m Start to train w for epoch 118
[33mIP:10.60.242.134 [0m[32m[0229 17:24:13 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:24:29 @trainer.py:198][0m Epoch[118] Batch[100] Speed: 276.110352 samples/sec loss: -31.66263 acc: 0.74490 ce: 0.71604 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:24:45 @trainer.py:198][0m Epoch[118] Batch[200] Speed: 415.096302 samples/sec loss: -31.66313 acc: 0.74507 ce: 0.71554 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:25:00 @trainer.py:198][0m Epoch[118] Batch[300] Speed: 405.549652 samples/sec loss: -31.66363 acc: 0.74525 ce: 0.71505 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:25:16 @trainer.py:198][0m Epoch[118] Batch[400] Speed: 419.205608 samples/sec loss: -31.66414 acc: 0.74543 ce: 0.71454 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:25:31 @trainer.py:198][0m Epoch[118] Batch[500] Speed: 404.132805 samples/sec loss: -31.66465 acc: 0.74561 ce: 0.71403 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:25:47 @trainer.py:198][0m Epoch[118] Batch[600] Speed: 405.875797 samples/sec loss: -31.66517 acc: 0.74580 ce: 0.71351 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:25:51 @trainer.py:173][0m Change temperature from 0.02704 to 0.02585
[33mIP:10.60.242.134 [0m[32m[0229 17:25:54 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:25:54 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785]
[33mIP:10.60.242.134 [0m[32m[0229 17:25:54 @trainer.py:234][0m acc 0.785
[33mIP:10.60.242.134 [0m[32m[0229 17:25:54 @trainer.py:235][0m max_acc 0.7927
[33mIP:10.60.242.134 [0m[32m[0229 17:25:54 @trainer.py:217][0m Start to train w for epoch 119
[33mIP:10.60.242.134 [0m[32m[0229 17:25:54 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:26:09 @trainer.py:198][0m Epoch[119] Batch[100] Speed: 287.475342 samples/sec loss: -31.66581 acc: 0.74602 ce: 0.71287 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:26:25 @trainer.py:198][0m Epoch[119] Batch[200] Speed: 410.922406 samples/sec loss: -31.66633 acc: 0.74620 ce: 0.71235 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:26:41 @trainer.py:198][0m Epoch[119] Batch[300] Speed: 414.600601 samples/sec loss: -31.66684 acc: 0.74638 ce: 0.71184 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:26:56 @trainer.py:198][0m Epoch[119] Batch[400] Speed: 411.429813 samples/sec loss: -31.66736 acc: 0.74657 ce: 0.71132 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:27:11 @trainer.py:198][0m Epoch[119] Batch[500] Speed: 427.710576 samples/sec loss: -31.66787 acc: 0.74675 ce: 0.71081 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:27:26 @trainer.py:198][0m Epoch[119] Batch[600] Speed: 417.833271 samples/sec loss: -31.66837 acc: 0.74692 ce: 0.71031 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:27:30 @trainer.py:173][0m Change temperature from 0.02585 to 0.02472
[33mIP:10.60.242.134 [0m[32m[0229 17:27:33 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:27:33 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886]
[33mIP:10.60.242.134 [0m[32m[0229 17:27:33 @trainer.py:234][0m acc 0.7886
[33mIP:10.60.242.134 [0m[32m[0229 17:27:33 @trainer.py:235][0m max_acc 0.7927
[33mIP:10.60.242.134 [0m[32m[0229 17:27:33 @trainer.py:217][0m Start to train w for epoch 120
[33mIP:10.60.242.134 [0m[32m[0229 17:27:33 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:27:49 @trainer.py:198][0m Epoch[120] Batch[100] Speed: 283.127416 samples/sec loss: -31.66899 acc: 0.74713 ce: 0.70969 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:28:04 @trainer.py:198][0m Epoch[120] Batch[200] Speed: 421.332129 samples/sec loss: -31.66950 acc: 0.74731 ce: 0.70918 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:28:19 @trainer.py:198][0m Epoch[120] Batch[300] Speed: 421.536151 samples/sec loss: -31.67000 acc: 0.74749 ce: 0.70869 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:28:35 @trainer.py:198][0m Epoch[120] Batch[400] Speed: 411.078675 samples/sec loss: -31.67050 acc: 0.74766 ce: 0.70818 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:28:51 @trainer.py:198][0m Epoch[120] Batch[500] Speed: 407.362626 samples/sec loss: -31.67099 acc: 0.74784 ce: 0.70769 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:29:06 @trainer.py:198][0m Epoch[120] Batch[600] Speed: 404.530877 samples/sec loss: -31.67150 acc: 0.74802 ce: 0.70718 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:29:10 @trainer.py:173][0m Change temperature from 0.02472 to 0.02363
[33mIP:10.60.242.134 [0m[32m[0229 17:29:13 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:29:13 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897]
[33mIP:10.60.242.134 [0m[32m[0229 17:29:13 @trainer.py:234][0m acc 0.7897
[33mIP:10.60.242.134 [0m[32m[0229 17:29:13 @trainer.py:235][0m max_acc 0.7927
[33mIP:10.60.242.134 [0m[32m[0229 17:29:13 @trainer.py:217][0m Start to train w for epoch 121
[33mIP:10.60.242.134 [0m[32m[0229 17:29:13 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:29:29 @trainer.py:198][0m Epoch[121] Batch[100] Speed: 281.633196 samples/sec loss: -31.67212 acc: 0.74824 ce: 0.70656 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:29:44 @trainer.py:198][0m Epoch[121] Batch[200] Speed: 417.818593 samples/sec loss: -31.67262 acc: 0.74842 ce: 0.70606 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:30:00 @trainer.py:198][0m Epoch[121] Batch[300] Speed: 410.901667 samples/sec loss: -31.67310 acc: 0.74859 ce: 0.70558 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:30:15 @trainer.py:198][0m Epoch[121] Batch[400] Speed: 419.939360 samples/sec loss: -31.67361 acc: 0.74877 ce: 0.70507 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:30:30 @trainer.py:198][0m Epoch[121] Batch[500] Speed: 421.191362 samples/sec loss: -31.67412 acc: 0.74895 ce: 0.70457 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:30:46 @trainer.py:198][0m Epoch[121] Batch[600] Speed: 424.930945 samples/sec loss: -31.67462 acc: 0.74913 ce: 0.70407 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:30:49 @trainer.py:173][0m Change temperature from 0.02363 to 0.02259
[33mIP:10.60.242.134 [0m[32m[0229 17:30:53 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:30:53 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947]
[33mIP:10.60.242.134 [0m[32m[0229 17:30:53 @trainer.py:234][0m acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:30:53 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:30:53 @trainer.py:217][0m Start to train w for epoch 122
[33mIP:10.60.242.134 [0m[32m[0229 17:30:53 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:31:08 @trainer.py:198][0m Epoch[122] Batch[100] Speed: 282.921337 samples/sec loss: -31.67522 acc: 0.74934 ce: 0.70347 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:31:24 @trainer.py:198][0m Epoch[122] Batch[200] Speed: 414.132813 samples/sec loss: -31.67573 acc: 0.74952 ce: 0.70296 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:31:40 @trainer.py:198][0m Epoch[122] Batch[300] Speed: 402.447210 samples/sec loss: -31.67620 acc: 0.74968 ce: 0.70249 lat: -16.18934
[33mIP:10.60.242.134 [0m[32m[0229 17:31:55 @trainer.py:198][0m Epoch[122] Batch[400] Speed: 415.250585 samples/sec loss: -31.67668 acc: 0.74986 ce: 0.70201 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:32:11 @trainer.py:198][0m Epoch[122] Batch[500] Speed: 405.026640 samples/sec loss: -31.67716 acc: 0.75002 ce: 0.70153 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:32:26 @trainer.py:198][0m Epoch[122] Batch[600] Speed: 415.088195 samples/sec loss: -31.67765 acc: 0.75020 ce: 0.70104 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:32:30 @trainer.py:173][0m Change temperature from 0.02259 to 0.02160
[33mIP:10.60.242.134 [0m[32m[0229 17:32:33 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:32:33 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916]
[33mIP:10.60.242.134 [0m[32m[0229 17:32:33 @trainer.py:234][0m acc 0.7916
[33mIP:10.60.242.134 [0m[32m[0229 17:32:33 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:32:33 @trainer.py:217][0m Start to train w for epoch 123
[33mIP:10.60.242.134 [0m[32m[0229 17:32:33 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:32:49 @trainer.py:198][0m Epoch[123] Batch[100] Speed: 286.046437 samples/sec loss: -31.67826 acc: 0.75042 ce: 0.70043 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:33:05 @trainer.py:198][0m Epoch[123] Batch[200] Speed: 388.924009 samples/sec loss: -31.67876 acc: 0.75060 ce: 0.69993 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:33:21 @trainer.py:198][0m Epoch[123] Batch[300] Speed: 399.750424 samples/sec loss: -31.67923 acc: 0.75077 ce: 0.69946 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:33:37 @trainer.py:198][0m Epoch[123] Batch[400] Speed: 403.907837 samples/sec loss: -31.67971 acc: 0.75094 ce: 0.69899 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:33:52 @trainer.py:198][0m Epoch[123] Batch[500] Speed: 421.649614 samples/sec loss: -31.68019 acc: 0.75111 ce: 0.69851 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:34:06 @trainer.py:198][0m Epoch[123] Batch[600] Speed: 442.670716 samples/sec loss: -31.68067 acc: 0.75128 ce: 0.69802 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:34:09 @trainer.py:173][0m Change temperature from 0.02160 to 0.02065
[33mIP:10.60.242.134 [0m[32m[0229 17:34:12 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:34:12 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875]
[33mIP:10.60.242.134 [0m[32m[0229 17:34:12 @trainer.py:234][0m acc 0.7875
[33mIP:10.60.242.134 [0m[32m[0229 17:34:12 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:34:12 @trainer.py:217][0m Start to train w for epoch 124
[33mIP:10.60.242.134 [0m[32m[0229 17:34:12 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:34:27 @trainer.py:198][0m Epoch[124] Batch[100] Speed: 315.589716 samples/sec loss: -31.68124 acc: 0.75149 ce: 0.69745 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:34:41 @trainer.py:198][0m Epoch[124] Batch[200] Speed: 436.044698 samples/sec loss: -31.68170 acc: 0.75165 ce: 0.69699 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:34:56 @trainer.py:198][0m Epoch[124] Batch[300] Speed: 436.878807 samples/sec loss: -31.68215 acc: 0.75181 ce: 0.69655 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:35:11 @trainer.py:198][0m Epoch[124] Batch[400] Speed: 432.597408 samples/sec loss: -31.68263 acc: 0.75198 ce: 0.69606 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:35:26 @trainer.py:198][0m Epoch[124] Batch[500] Speed: 417.477538 samples/sec loss: -31.68311 acc: 0.75215 ce: 0.69558 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:35:42 @trainer.py:198][0m Epoch[124] Batch[600] Speed: 404.284287 samples/sec loss: -31.68358 acc: 0.75232 ce: 0.69512 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:35:46 @trainer.py:173][0m Change temperature from 0.02065 to 0.01974
[33mIP:10.60.242.134 [0m[32m[0229 17:35:49 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:35:49 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875]
[33mIP:10.60.242.134 [0m[32m[0229 17:35:49 @trainer.py:234][0m acc 0.7875
[33mIP:10.60.242.134 [0m[32m[0229 17:35:49 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:35:49 @trainer.py:217][0m Start to train w for epoch 125
[33mIP:10.60.242.134 [0m[32m[0229 17:35:49 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:36:05 @trainer.py:198][0m Epoch[125] Batch[100] Speed: 274.918561 samples/sec loss: -31.68418 acc: 0.75253 ce: 0.69452 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:36:21 @trainer.py:198][0m Epoch[125] Batch[200] Speed: 408.327602 samples/sec loss: -31.68465 acc: 0.75270 ce: 0.69405 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:36:37 @trainer.py:198][0m Epoch[125] Batch[300] Speed: 406.768732 samples/sec loss: -31.68512 acc: 0.75287 ce: 0.69358 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:36:53 @trainer.py:198][0m Epoch[125] Batch[400] Speed: 403.199267 samples/sec loss: -31.68559 acc: 0.75304 ce: 0.69311 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:37:08 @trainer.py:198][0m Epoch[125] Batch[500] Speed: 413.091250 samples/sec loss: -31.68605 acc: 0.75320 ce: 0.69265 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:37:23 @trainer.py:198][0m Epoch[125] Batch[600] Speed: 423.456793 samples/sec loss: -31.68651 acc: 0.75336 ce: 0.69220 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:37:27 @trainer.py:173][0m Change temperature from 0.01974 to 0.01887
[33mIP:10.60.242.134 [0m[32m[0229 17:37:31 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:37:31 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882]
[33mIP:10.60.242.134 [0m[32m[0229 17:37:31 @trainer.py:234][0m acc 0.7882
[33mIP:10.60.242.134 [0m[32m[0229 17:37:31 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:37:31 @trainer.py:217][0m Start to train w for epoch 126
[33mIP:10.60.242.134 [0m[32m[0229 17:37:31 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:37:47 @trainer.py:198][0m Epoch[126] Batch[100] Speed: 270.427612 samples/sec loss: -31.68704 acc: 0.75356 ce: 0.69166 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:38:03 @trainer.py:198][0m Epoch[126] Batch[200] Speed: 409.452347 samples/sec loss: -31.68750 acc: 0.75372 ce: 0.69120 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:38:18 @trainer.py:198][0m Epoch[126] Batch[300] Speed: 406.077856 samples/sec loss: -31.68796 acc: 0.75388 ce: 0.69074 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:38:33 @trainer.py:198][0m Epoch[126] Batch[400] Speed: 429.296032 samples/sec loss: -31.68842 acc: 0.75406 ce: 0.69028 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:38:48 @trainer.py:198][0m Epoch[126] Batch[500] Speed: 418.541757 samples/sec loss: -31.68889 acc: 0.75422 ce: 0.68982 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:39:04 @trainer.py:198][0m Epoch[126] Batch[600] Speed: 418.222397 samples/sec loss: -31.68935 acc: 0.75438 ce: 0.68936 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:39:08 @trainer.py:173][0m Change temperature from 0.01887 to 0.01804
[33mIP:10.60.242.134 [0m[32m[0229 17:39:12 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:39:12 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898]
[33mIP:10.60.242.134 [0m[32m[0229 17:39:12 @trainer.py:234][0m acc 0.7898
[33mIP:10.60.242.134 [0m[32m[0229 17:39:12 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:39:12 @trainer.py:217][0m Start to train w for epoch 127
[33mIP:10.60.242.134 [0m[32m[0229 17:39:12 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:39:27 @trainer.py:198][0m Epoch[127] Batch[100] Speed: 270.299381 samples/sec loss: -31.68977 acc: 0.75453 ce: 0.68893 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:39:43 @trainer.py:198][0m Epoch[127] Batch[200] Speed: 406.095008 samples/sec loss: -31.69002 acc: 0.75462 ce: 0.68869 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:39:59 @trainer.py:198][0m Epoch[127] Batch[300] Speed: 401.126628 samples/sec loss: -31.69027 acc: 0.75471 ce: 0.68844 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:40:14 @trainer.py:198][0m Epoch[127] Batch[400] Speed: 420.396478 samples/sec loss: -31.69051 acc: 0.75481 ce: 0.68819 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:40:30 @trainer.py:198][0m Epoch[127] Batch[500] Speed: 411.779498 samples/sec loss: -31.69077 acc: 0.75489 ce: 0.68794 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:40:44 @trainer.py:198][0m Epoch[127] Batch[600] Speed: 450.510084 samples/sec loss: -31.69102 acc: 0.75498 ce: 0.68769 lat: -16.18935
[33mIP:10.60.242.134 [0m[32m[0229 17:40:48 @trainer.py:173][0m Change temperature from 0.01804 to 0.01725
[33mIP:10.60.242.134 [0m[32m[0229 17:40:52 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:40:52 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77]
[33mIP:10.60.242.134 [0m[32m[0229 17:40:52 @trainer.py:234][0m acc 0.77
[33mIP:10.60.242.134 [0m[32m[0229 17:40:52 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:40:52 @trainer.py:217][0m Start to train w for epoch 128
[33mIP:10.60.242.134 [0m[32m[0229 17:40:52 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:41:07 @trainer.py:198][0m Epoch[128] Batch[100] Speed: 278.901868 samples/sec loss: -31.69133 acc: 0.75510 ce: 0.68738 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:41:22 @trainer.py:198][0m Epoch[128] Batch[200] Speed: 417.989609 samples/sec loss: -31.69159 acc: 0.75519 ce: 0.68712 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:41:38 @trainer.py:198][0m Epoch[128] Batch[300] Speed: 423.163202 samples/sec loss: -31.69182 acc: 0.75527 ce: 0.68690 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:41:53 @trainer.py:198][0m Epoch[128] Batch[400] Speed: 416.166426 samples/sec loss: -31.69207 acc: 0.75536 ce: 0.68665 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:42:08 @trainer.py:198][0m Epoch[128] Batch[500] Speed: 421.691921 samples/sec loss: -31.69231 acc: 0.75545 ce: 0.68641 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:42:23 @trainer.py:198][0m Epoch[128] Batch[600] Speed: 419.626005 samples/sec loss: -31.69252 acc: 0.75553 ce: 0.68620 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:42:27 @trainer.py:173][0m Change temperature from 0.01725 to 0.01649
[33mIP:10.60.242.134 [0m[32m[0229 17:42:31 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:42:31 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594]
[33mIP:10.60.242.134 [0m[32m[0229 17:42:31 @trainer.py:234][0m acc 0.7594
[33mIP:10.60.242.134 [0m[32m[0229 17:42:31 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:42:31 @trainer.py:217][0m Start to train w for epoch 129
[33mIP:10.60.242.134 [0m[32m[0229 17:42:31 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:42:47 @trainer.py:198][0m Epoch[129] Batch[100] Speed: 268.521506 samples/sec loss: -31.69283 acc: 0.75564 ce: 0.68589 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:43:03 @trainer.py:198][0m Epoch[129] Batch[200] Speed: 403.926556 samples/sec loss: -31.69306 acc: 0.75572 ce: 0.68566 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:43:19 @trainer.py:198][0m Epoch[129] Batch[300] Speed: 411.571210 samples/sec loss: -31.69332 acc: 0.75582 ce: 0.68540 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:43:34 @trainer.py:198][0m Epoch[129] Batch[400] Speed: 406.148346 samples/sec loss: -31.69354 acc: 0.75589 ce: 0.68519 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:43:50 @trainer.py:198][0m Epoch[129] Batch[500] Speed: 417.585865 samples/sec loss: -31.69377 acc: 0.75598 ce: 0.68496 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:44:05 @trainer.py:198][0m Epoch[129] Batch[600] Speed: 424.176216 samples/sec loss: -31.69401 acc: 0.75607 ce: 0.68472 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:44:08 @trainer.py:173][0m Change temperature from 0.01649 to 0.01576
[33mIP:10.60.242.134 [0m[32m[0229 17:44:12 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:44:12 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776]
[33mIP:10.60.242.134 [0m[32m[0229 17:44:12 @trainer.py:234][0m acc 0.7776
[33mIP:10.60.242.134 [0m[32m[0229 17:44:12 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:44:12 @trainer.py:217][0m Start to train w for epoch 130
[33mIP:10.60.242.134 [0m[32m[0229 17:44:12 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:44:28 @trainer.py:198][0m Epoch[130] Batch[100] Speed: 269.613375 samples/sec loss: -31.69433 acc: 0.75618 ce: 0.68440 lat: -16.18936
[33mIP:10.60.242.134 [0m[32m[0229 17:44:44 @trainer.py:198][0m Epoch[130] Batch[200] Speed: 409.948985 samples/sec loss: -31.69457 acc: 0.75628 ce: 0.68416 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:44:59 @trainer.py:198][0m Epoch[130] Batch[300] Speed: 423.236179 samples/sec loss: -31.69481 acc: 0.75636 ce: 0.68392 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:45:15 @trainer.py:198][0m Epoch[130] Batch[400] Speed: 403.482647 samples/sec loss: -31.69505 acc: 0.75646 ce: 0.68369 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:45:31 @trainer.py:198][0m Epoch[130] Batch[500] Speed: 407.837182 samples/sec loss: -31.69526 acc: 0.75653 ce: 0.68348 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:45:46 @trainer.py:198][0m Epoch[130] Batch[600] Speed: 421.884489 samples/sec loss: -31.69548 acc: 0.75661 ce: 0.68326 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:45:49 @trainer.py:173][0m Change temperature from 0.01576 to 0.01507
[33mIP:10.60.242.134 [0m[32m[0229 17:45:53 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:45:53 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77]
[33mIP:10.60.242.134 [0m[32m[0229 17:45:53 @trainer.py:234][0m acc 0.77
[33mIP:10.60.242.134 [0m[32m[0229 17:45:53 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:45:53 @trainer.py:217][0m Start to train w for epoch 131
[33mIP:10.60.242.134 [0m[32m[0229 17:45:53 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:46:09 @trainer.py:198][0m Epoch[131] Batch[100] Speed: 282.418228 samples/sec loss: -31.69577 acc: 0.75672 ce: 0.68297 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:46:24 @trainer.py:198][0m Epoch[131] Batch[200] Speed: 414.787739 samples/sec loss: -31.69600 acc: 0.75679 ce: 0.68274 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:46:39 @trainer.py:198][0m Epoch[131] Batch[300] Speed: 419.932810 samples/sec loss: -31.69624 acc: 0.75688 ce: 0.68251 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:46:55 @trainer.py:198][0m Epoch[131] Batch[400] Speed: 411.687333 samples/sec loss: -31.69647 acc: 0.75696 ce: 0.68228 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:47:10 @trainer.py:198][0m Epoch[131] Batch[500] Speed: 409.507858 samples/sec loss: -31.69670 acc: 0.75704 ce: 0.68205 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:47:27 @trainer.py:198][0m Epoch[131] Batch[600] Speed: 399.014689 samples/sec loss: -31.69693 acc: 0.75713 ce: 0.68182 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:47:30 @trainer.py:173][0m Change temperature from 0.01507 to 0.01440
[33mIP:10.60.242.134 [0m[32m[0229 17:47:33 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:47:33 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622]
[33mIP:10.60.242.134 [0m[32m[0229 17:47:33 @trainer.py:234][0m acc 0.7622
[33mIP:10.60.242.134 [0m[32m[0229 17:47:33 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:47:33 @trainer.py:217][0m Start to train w for epoch 132
[33mIP:10.60.242.134 [0m[32m[0229 17:47:33 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:47:49 @trainer.py:198][0m Epoch[132] Batch[100] Speed: 280.150665 samples/sec loss: -31.69723 acc: 0.75724 ce: 0.68152 lat: -16.18937
[33mIP:10.60.242.134 [0m[32m[0229 17:48:05 @trainer.py:198][0m Epoch[132] Batch[200] Speed: 418.808777 samples/sec loss: -31.69745 acc: 0.75732 ce: 0.68130 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:48:20 @trainer.py:198][0m Epoch[132] Batch[300] Speed: 429.996723 samples/sec loss: -31.69768 acc: 0.75740 ce: 0.68107 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:48:33 @trainer.py:198][0m Epoch[132] Batch[400] Speed: 463.112479 samples/sec loss: -31.69788 acc: 0.75748 ce: 0.68087 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:48:48 @trainer.py:198][0m Epoch[132] Batch[500] Speed: 437.616897 samples/sec loss: -31.69810 acc: 0.75756 ce: 0.68065 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:49:03 @trainer.py:198][0m Epoch[132] Batch[600] Speed: 417.215118 samples/sec loss: -31.69833 acc: 0.75764 ce: 0.68043 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:49:07 @trainer.py:173][0m Change temperature from 0.01440 to 0.01377
[33mIP:10.60.242.134 [0m[32m[0229 17:49:10 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:49:10 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769]
[33mIP:10.60.242.134 [0m[32m[0229 17:49:10 @trainer.py:234][0m acc 0.7769
[33mIP:10.60.242.134 [0m[32m[0229 17:49:10 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:49:10 @trainer.py:217][0m Start to train w for epoch 133
[33mIP:10.60.242.134 [0m[32m[0229 17:49:10 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:49:27 @trainer.py:198][0m Epoch[133] Batch[100] Speed: 275.365395 samples/sec loss: -31.69862 acc: 0.75775 ce: 0.68014 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:49:42 @trainer.py:198][0m Epoch[133] Batch[200] Speed: 415.467444 samples/sec loss: -31.69887 acc: 0.75783 ce: 0.67989 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:49:57 @trainer.py:198][0m Epoch[133] Batch[300] Speed: 413.494391 samples/sec loss: -31.69911 acc: 0.75792 ce: 0.67965 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:50:13 @trainer.py:198][0m Epoch[133] Batch[400] Speed: 418.197762 samples/sec loss: -31.69932 acc: 0.75799 ce: 0.67944 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:50:28 @trainer.py:198][0m Epoch[133] Batch[500] Speed: 420.080304 samples/sec loss: -31.69953 acc: 0.75807 ce: 0.67923 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:50:43 @trainer.py:198][0m Epoch[133] Batch[600] Speed: 429.069761 samples/sec loss: -31.69976 acc: 0.75815 ce: 0.67901 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:50:47 @trainer.py:173][0m Change temperature from 0.01377 to 0.01316
[33mIP:10.60.242.134 [0m[32m[0229 17:50:51 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:50:51 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699]
[33mIP:10.60.242.134 [0m[32m[0229 17:50:51 @trainer.py:234][0m acc 0.7699
[33mIP:10.60.242.134 [0m[32m[0229 17:50:51 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:50:51 @trainer.py:217][0m Start to train w for epoch 134
[33mIP:10.60.242.134 [0m[32m[0229 17:50:51 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:51:07 @trainer.py:198][0m Epoch[134] Batch[100] Speed: 267.116855 samples/sec loss: -31.70004 acc: 0.75826 ce: 0.67873 lat: -16.18938
[33mIP:10.60.242.134 [0m[32m[0229 17:51:22 @trainer.py:198][0m Epoch[134] Batch[200] Speed: 420.721819 samples/sec loss: -31.70028 acc: 0.75834 ce: 0.67849 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:51:38 @trainer.py:198][0m Epoch[134] Batch[300] Speed: 410.407846 samples/sec loss: -31.70050 acc: 0.75842 ce: 0.67827 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:51:52 @trainer.py:198][0m Epoch[134] Batch[400] Speed: 432.002392 samples/sec loss: -31.70071 acc: 0.75850 ce: 0.67806 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:52:08 @trainer.py:198][0m Epoch[134] Batch[500] Speed: 425.821373 samples/sec loss: -31.70093 acc: 0.75858 ce: 0.67784 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:52:22 @trainer.py:198][0m Epoch[134] Batch[600] Speed: 433.852785 samples/sec loss: -31.70115 acc: 0.75865 ce: 0.67763 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:52:26 @trainer.py:173][0m Change temperature from 0.01316 to 0.01259
[33mIP:10.60.242.134 [0m[32m[0229 17:52:29 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:52:29 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707]
[33mIP:10.60.242.134 [0m[32m[0229 17:52:29 @trainer.py:234][0m acc 0.7707
[33mIP:10.60.242.134 [0m[32m[0229 17:52:29 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:52:29 @trainer.py:217][0m Start to train w for epoch 135
[33mIP:10.60.242.134 [0m[32m[0229 17:52:29 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:52:45 @trainer.py:198][0m Epoch[135] Batch[100] Speed: 282.644096 samples/sec loss: -31.70146 acc: 0.75877 ce: 0.67732 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:53:00 @trainer.py:198][0m Epoch[135] Batch[200] Speed: 413.552386 samples/sec loss: -31.70170 acc: 0.75885 ce: 0.67708 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:53:16 @trainer.py:198][0m Epoch[135] Batch[300] Speed: 398.758628 samples/sec loss: -31.70193 acc: 0.75893 ce: 0.67685 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:53:32 @trainer.py:198][0m Epoch[135] Batch[400] Speed: 411.161386 samples/sec loss: -31.70214 acc: 0.75901 ce: 0.67665 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:53:48 @trainer.py:198][0m Epoch[135] Batch[500] Speed: 410.668021 samples/sec loss: -31.70235 acc: 0.75909 ce: 0.67644 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:54:03 @trainer.py:198][0m Epoch[135] Batch[600] Speed: 420.738713 samples/sec loss: -31.70255 acc: 0.75916 ce: 0.67624 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:54:06 @trainer.py:173][0m Change temperature from 0.01259 to 0.01203
[33mIP:10.60.242.134 [0m[32m[0229 17:54:10 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:54:10 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754]
[33mIP:10.60.242.134 [0m[32m[0229 17:54:10 @trainer.py:234][0m acc 0.7754
[33mIP:10.60.242.134 [0m[32m[0229 17:54:10 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:54:10 @trainer.py:217][0m Start to train w for epoch 136
[33mIP:10.60.242.134 [0m[32m[0229 17:54:10 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:54:26 @trainer.py:198][0m Epoch[136] Batch[100] Speed: 279.896262 samples/sec loss: -31.70283 acc: 0.75926 ce: 0.67596 lat: -16.18939
[33mIP:10.60.242.134 [0m[32m[0229 17:54:40 @trainer.py:198][0m Epoch[136] Batch[200] Speed: 451.550370 samples/sec loss: -31.70306 acc: 0.75935 ce: 0.67573 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:54:54 @trainer.py:198][0m Epoch[136] Batch[300] Speed: 459.519664 samples/sec loss: -31.70329 acc: 0.75943 ce: 0.67550 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:55:09 @trainer.py:198][0m Epoch[136] Batch[400] Speed: 426.230975 samples/sec loss: -31.70352 acc: 0.75952 ce: 0.67528 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:55:24 @trainer.py:198][0m Epoch[136] Batch[500] Speed: 411.096328 samples/sec loss: -31.70372 acc: 0.75959 ce: 0.67508 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:55:40 @trainer.py:198][0m Epoch[136] Batch[600] Speed: 414.345577 samples/sec loss: -31.70396 acc: 0.75968 ce: 0.67484 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:55:43 @trainer.py:173][0m Change temperature from 0.01203 to 0.01150
[33mIP:10.60.242.134 [0m[32m[0229 17:55:47 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:55:47 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727]
[33mIP:10.60.242.134 [0m[32m[0229 17:55:47 @trainer.py:234][0m acc 0.7727
[33mIP:10.60.242.134 [0m[32m[0229 17:55:47 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:55:47 @trainer.py:217][0m Start to train w for epoch 137
[33mIP:10.60.242.134 [0m[32m[0229 17:55:47 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:56:03 @trainer.py:198][0m Epoch[137] Batch[100] Speed: 275.360390 samples/sec loss: -31.70428 acc: 0.75979 ce: 0.67452 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:56:18 @trainer.py:198][0m Epoch[137] Batch[200] Speed: 416.331011 samples/sec loss: -31.70450 acc: 0.75987 ce: 0.67430 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:56:35 @trainer.py:198][0m Epoch[137] Batch[300] Speed: 397.411635 samples/sec loss: -31.70472 acc: 0.75995 ce: 0.67408 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:56:50 @trainer.py:198][0m Epoch[137] Batch[400] Speed: 411.186295 samples/sec loss: -31.70494 acc: 0.76004 ce: 0.67387 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:57:06 @trainer.py:198][0m Epoch[137] Batch[500] Speed: 410.199739 samples/sec loss: -31.70516 acc: 0.76012 ce: 0.67365 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:57:21 @trainer.py:198][0m Epoch[137] Batch[600] Speed: 407.286720 samples/sec loss: -31.70537 acc: 0.76019 ce: 0.67344 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:57:25 @trainer.py:173][0m Change temperature from 0.01150 to 0.01100
[33mIP:10.60.242.134 [0m[32m[0229 17:57:28 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:57:28 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829]
[33mIP:10.60.242.134 [0m[32m[0229 17:57:28 @trainer.py:234][0m acc 0.7829
[33mIP:10.60.242.134 [0m[32m[0229 17:57:28 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:57:28 @trainer.py:217][0m Start to train w for epoch 138
[33mIP:10.60.242.134 [0m[32m[0229 17:57:28 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:57:44 @trainer.py:198][0m Epoch[138] Batch[100] Speed: 287.202604 samples/sec loss: -31.70566 acc: 0.76029 ce: 0.67315 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:57:59 @trainer.py:198][0m Epoch[138] Batch[200] Speed: 426.802330 samples/sec loss: -31.70587 acc: 0.76038 ce: 0.67294 lat: -16.18940
[33mIP:10.60.242.134 [0m[32m[0229 17:58:14 @trainer.py:198][0m Epoch[138] Batch[300] Speed: 420.542966 samples/sec loss: -31.70607 acc: 0.76046 ce: 0.67274 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 17:58:30 @trainer.py:198][0m Epoch[138] Batch[400] Speed: 393.762280 samples/sec loss: -31.70630 acc: 0.76054 ce: 0.67251 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 17:58:46 @trainer.py:198][0m Epoch[138] Batch[500] Speed: 411.778766 samples/sec loss: -31.70652 acc: 0.76063 ce: 0.67229 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 17:59:00 @trainer.py:198][0m Epoch[138] Batch[600] Speed: 433.881628 samples/sec loss: -31.70675 acc: 0.76071 ce: 0.67207 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 17:59:04 @trainer.py:173][0m Change temperature from 0.01100 to 0.01051
[33mIP:10.60.242.134 [0m[32m[0229 17:59:07 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 17:59:07 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691]
[33mIP:10.60.242.134 [0m[32m[0229 17:59:07 @trainer.py:234][0m acc 0.7691
[33mIP:10.60.242.134 [0m[32m[0229 17:59:07 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 17:59:07 @trainer.py:217][0m Start to train w for epoch 139
[33mIP:10.60.242.134 [0m[32m[0229 17:59:07 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 17:59:22 @trainer.py:198][0m Epoch[139] Batch[100] Speed: 292.435631 samples/sec loss: -31.70704 acc: 0.76082 ce: 0.67178 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 17:59:38 @trainer.py:198][0m Epoch[139] Batch[200] Speed: 421.334060 samples/sec loss: -31.70727 acc: 0.76091 ce: 0.67154 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 17:59:53 @trainer.py:198][0m Epoch[139] Batch[300] Speed: 414.919576 samples/sec loss: -31.70749 acc: 0.76098 ce: 0.67133 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 18:00:08 @trainer.py:198][0m Epoch[139] Batch[400] Speed: 421.535191 samples/sec loss: -31.70772 acc: 0.76107 ce: 0.67111 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 18:00:23 @trainer.py:198][0m Epoch[139] Batch[500] Speed: 422.379859 samples/sec loss: -31.70793 acc: 0.76115 ce: 0.67089 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 18:00:38 @trainer.py:198][0m Epoch[139] Batch[600] Speed: 422.670686 samples/sec loss: -31.70815 acc: 0.76123 ce: 0.67067 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 18:00:42 @trainer.py:173][0m Change temperature from 0.01051 to 0.01005
[33mIP:10.60.242.134 [0m[32m[0229 18:00:46 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:00:46 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846]
[33mIP:10.60.242.134 [0m[32m[0229 18:00:46 @trainer.py:234][0m acc 0.7846
[33mIP:10.60.242.134 [0m[32m[0229 18:00:46 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:00:46 @trainer.py:217][0m Start to train w for epoch 140
[33mIP:10.60.242.134 [0m[32m[0229 18:00:46 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:01:01 @trainer.py:198][0m Epoch[140] Batch[100] Speed: 285.256274 samples/sec loss: -31.70845 acc: 0.76134 ce: 0.67038 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 18:01:16 @trainer.py:198][0m Epoch[140] Batch[200] Speed: 425.154164 samples/sec loss: -31.70869 acc: 0.76143 ce: 0.67014 lat: -16.18941
[33mIP:10.60.242.134 [0m[32m[0229 18:01:31 @trainer.py:198][0m Epoch[140] Batch[300] Speed: 417.465572 samples/sec loss: -31.70893 acc: 0.76151 ce: 0.66990 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:01:48 @trainer.py:198][0m Epoch[140] Batch[400] Speed: 389.285054 samples/sec loss: -31.70915 acc: 0.76160 ce: 0.66968 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:02:03 @trainer.py:198][0m Epoch[140] Batch[500] Speed: 412.112607 samples/sec loss: -31.70936 acc: 0.76167 ce: 0.66948 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:02:18 @trainer.py:198][0m Epoch[140] Batch[600] Speed: 424.643261 samples/sec loss: -31.70957 acc: 0.76175 ce: 0.66926 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:02:22 @trainer.py:173][0m Change temperature from 0.01005 to 0.00961
[33mIP:10.60.242.134 [0m[32m[0229 18:02:25 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:02:25 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777]
[33mIP:10.60.242.134 [0m[32m[0229 18:02:25 @trainer.py:234][0m acc 0.777
[33mIP:10.60.242.134 [0m[32m[0229 18:02:25 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:02:25 @trainer.py:217][0m Start to train w for epoch 141
[33mIP:10.60.242.134 [0m[32m[0229 18:02:25 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:02:39 @trainer.py:198][0m Epoch[141] Batch[100] Speed: 301.994804 samples/sec loss: -31.70986 acc: 0.76186 ce: 0.66898 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:02:54 @trainer.py:198][0m Epoch[141] Batch[200] Speed: 450.246721 samples/sec loss: -31.71008 acc: 0.76194 ce: 0.66876 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:03:08 @trainer.py:198][0m Epoch[141] Batch[300] Speed: 454.652238 samples/sec loss: -31.71032 acc: 0.76203 ce: 0.66852 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:03:22 @trainer.py:198][0m Epoch[141] Batch[400] Speed: 462.508739 samples/sec loss: -31.71055 acc: 0.76211 ce: 0.66829 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:03:37 @trainer.py:198][0m Epoch[141] Batch[500] Speed: 429.781554 samples/sec loss: -31.71076 acc: 0.76219 ce: 0.66808 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:03:52 @trainer.py:198][0m Epoch[141] Batch[600] Speed: 421.217283 samples/sec loss: -31.71100 acc: 0.76228 ce: 0.66784 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:03:55 @trainer.py:173][0m Change temperature from 0.00961 to 0.00918
[33mIP:10.60.242.134 [0m[32m[0229 18:03:59 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:03:59 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883]
[33mIP:10.60.242.134 [0m[32m[0229 18:03:59 @trainer.py:234][0m acc 0.7883
[33mIP:10.60.242.134 [0m[32m[0229 18:03:59 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:03:59 @trainer.py:217][0m Start to train w for epoch 142
[33mIP:10.60.242.134 [0m[32m[0229 18:03:59 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:04:14 @trainer.py:198][0m Epoch[142] Batch[100] Speed: 291.885626 samples/sec loss: -31.71131 acc: 0.76238 ce: 0.66754 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:04:30 @trainer.py:198][0m Epoch[142] Batch[200] Speed: 397.554969 samples/sec loss: -31.71155 acc: 0.76247 ce: 0.66730 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:04:45 @trainer.py:198][0m Epoch[142] Batch[300] Speed: 408.050596 samples/sec loss: -31.71178 acc: 0.76256 ce: 0.66707 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:05:01 @trainer.py:198][0m Epoch[142] Batch[400] Speed: 410.789941 samples/sec loss: -31.71202 acc: 0.76264 ce: 0.66683 lat: -16.18942
[33mIP:10.60.242.134 [0m[32m[0229 18:05:16 @trainer.py:198][0m Epoch[142] Batch[500] Speed: 436.370749 samples/sec loss: -31.71222 acc: 0.76272 ce: 0.66663 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:05:31 @trainer.py:198][0m Epoch[142] Batch[600] Speed: 421.702666 samples/sec loss: -31.71241 acc: 0.76279 ce: 0.66644 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:05:34 @trainer.py:173][0m Change temperature from 0.00918 to 0.00878
[33mIP:10.60.242.134 [0m[32m[0229 18:05:38 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:05:38 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784]
[33mIP:10.60.242.134 [0m[32m[0229 18:05:38 @trainer.py:234][0m acc 0.7784
[33mIP:10.60.242.134 [0m[32m[0229 18:05:38 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:05:38 @trainer.py:217][0m Start to train w for epoch 143
[33mIP:10.60.242.134 [0m[32m[0229 18:05:38 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:05:55 @trainer.py:198][0m Epoch[143] Batch[100] Speed: 270.027829 samples/sec loss: -31.71271 acc: 0.76289 ce: 0.66614 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:06:10 @trainer.py:198][0m Epoch[143] Batch[200] Speed: 413.474449 samples/sec loss: -31.71295 acc: 0.76298 ce: 0.66591 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:06:25 @trainer.py:198][0m Epoch[143] Batch[300] Speed: 423.894466 samples/sec loss: -31.71318 acc: 0.76307 ce: 0.66568 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:06:41 @trainer.py:198][0m Epoch[143] Batch[400] Speed: 414.332639 samples/sec loss: -31.71339 acc: 0.76315 ce: 0.66547 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:06:56 @trainer.py:198][0m Epoch[143] Batch[500] Speed: 413.852943 samples/sec loss: -31.71362 acc: 0.76323 ce: 0.66524 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:07:11 @trainer.py:198][0m Epoch[143] Batch[600] Speed: 423.838298 samples/sec loss: -31.71383 acc: 0.76330 ce: 0.66503 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:07:15 @trainer.py:173][0m Change temperature from 0.00878 to 0.00839
[33mIP:10.60.242.134 [0m[32m[0229 18:07:18 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:07:18 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767]
[33mIP:10.60.242.134 [0m[32m[0229 18:07:18 @trainer.py:234][0m acc 0.7767
[33mIP:10.60.242.134 [0m[32m[0229 18:07:18 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:07:18 @trainer.py:217][0m Start to train w for epoch 144
[33mIP:10.60.242.134 [0m[32m[0229 18:07:18 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:07:34 @trainer.py:198][0m Epoch[144] Batch[100] Speed: 278.901717 samples/sec loss: -31.71414 acc: 0.76341 ce: 0.66472 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:07:50 @trainer.py:198][0m Epoch[144] Batch[200] Speed: 410.152757 samples/sec loss: -31.71437 acc: 0.76349 ce: 0.66450 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:08:05 @trainer.py:198][0m Epoch[144] Batch[300] Speed: 414.462004 samples/sec loss: -31.71459 acc: 0.76357 ce: 0.66428 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:08:21 @trainer.py:198][0m Epoch[144] Batch[400] Speed: 410.336560 samples/sec loss: -31.71481 acc: 0.76365 ce: 0.66406 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:08:36 @trainer.py:198][0m Epoch[144] Batch[500] Speed: 418.469842 samples/sec loss: -31.71501 acc: 0.76373 ce: 0.66385 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:08:51 @trainer.py:198][0m Epoch[144] Batch[600] Speed: 416.757144 samples/sec loss: -31.71523 acc: 0.76381 ce: 0.66364 lat: -16.18943
[33mIP:10.60.242.134 [0m[32m[0229 18:08:55 @trainer.py:173][0m Change temperature from 0.00839 to 0.00803
[33mIP:10.60.242.134 [0m[32m[0229 18:08:59 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:08:59 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813]
[33mIP:10.60.242.134 [0m[32m[0229 18:08:59 @trainer.py:234][0m acc 0.7813
[33mIP:10.60.242.134 [0m[32m[0229 18:08:59 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:08:59 @trainer.py:217][0m Start to train w for epoch 145
[33mIP:10.60.242.134 [0m[32m[0229 18:08:59 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:09:15 @trainer.py:198][0m Epoch[145] Batch[100] Speed: 274.355880 samples/sec loss: -31.71551 acc: 0.76391 ce: 0.66336 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:09:30 @trainer.py:198][0m Epoch[145] Batch[200] Speed: 405.685024 samples/sec loss: -31.71573 acc: 0.76399 ce: 0.66314 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:09:46 @trainer.py:198][0m Epoch[145] Batch[300] Speed: 404.469515 samples/sec loss: -31.71596 acc: 0.76407 ce: 0.66292 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:10:02 @trainer.py:198][0m Epoch[145] Batch[400] Speed: 403.596575 samples/sec loss: -31.71619 acc: 0.76415 ce: 0.66268 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:10:18 @trainer.py:198][0m Epoch[145] Batch[500] Speed: 410.276873 samples/sec loss: -31.71641 acc: 0.76423 ce: 0.66247 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:10:34 @trainer.py:198][0m Epoch[145] Batch[600] Speed: 404.673214 samples/sec loss: -31.71663 acc: 0.76431 ce: 0.66224 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:10:37 @trainer.py:173][0m Change temperature from 0.00803 to 0.00767
[33mIP:10.60.242.134 [0m[32m[0229 18:10:41 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:10:41 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836]
[33mIP:10.60.242.134 [0m[32m[0229 18:10:41 @trainer.py:234][0m acc 0.7836
[33mIP:10.60.242.134 [0m[32m[0229 18:10:41 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:10:41 @trainer.py:217][0m Start to train w for epoch 146
[33mIP:10.60.242.134 [0m[32m[0229 18:10:41 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:10:57 @trainer.py:198][0m Epoch[146] Batch[100] Speed: 275.494809 samples/sec loss: -31.71692 acc: 0.76442 ce: 0.66196 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:11:12 @trainer.py:198][0m Epoch[146] Batch[200] Speed: 428.769112 samples/sec loss: -31.71714 acc: 0.76449 ce: 0.66174 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:11:27 @trainer.py:198][0m Epoch[146] Batch[300] Speed: 427.507826 samples/sec loss: -31.71735 acc: 0.76457 ce: 0.66154 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:11:42 @trainer.py:198][0m Epoch[146] Batch[400] Speed: 408.189046 samples/sec loss: -31.71760 acc: 0.76466 ce: 0.66129 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:11:58 @trainer.py:198][0m Epoch[146] Batch[500] Speed: 419.824799 samples/sec loss: -31.71782 acc: 0.76474 ce: 0.66107 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:12:13 @trainer.py:198][0m Epoch[146] Batch[600] Speed: 429.267775 samples/sec loss: -31.71803 acc: 0.76482 ce: 0.66085 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:12:16 @trainer.py:173][0m Change temperature from 0.00767 to 0.00733
[33mIP:10.60.242.134 [0m[32m[0229 18:12:20 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:12:20 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927]
[33mIP:10.60.242.134 [0m[32m[0229 18:12:20 @trainer.py:234][0m acc 0.7927
[33mIP:10.60.242.134 [0m[32m[0229 18:12:20 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:12:20 @trainer.py:217][0m Start to train w for epoch 147
[33mIP:10.60.242.134 [0m[32m[0229 18:12:20 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:12:36 @trainer.py:198][0m Epoch[147] Batch[100] Speed: 270.710624 samples/sec loss: -31.71832 acc: 0.76492 ce: 0.66057 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:12:52 @trainer.py:198][0m Epoch[147] Batch[200] Speed: 415.233711 samples/sec loss: -31.71855 acc: 0.76500 ce: 0.66034 lat: -16.18944
[33mIP:10.60.242.134 [0m[32m[0229 18:13:07 @trainer.py:198][0m Epoch[147] Batch[300] Speed: 409.019031 samples/sec loss: -31.71878 acc: 0.76508 ce: 0.66011 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:13:23 @trainer.py:198][0m Epoch[147] Batch[400] Speed: 415.127108 samples/sec loss: -31.71899 acc: 0.76515 ce: 0.65990 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:13:38 @trainer.py:198][0m Epoch[147] Batch[500] Speed: 410.881818 samples/sec loss: -31.71921 acc: 0.76523 ce: 0.65968 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:13:53 @trainer.py:198][0m Epoch[147] Batch[600] Speed: 423.763280 samples/sec loss: -31.71944 acc: 0.76531 ce: 0.65945 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:13:57 @trainer.py:173][0m Change temperature from 0.00733 to 0.00701
[33mIP:10.60.242.134 [0m[32m[0229 18:14:01 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:14:01 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856]
[33mIP:10.60.242.134 [0m[32m[0229 18:14:01 @trainer.py:234][0m acc 0.7856
[33mIP:10.60.242.134 [0m[32m[0229 18:14:01 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:14:01 @trainer.py:217][0m Start to train w for epoch 148
[33mIP:10.60.242.134 [0m[32m[0229 18:14:01 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:14:16 @trainer.py:198][0m Epoch[148] Batch[100] Speed: 278.674668 samples/sec loss: -31.71974 acc: 0.76542 ce: 0.65915 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:14:32 @trainer.py:198][0m Epoch[148] Batch[200] Speed: 418.658779 samples/sec loss: -31.71997 acc: 0.76550 ce: 0.65892 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:14:47 @trainer.py:198][0m Epoch[148] Batch[300] Speed: 407.118167 samples/sec loss: -31.72020 acc: 0.76558 ce: 0.65870 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:15:02 @trainer.py:198][0m Epoch[148] Batch[400] Speed: 427.179394 samples/sec loss: -31.72042 acc: 0.76566 ce: 0.65848 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:15:16 @trainer.py:198][0m Epoch[148] Batch[500] Speed: 458.662780 samples/sec loss: -31.72067 acc: 0.76576 ce: 0.65824 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:15:31 @trainer.py:198][0m Epoch[148] Batch[600] Speed: 437.105207 samples/sec loss: -31.72090 acc: 0.76584 ce: 0.65800 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:15:35 @trainer.py:173][0m Change temperature from 0.00701 to 0.00670
[33mIP:10.60.242.134 [0m[32m[0229 18:15:38 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:15:38 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888]
[33mIP:10.60.242.134 [0m[32m[0229 18:15:38 @trainer.py:234][0m acc 0.7888
[33mIP:10.60.242.134 [0m[32m[0229 18:15:38 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:15:38 @trainer.py:217][0m Start to train w for epoch 149
[33mIP:10.60.242.134 [0m[32m[0229 18:15:38 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:15:54 @trainer.py:198][0m Epoch[149] Batch[100] Speed: 271.586401 samples/sec loss: -31.72118 acc: 0.76595 ce: 0.65773 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:16:10 @trainer.py:198][0m Epoch[149] Batch[200] Speed: 407.212597 samples/sec loss: -31.72139 acc: 0.76603 ce: 0.65751 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:16:26 @trainer.py:198][0m Epoch[149] Batch[300] Speed: 399.431026 samples/sec loss: -31.72161 acc: 0.76611 ce: 0.65729 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:16:41 @trainer.py:198][0m Epoch[149] Batch[400] Speed: 421.748905 samples/sec loss: -31.72183 acc: 0.76618 ce: 0.65708 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:16:57 @trainer.py:198][0m Epoch[149] Batch[500] Speed: 417.839268 samples/sec loss: -31.72206 acc: 0.76626 ce: 0.65685 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:17:11 @trainer.py:198][0m Epoch[149] Batch[600] Speed: 437.026223 samples/sec loss: -31.72227 acc: 0.76634 ce: 0.65664 lat: -16.18945
[33mIP:10.60.242.134 [0m[32m[0229 18:17:15 @trainer.py:173][0m Change temperature from 0.00670 to 0.00641
[33mIP:10.60.242.134 [0m[32m[0229 18:17:19 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:17:19 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896]
[33mIP:10.60.242.134 [0m[32m[0229 18:17:19 @trainer.py:234][0m acc 0.7896
[33mIP:10.60.242.134 [0m[32m[0229 18:17:19 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:17:19 @trainer.py:217][0m Start to train w for epoch 150
[33mIP:10.60.242.134 [0m[32m[0229 18:17:19 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:17:35 @trainer.py:198][0m Epoch[150] Batch[100] Speed: 272.362374 samples/sec loss: -31.72257 acc: 0.76644 ce: 0.65634 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:17:51 @trainer.py:198][0m Epoch[150] Batch[200] Speed: 405.306091 samples/sec loss: -31.72282 acc: 0.76653 ce: 0.65610 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:18:05 @trainer.py:198][0m Epoch[150] Batch[300] Speed: 439.982729 samples/sec loss: -31.72304 acc: 0.76662 ce: 0.65587 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:18:20 @trainer.py:198][0m Epoch[150] Batch[400] Speed: 422.445532 samples/sec loss: -31.72326 acc: 0.76669 ce: 0.65565 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:18:36 @trainer.py:198][0m Epoch[150] Batch[500] Speed: 414.292250 samples/sec loss: -31.72349 acc: 0.76678 ce: 0.65543 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:18:51 @trainer.py:198][0m Epoch[150] Batch[600] Speed: 418.287228 samples/sec loss: -31.72372 acc: 0.76686 ce: 0.65520 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:18:55 @trainer.py:173][0m Change temperature from 0.00641 to 0.00613
[33mIP:10.60.242.134 [0m[32m[0229 18:18:59 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:18:59 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941]
[33mIP:10.60.242.134 [0m[32m[0229 18:18:59 @trainer.py:234][0m acc 0.7941
[33mIP:10.60.242.134 [0m[32m[0229 18:18:59 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:18:59 @trainer.py:217][0m Start to train w for epoch 151
[33mIP:10.60.242.134 [0m[32m[0229 18:18:59 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:19:14 @trainer.py:198][0m Epoch[151] Batch[100] Speed: 275.380232 samples/sec loss: -31.72403 acc: 0.76696 ce: 0.65489 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:19:30 @trainer.py:198][0m Epoch[151] Batch[200] Speed: 407.816116 samples/sec loss: -31.72425 acc: 0.76704 ce: 0.65467 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:19:46 @trainer.py:198][0m Epoch[151] Batch[300] Speed: 407.887273 samples/sec loss: -31.72450 acc: 0.76713 ce: 0.65442 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:20:01 @trainer.py:198][0m Epoch[151] Batch[400] Speed: 408.430791 samples/sec loss: -31.72473 acc: 0.76722 ce: 0.65419 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:20:17 @trainer.py:198][0m Epoch[151] Batch[500] Speed: 412.525205 samples/sec loss: -31.72491 acc: 0.76729 ce: 0.65401 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:20:32 @trainer.py:198][0m Epoch[151] Batch[600] Speed: 418.144566 samples/sec loss: -31.72513 acc: 0.76737 ce: 0.65379 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:20:36 @trainer.py:173][0m Change temperature from 0.00613 to 0.00586
[33mIP:10.60.242.134 [0m[32m[0229 18:20:39 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:20:39 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936]
[33mIP:10.60.242.134 [0m[32m[0229 18:20:39 @trainer.py:234][0m acc 0.7936
[33mIP:10.60.242.134 [0m[32m[0229 18:20:39 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:20:39 @trainer.py:217][0m Start to train w for epoch 152
[33mIP:10.60.242.134 [0m[32m[0229 18:20:39 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:20:54 @trainer.py:198][0m Epoch[152] Batch[100] Speed: 288.085519 samples/sec loss: -31.72544 acc: 0.76748 ce: 0.65349 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:21:09 @trainer.py:198][0m Epoch[152] Batch[200] Speed: 452.522661 samples/sec loss: -31.72569 acc: 0.76757 ce: 0.65324 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:21:22 @trainer.py:198][0m Epoch[152] Batch[300] Speed: 466.459219 samples/sec loss: -31.72592 acc: 0.76766 ce: 0.65301 lat: -16.18946
[33mIP:10.60.242.134 [0m[32m[0229 18:21:38 @trainer.py:198][0m Epoch[152] Batch[400] Speed: 403.908268 samples/sec loss: -31.72615 acc: 0.76775 ce: 0.65278 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:21:54 @trainer.py:198][0m Epoch[152] Batch[500] Speed: 398.619640 samples/sec loss: -31.72638 acc: 0.76783 ce: 0.65255 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:22:10 @trainer.py:198][0m Epoch[152] Batch[600] Speed: 413.103907 samples/sec loss: -31.72658 acc: 0.76790 ce: 0.65235 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:22:13 @trainer.py:173][0m Change temperature from 0.00586 to 0.00560
[33mIP:10.60.242.134 [0m[32m[0229 18:22:17 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:22:17 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891]
[33mIP:10.60.242.134 [0m[32m[0229 18:22:17 @trainer.py:234][0m acc 0.7891
[33mIP:10.60.242.134 [0m[32m[0229 18:22:17 @trainer.py:235][0m max_acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 18:22:17 @trainer.py:217][0m Start to train w for epoch 153
[33mIP:10.60.242.134 [0m[32m[0229 18:22:17 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:22:33 @trainer.py:198][0m Epoch[153] Batch[100] Speed: 275.637715 samples/sec loss: -31.72688 acc: 0.76801 ce: 0.65206 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:22:48 @trainer.py:198][0m Epoch[153] Batch[200] Speed: 422.986660 samples/sec loss: -31.72713 acc: 0.76810 ce: 0.65181 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:23:03 @trainer.py:198][0m Epoch[153] Batch[300] Speed: 425.281563 samples/sec loss: -31.72737 acc: 0.76819 ce: 0.65157 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:23:19 @trainer.py:198][0m Epoch[153] Batch[400] Speed: 403.504900 samples/sec loss: -31.72760 acc: 0.76828 ce: 0.65133 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:23:35 @trainer.py:198][0m Epoch[153] Batch[500] Speed: 409.809363 samples/sec loss: -31.72782 acc: 0.76836 ce: 0.65112 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:23:50 @trainer.py:198][0m Epoch[153] Batch[600] Speed: 420.621159 samples/sec loss: -31.72802 acc: 0.76843 ce: 0.65091 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:23:53 @trainer.py:173][0m Change temperature from 0.00560 to 0.00535
[33mIP:10.60.242.134 [0m[32m[0229 18:23:57 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:23:57 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958]
[33mIP:10.60.242.134 [0m[32m[0229 18:23:57 @trainer.py:234][0m acc 0.7958
[33mIP:10.60.242.134 [0m[32m[0229 18:23:57 @trainer.py:235][0m max_acc 0.7958
[33mIP:10.60.242.134 [0m[32m[0229 18:23:57 @trainer.py:217][0m Start to train w for epoch 154
[33mIP:10.60.242.134 [0m[32m[0229 18:23:57 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:24:14 @trainer.py:198][0m Epoch[154] Batch[100] Speed: 269.619550 samples/sec loss: -31.72836 acc: 0.76855 ce: 0.65058 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:24:29 @trainer.py:198][0m Epoch[154] Batch[200] Speed: 411.681689 samples/sec loss: -31.72861 acc: 0.76864 ce: 0.65033 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:24:44 @trainer.py:198][0m Epoch[154] Batch[300] Speed: 432.572291 samples/sec loss: -31.72885 acc: 0.76873 ce: 0.65009 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:24:58 @trainer.py:198][0m Epoch[154] Batch[400] Speed: 452.727900 samples/sec loss: -31.72906 acc: 0.76880 ce: 0.64988 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:25:12 @trainer.py:198][0m Epoch[154] Batch[500] Speed: 464.393807 samples/sec loss: -31.72928 acc: 0.76888 ce: 0.64966 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:25:26 @trainer.py:198][0m Epoch[154] Batch[600] Speed: 448.222355 samples/sec loss: -31.72949 acc: 0.76895 ce: 0.64946 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:25:30 @trainer.py:173][0m Change temperature from 0.00535 to 0.00512
[33mIP:10.60.242.134 [0m[32m[0229 18:25:34 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:25:34 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814]
[33mIP:10.60.242.134 [0m[32m[0229 18:25:34 @trainer.py:234][0m acc 0.7814
[33mIP:10.60.242.134 [0m[32m[0229 18:25:34 @trainer.py:235][0m max_acc 0.7958
[33mIP:10.60.242.134 [0m[32m[0229 18:25:34 @trainer.py:217][0m Start to train w for epoch 155
[33mIP:10.60.242.134 [0m[32m[0229 18:25:34 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:25:49 @trainer.py:198][0m Epoch[155] Batch[100] Speed: 279.593123 samples/sec loss: -31.72978 acc: 0.76905 ce: 0.64917 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:26:04 @trainer.py:198][0m Epoch[155] Batch[200] Speed: 432.394875 samples/sec loss: -31.73003 acc: 0.76914 ce: 0.64892 lat: -16.18947
[33mIP:10.60.242.134 [0m[32m[0229 18:26:19 @trainer.py:198][0m Epoch[155] Batch[300] Speed: 422.446722 samples/sec loss: -31.73028 acc: 0.76923 ce: 0.64868 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:26:34 @trainer.py:198][0m Epoch[155] Batch[400] Speed: 412.872749 samples/sec loss: -31.73049 acc: 0.76931 ce: 0.64846 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:26:49 @trainer.py:198][0m Epoch[155] Batch[500] Speed: 426.717746 samples/sec loss: -31.73073 acc: 0.76940 ce: 0.64823 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:27:04 @trainer.py:198][0m Epoch[155] Batch[600] Speed: 425.751054 samples/sec loss: -31.73094 acc: 0.76947 ce: 0.64802 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:27:08 @trainer.py:173][0m Change temperature from 0.00512 to 0.00489
[33mIP:10.60.242.134 [0m[32m[0229 18:27:12 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:27:12 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838]
[33mIP:10.60.242.134 [0m[32m[0229 18:27:12 @trainer.py:234][0m acc 0.7838
[33mIP:10.60.242.134 [0m[32m[0229 18:27:12 @trainer.py:235][0m max_acc 0.7958
[33mIP:10.60.242.134 [0m[32m[0229 18:27:12 @trainer.py:217][0m Start to train w for epoch 156
[33mIP:10.60.242.134 [0m[32m[0229 18:27:12 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:27:28 @trainer.py:198][0m Epoch[156] Batch[100] Speed: 268.460165 samples/sec loss: -31.73124 acc: 0.76958 ce: 0.64772 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:27:44 @trainer.py:198][0m Epoch[156] Batch[200] Speed: 408.796940 samples/sec loss: -31.73147 acc: 0.76967 ce: 0.64748 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:27:59 @trainer.py:198][0m Epoch[156] Batch[300] Speed: 421.467358 samples/sec loss: -31.73172 acc: 0.76976 ce: 0.64724 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:28:14 @trainer.py:198][0m Epoch[156] Batch[400] Speed: 432.946119 samples/sec loss: -31.73196 acc: 0.76985 ce: 0.64700 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:28:29 @trainer.py:198][0m Epoch[156] Batch[500] Speed: 414.640627 samples/sec loss: -31.73219 acc: 0.76993 ce: 0.64677 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:28:45 @trainer.py:198][0m Epoch[156] Batch[600] Speed: 412.375189 samples/sec loss: -31.73242 acc: 0.77002 ce: 0.64654 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:28:49 @trainer.py:173][0m Change temperature from 0.00489 to 0.00468
[33mIP:10.60.242.134 [0m[32m[0229 18:28:52 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:28:52 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793]
[33mIP:10.60.242.134 [0m[32m[0229 18:28:52 @trainer.py:234][0m acc 0.793
[33mIP:10.60.242.134 [0m[32m[0229 18:28:52 @trainer.py:235][0m max_acc 0.7958
[33mIP:10.60.242.134 [0m[32m[0229 18:28:52 @trainer.py:217][0m Start to train w for epoch 157
[33mIP:10.60.242.134 [0m[32m[0229 18:28:52 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:29:07 @trainer.py:198][0m Epoch[157] Batch[100] Speed: 282.978556 samples/sec loss: -31.73272 acc: 0.77013 ce: 0.64624 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:29:23 @trainer.py:198][0m Epoch[157] Batch[200] Speed: 417.303696 samples/sec loss: -31.73296 acc: 0.77021 ce: 0.64600 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:29:38 @trainer.py:198][0m Epoch[157] Batch[300] Speed: 419.623650 samples/sec loss: -31.73320 acc: 0.77030 ce: 0.64577 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:29:54 @trainer.py:198][0m Epoch[157] Batch[400] Speed: 406.484756 samples/sec loss: -31.73341 acc: 0.77037 ce: 0.64556 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:30:09 @trainer.py:198][0m Epoch[157] Batch[500] Speed: 420.003902 samples/sec loss: -31.73361 acc: 0.77044 ce: 0.64536 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:30:24 @trainer.py:198][0m Epoch[157] Batch[600] Speed: 416.600058 samples/sec loss: -31.73385 acc: 0.77053 ce: 0.64512 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:30:27 @trainer.py:173][0m Change temperature from 0.00468 to 0.00447
[33mIP:10.60.242.134 [0m[32m[0229 18:30:31 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:30:31 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989]
[33mIP:10.60.242.134 [0m[32m[0229 18:30:31 @trainer.py:234][0m acc 0.7989
[33mIP:10.60.242.134 [0m[32m[0229 18:30:31 @trainer.py:235][0m max_acc 0.7989
[33mIP:10.60.242.134 [0m[32m[0229 18:30:31 @trainer.py:217][0m Start to train w for epoch 158
[33mIP:10.60.242.134 [0m[32m[0229 18:30:31 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:30:47 @trainer.py:198][0m Epoch[158] Batch[100] Speed: 283.863010 samples/sec loss: -31.73416 acc: 0.77064 ce: 0.64481 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:31:03 @trainer.py:198][0m Epoch[158] Batch[200] Speed: 411.023499 samples/sec loss: -31.73441 acc: 0.77073 ce: 0.64456 lat: -16.18948
[33mIP:10.60.242.134 [0m[32m[0229 18:31:18 @trainer.py:198][0m Epoch[158] Batch[300] Speed: 417.144403 samples/sec loss: -31.73465 acc: 0.77081 ce: 0.64432 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:31:33 @trainer.py:198][0m Epoch[158] Batch[400] Speed: 425.533636 samples/sec loss: -31.73487 acc: 0.77090 ce: 0.64410 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:31:48 @trainer.py:198][0m Epoch[158] Batch[500] Speed: 416.448977 samples/sec loss: -31.73511 acc: 0.77098 ce: 0.64386 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:32:04 @trainer.py:198][0m Epoch[158] Batch[600] Speed: 409.807048 samples/sec loss: -31.73536 acc: 0.77107 ce: 0.64362 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:32:07 @trainer.py:173][0m Change temperature from 0.00447 to 0.00427
[33mIP:10.60.242.134 [0m[32m[0229 18:32:11 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:32:11 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912]
[33mIP:10.60.242.134 [0m[32m[0229 18:32:11 @trainer.py:234][0m acc 0.7912
[33mIP:10.60.242.134 [0m[32m[0229 18:32:11 @trainer.py:235][0m max_acc 0.7989
[33mIP:10.60.242.134 [0m[32m[0229 18:32:11 @trainer.py:217][0m Start to train w for epoch 159
[33mIP:10.60.242.134 [0m[32m[0229 18:32:11 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:32:27 @trainer.py:198][0m Epoch[159] Batch[100] Speed: 279.873543 samples/sec loss: -31.73566 acc: 0.77118 ce: 0.64332 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:32:42 @trainer.py:198][0m Epoch[159] Batch[200] Speed: 411.382095 samples/sec loss: -31.73590 acc: 0.77127 ce: 0.64308 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:32:58 @trainer.py:198][0m Epoch[159] Batch[300] Speed: 421.269948 samples/sec loss: -31.73615 acc: 0.77135 ce: 0.64283 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:33:13 @trainer.py:198][0m Epoch[159] Batch[400] Speed: 424.035110 samples/sec loss: -31.73638 acc: 0.77143 ce: 0.64260 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:33:28 @trainer.py:198][0m Epoch[159] Batch[500] Speed: 406.940709 samples/sec loss: -31.73661 acc: 0.77151 ce: 0.64237 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:33:43 @trainer.py:198][0m Epoch[159] Batch[600] Speed: 426.431831 samples/sec loss: -31.73683 acc: 0.77159 ce: 0.64215 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:33:47 @trainer.py:173][0m Change temperature from 0.00427 to 0.00409
[33mIP:10.60.242.134 [0m[32m[0229 18:33:51 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:33:51 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914]
[33mIP:10.60.242.134 [0m[32m[0229 18:33:51 @trainer.py:234][0m acc 0.7914
[33mIP:10.60.242.134 [0m[32m[0229 18:33:51 @trainer.py:235][0m max_acc 0.7989
[33mIP:10.60.242.134 [0m[32m[0229 18:33:51 @trainer.py:217][0m Start to train w for epoch 160
[33mIP:10.60.242.134 [0m[32m[0229 18:33:51 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:34:06 @trainer.py:198][0m Epoch[160] Batch[100] Speed: 281.947588 samples/sec loss: -31.73715 acc: 0.77170 ce: 0.64183 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:34:20 @trainer.py:198][0m Epoch[160] Batch[200] Speed: 451.442718 samples/sec loss: -31.73739 acc: 0.77179 ce: 0.64159 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:34:35 @trainer.py:198][0m Epoch[160] Batch[300] Speed: 443.787071 samples/sec loss: -31.73762 acc: 0.77187 ce: 0.64137 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:34:50 @trainer.py:198][0m Epoch[160] Batch[400] Speed: 406.714799 samples/sec loss: -31.73786 acc: 0.77196 ce: 0.64112 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:35:05 @trainer.py:198][0m Epoch[160] Batch[500] Speed: 429.905677 samples/sec loss: -31.73808 acc: 0.77204 ce: 0.64090 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:35:21 @trainer.py:198][0m Epoch[160] Batch[600] Speed: 417.000227 samples/sec loss: -31.73833 acc: 0.77212 ce: 0.64066 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:35:24 @trainer.py:173][0m Change temperature from 0.00409 to 0.00391
[33mIP:10.60.242.134 [0m[32m[0229 18:35:27 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:35:27 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978]
[33mIP:10.60.242.134 [0m[32m[0229 18:35:27 @trainer.py:234][0m acc 0.7978
[33mIP:10.60.242.134 [0m[32m[0229 18:35:27 @trainer.py:235][0m max_acc 0.7989
[33mIP:10.60.242.134 [0m[32m[0229 18:35:27 @trainer.py:217][0m Start to train w for epoch 161
[33mIP:10.60.242.134 [0m[32m[0229 18:35:27 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:35:43 @trainer.py:198][0m Epoch[161] Batch[100] Speed: 281.944665 samples/sec loss: -31.73866 acc: 0.77224 ce: 0.64033 lat: -16.18949
[33mIP:10.60.242.134 [0m[32m[0229 18:35:59 @trainer.py:198][0m Epoch[161] Batch[200] Speed: 411.533011 samples/sec loss: -31.73889 acc: 0.77232 ce: 0.64010 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:36:15 @trainer.py:198][0m Epoch[161] Batch[300] Speed: 405.974275 samples/sec loss: -31.73913 acc: 0.77240 ce: 0.63986 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:36:30 @trainer.py:198][0m Epoch[161] Batch[400] Speed: 430.295744 samples/sec loss: -31.73936 acc: 0.77249 ce: 0.63963 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:36:45 @trainer.py:198][0m Epoch[161] Batch[500] Speed: 418.532432 samples/sec loss: -31.73958 acc: 0.77257 ce: 0.63941 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:37:00 @trainer.py:198][0m Epoch[161] Batch[600] Speed: 424.366693 samples/sec loss: -31.73979 acc: 0.77264 ce: 0.63920 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:37:03 @trainer.py:173][0m Change temperature from 0.00391 to 0.00373
[33mIP:10.60.242.134 [0m[32m[0229 18:37:07 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:37:07 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959]
[33mIP:10.60.242.134 [0m[32m[0229 18:37:07 @trainer.py:234][0m acc 0.7959
[33mIP:10.60.242.134 [0m[32m[0229 18:37:07 @trainer.py:235][0m max_acc 0.7989
[33mIP:10.60.242.134 [0m[32m[0229 18:37:07 @trainer.py:217][0m Start to train w for epoch 162
[33mIP:10.60.242.134 [0m[32m[0229 18:37:07 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:37:23 @trainer.py:198][0m Epoch[162] Batch[100] Speed: 274.735141 samples/sec loss: -31.74010 acc: 0.77275 ce: 0.63890 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:37:39 @trainer.py:198][0m Epoch[162] Batch[200] Speed: 410.089797 samples/sec loss: -31.74034 acc: 0.77284 ce: 0.63866 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:37:54 @trainer.py:198][0m Epoch[162] Batch[300] Speed: 431.305667 samples/sec loss: -31.74058 acc: 0.77293 ce: 0.63841 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:38:09 @trainer.py:198][0m Epoch[162] Batch[400] Speed: 427.764427 samples/sec loss: -31.74081 acc: 0.77302 ce: 0.63819 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:38:23 @trainer.py:198][0m Epoch[162] Batch[500] Speed: 430.431951 samples/sec loss: -31.74104 acc: 0.77310 ce: 0.63795 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:38:38 @trainer.py:198][0m Epoch[162] Batch[600] Speed: 428.234391 samples/sec loss: -31.74128 acc: 0.77318 ce: 0.63772 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:38:42 @trainer.py:173][0m Change temperature from 0.00373 to 0.00357
[33mIP:10.60.242.134 [0m[32m[0229 18:38:46 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:38:46 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998]
[33mIP:10.60.242.134 [0m[32m[0229 18:38:46 @trainer.py:234][0m acc 0.7998
[33mIP:10.60.242.134 [0m[32m[0229 18:38:46 @trainer.py:235][0m max_acc 0.7998
[33mIP:10.60.242.134 [0m[32m[0229 18:38:46 @trainer.py:217][0m Start to train w for epoch 163
[33mIP:10.60.242.134 [0m[32m[0229 18:38:46 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:39:02 @trainer.py:198][0m Epoch[163] Batch[100] Speed: 270.521163 samples/sec loss: -31.74159 acc: 0.77329 ce: 0.63741 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:39:18 @trainer.py:198][0m Epoch[163] Batch[200] Speed: 411.937596 samples/sec loss: -31.74184 acc: 0.77338 ce: 0.63716 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:39:33 @trainer.py:198][0m Epoch[163] Batch[300] Speed: 404.398363 samples/sec loss: -31.74208 acc: 0.77346 ce: 0.63693 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:39:49 @trainer.py:198][0m Epoch[163] Batch[400] Speed: 408.960301 samples/sec loss: -31.74232 acc: 0.77355 ce: 0.63669 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:40:04 @trainer.py:198][0m Epoch[163] Batch[500] Speed: 427.118452 samples/sec loss: -31.74255 acc: 0.77364 ce: 0.63645 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:40:20 @trainer.py:198][0m Epoch[163] Batch[600] Speed: 408.416181 samples/sec loss: -31.74281 acc: 0.77373 ce: 0.63620 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:40:23 @trainer.py:173][0m Change temperature from 0.00357 to 0.00341
[33mIP:10.60.242.134 [0m[32m[0229 18:40:27 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:40:27 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946]
[33mIP:10.60.242.134 [0m[32m[0229 18:40:27 @trainer.py:234][0m acc 0.7946
[33mIP:10.60.242.134 [0m[32m[0229 18:40:27 @trainer.py:235][0m max_acc 0.7998
[33mIP:10.60.242.134 [0m[32m[0229 18:40:27 @trainer.py:217][0m Start to train w for epoch 164
[33mIP:10.60.242.134 [0m[32m[0229 18:40:27 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:40:42 @trainer.py:198][0m Epoch[164] Batch[100] Speed: 287.404612 samples/sec loss: -31.74313 acc: 0.77384 ce: 0.63588 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:40:57 @trainer.py:198][0m Epoch[164] Batch[200] Speed: 430.813143 samples/sec loss: -31.74337 acc: 0.77393 ce: 0.63563 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:41:12 @trainer.py:198][0m Epoch[164] Batch[300] Speed: 431.045140 samples/sec loss: -31.74362 acc: 0.77402 ce: 0.63539 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:41:27 @trainer.py:198][0m Epoch[164] Batch[400] Speed: 417.279150 samples/sec loss: -31.74385 acc: 0.77410 ce: 0.63516 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:41:43 @trainer.py:198][0m Epoch[164] Batch[500] Speed: 402.251068 samples/sec loss: -31.74407 acc: 0.77417 ce: 0.63494 lat: -16.18950
[33mIP:10.60.242.134 [0m[32m[0229 18:41:58 @trainer.py:198][0m Epoch[164] Batch[600] Speed: 418.016290 samples/sec loss: -31.74430 acc: 0.77425 ce: 0.63471 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:42:02 @trainer.py:173][0m Change temperature from 0.00341 to 0.00326
[33mIP:10.60.242.134 [0m[32m[0229 18:42:05 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:42:05 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029]
[33mIP:10.60.242.134 [0m[32m[0229 18:42:05 @trainer.py:234][0m acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:42:05 @trainer.py:235][0m max_acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:42:05 @trainer.py:217][0m Start to train w for epoch 165
[33mIP:10.60.242.134 [0m[32m[0229 18:42:05 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:42:21 @trainer.py:198][0m Epoch[165] Batch[100] Speed: 282.834072 samples/sec loss: -31.74461 acc: 0.77437 ce: 0.63440 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:42:36 @trainer.py:198][0m Epoch[165] Batch[200] Speed: 418.751773 samples/sec loss: -31.74485 acc: 0.77446 ce: 0.63417 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:42:52 @trainer.py:198][0m Epoch[165] Batch[300] Speed: 412.724631 samples/sec loss: -31.74509 acc: 0.77454 ce: 0.63393 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:43:07 @trainer.py:198][0m Epoch[165] Batch[400] Speed: 420.959899 samples/sec loss: -31.74533 acc: 0.77463 ce: 0.63368 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:43:22 @trainer.py:198][0m Epoch[165] Batch[500] Speed: 428.065689 samples/sec loss: -31.74557 acc: 0.77471 ce: 0.63345 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:43:37 @trainer.py:198][0m Epoch[165] Batch[600] Speed: 432.916472 samples/sec loss: -31.74580 acc: 0.77480 ce: 0.63322 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:43:40 @trainer.py:173][0m Change temperature from 0.00326 to 0.00312
[33mIP:10.60.242.134 [0m[32m[0229 18:43:44 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:43:44 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878]
[33mIP:10.60.242.134 [0m[32m[0229 18:43:44 @trainer.py:234][0m acc 0.7878
[33mIP:10.60.242.134 [0m[32m[0229 18:43:44 @trainer.py:235][0m max_acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:43:44 @trainer.py:217][0m Start to train w for epoch 166
[33mIP:10.60.242.134 [0m[32m[0229 18:43:44 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:44:00 @trainer.py:198][0m Epoch[166] Batch[100] Speed: 278.440124 samples/sec loss: -31.74611 acc: 0.77491 ce: 0.63291 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:44:16 @trainer.py:198][0m Epoch[166] Batch[200] Speed: 401.617082 samples/sec loss: -31.74635 acc: 0.77500 ce: 0.63267 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:44:31 @trainer.py:198][0m Epoch[166] Batch[300] Speed: 403.291881 samples/sec loss: -31.74660 acc: 0.77509 ce: 0.63242 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:44:47 @trainer.py:198][0m Epoch[166] Batch[400] Speed: 415.489534 samples/sec loss: -31.74683 acc: 0.77517 ce: 0.63219 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:45:02 @trainer.py:198][0m Epoch[166] Batch[500] Speed: 421.922969 samples/sec loss: -31.74706 acc: 0.77525 ce: 0.63196 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:45:17 @trainer.py:198][0m Epoch[166] Batch[600] Speed: 424.835872 samples/sec loss: -31.74730 acc: 0.77533 ce: 0.63173 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:45:21 @trainer.py:173][0m Change temperature from 0.00312 to 0.00298
[33mIP:10.60.242.134 [0m[32m[0229 18:45:24 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:45:24 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793]
[33mIP:10.60.242.134 [0m[32m[0229 18:45:24 @trainer.py:234][0m acc 0.793
[33mIP:10.60.242.134 [0m[32m[0229 18:45:24 @trainer.py:235][0m max_acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:45:24 @trainer.py:217][0m Start to train w for epoch 167
[33mIP:10.60.242.134 [0m[32m[0229 18:45:24 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:45:41 @trainer.py:198][0m Epoch[167] Batch[100] Speed: 270.702142 samples/sec loss: -31.74762 acc: 0.77545 ce: 0.63140 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:45:56 @trainer.py:198][0m Epoch[167] Batch[200] Speed: 409.852756 samples/sec loss: -31.74787 acc: 0.77554 ce: 0.63115 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:46:12 @trainer.py:198][0m Epoch[167] Batch[300] Speed: 409.179644 samples/sec loss: -31.74813 acc: 0.77563 ce: 0.63089 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:46:28 @trainer.py:198][0m Epoch[167] Batch[400] Speed: 409.902968 samples/sec loss: -31.74837 acc: 0.77572 ce: 0.63066 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:46:42 @trainer.py:198][0m Epoch[167] Batch[500] Speed: 459.429479 samples/sec loss: -31.74860 acc: 0.77580 ce: 0.63043 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:46:56 @trainer.py:198][0m Epoch[167] Batch[600] Speed: 449.921684 samples/sec loss: -31.74882 acc: 0.77589 ce: 0.63020 lat: -16.18951
[33mIP:10.60.242.134 [0m[32m[0229 18:46:59 @trainer.py:173][0m Change temperature from 0.00298 to 0.00285
[33mIP:10.60.242.134 [0m[32m[0229 18:47:03 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:47:03 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978]
[33mIP:10.60.242.134 [0m[32m[0229 18:47:03 @trainer.py:234][0m acc 0.7978
[33mIP:10.60.242.134 [0m[32m[0229 18:47:03 @trainer.py:235][0m max_acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:47:03 @trainer.py:217][0m Start to train w for epoch 168
[33mIP:10.60.242.134 [0m[32m[0229 18:47:03 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:47:19 @trainer.py:198][0m Epoch[168] Batch[100] Speed: 281.177442 samples/sec loss: -31.74914 acc: 0.77600 ce: 0.62989 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:47:34 @trainer.py:198][0m Epoch[168] Batch[200] Speed: 416.647022 samples/sec loss: -31.74940 acc: 0.77610 ce: 0.62963 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:47:49 @trainer.py:198][0m Epoch[168] Batch[300] Speed: 413.109407 samples/sec loss: -31.74963 acc: 0.77618 ce: 0.62940 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:48:05 @trainer.py:198][0m Epoch[168] Batch[400] Speed: 413.532662 samples/sec loss: -31.74988 acc: 0.77627 ce: 0.62915 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:48:21 @trainer.py:198][0m Epoch[168] Batch[500] Speed: 408.845069 samples/sec loss: -31.75010 acc: 0.77635 ce: 0.62893 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:48:35 @trainer.py:198][0m Epoch[168] Batch[600] Speed: 428.393756 samples/sec loss: -31.75033 acc: 0.77644 ce: 0.62870 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:48:39 @trainer.py:173][0m Change temperature from 0.00285 to 0.00273
[33mIP:10.60.242.134 [0m[32m[0229 18:48:42 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:48:42 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922]
[33mIP:10.60.242.134 [0m[32m[0229 18:48:42 @trainer.py:234][0m acc 0.7922
[33mIP:10.60.242.134 [0m[32m[0229 18:48:42 @trainer.py:235][0m max_acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:48:42 @trainer.py:217][0m Start to train w for epoch 169
[33mIP:10.60.242.134 [0m[32m[0229 18:48:42 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:48:57 @trainer.py:198][0m Epoch[169] Batch[100] Speed: 298.683465 samples/sec loss: -31.75065 acc: 0.77655 ce: 0.62838 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:49:10 @trainer.py:198][0m Epoch[169] Batch[200] Speed: 483.886118 samples/sec loss: -31.75090 acc: 0.77664 ce: 0.62814 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:49:25 @trainer.py:198][0m Epoch[169] Batch[300] Speed: 430.233717 samples/sec loss: -31.75115 acc: 0.77673 ce: 0.62788 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:49:39 @trainer.py:198][0m Epoch[169] Batch[400] Speed: 448.195915 samples/sec loss: -31.75140 acc: 0.77681 ce: 0.62764 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:49:55 @trainer.py:198][0m Epoch[169] Batch[500] Speed: 414.572082 samples/sec loss: -31.75162 acc: 0.77689 ce: 0.62742 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:50:09 @trainer.py:198][0m Epoch[169] Batch[600] Speed: 442.176396 samples/sec loss: -31.75184 acc: 0.77697 ce: 0.62720 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:50:13 @trainer.py:173][0m Change temperature from 0.00273 to 0.00261
[33mIP:10.60.242.134 [0m[32m[0229 18:50:16 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:50:16 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892]
[33mIP:10.60.242.134 [0m[32m[0229 18:50:16 @trainer.py:234][0m acc 0.7892
[33mIP:10.60.242.134 [0m[32m[0229 18:50:16 @trainer.py:235][0m max_acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:50:16 @trainer.py:217][0m Start to train w for epoch 170
[33mIP:10.60.242.134 [0m[32m[0229 18:50:16 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:50:31 @trainer.py:198][0m Epoch[170] Batch[100] Speed: 289.063446 samples/sec loss: -31.75215 acc: 0.77708 ce: 0.62689 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:50:46 @trainer.py:198][0m Epoch[170] Batch[200] Speed: 430.209632 samples/sec loss: -31.75241 acc: 0.77717 ce: 0.62663 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:51:01 @trainer.py:198][0m Epoch[170] Batch[300] Speed: 426.836283 samples/sec loss: -31.75264 acc: 0.77726 ce: 0.62640 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:51:16 @trainer.py:198][0m Epoch[170] Batch[400] Speed: 437.728284 samples/sec loss: -31.75288 acc: 0.77734 ce: 0.62616 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:51:30 @trainer.py:198][0m Epoch[170] Batch[500] Speed: 441.551793 samples/sec loss: -31.75312 acc: 0.77743 ce: 0.62592 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:51:46 @trainer.py:198][0m Epoch[170] Batch[600] Speed: 416.514189 samples/sec loss: -31.75337 acc: 0.77752 ce: 0.62568 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:51:49 @trainer.py:173][0m Change temperature from 0.00261 to 0.00249
[33mIP:10.60.242.134 [0m[32m[0229 18:51:53 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:51:53 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027]
[33mIP:10.60.242.134 [0m[32m[0229 18:51:53 @trainer.py:234][0m acc 0.8027
[33mIP:10.60.242.134 [0m[32m[0229 18:51:53 @trainer.py:235][0m max_acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:51:53 @trainer.py:217][0m Start to train w for epoch 171
[33mIP:10.60.242.134 [0m[32m[0229 18:51:53 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:52:08 @trainer.py:198][0m Epoch[171] Batch[100] Speed: 283.023799 samples/sec loss: -31.75368 acc: 0.77762 ce: 0.62537 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:52:23 @trainer.py:198][0m Epoch[171] Batch[200] Speed: 425.946422 samples/sec loss: -31.75393 acc: 0.77771 ce: 0.62512 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:52:38 @trainer.py:198][0m Epoch[171] Batch[300] Speed: 433.878752 samples/sec loss: -31.75418 acc: 0.77781 ce: 0.62487 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:52:53 @trainer.py:198][0m Epoch[171] Batch[400] Speed: 440.824784 samples/sec loss: -31.75444 acc: 0.77790 ce: 0.62461 lat: -16.18952
[33mIP:10.60.242.134 [0m[32m[0229 18:53:08 @trainer.py:198][0m Epoch[171] Batch[500] Speed: 419.706482 samples/sec loss: -31.75467 acc: 0.77799 ce: 0.62438 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:53:23 @trainer.py:198][0m Epoch[171] Batch[600] Speed: 415.879304 samples/sec loss: -31.75491 acc: 0.77807 ce: 0.62414 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:53:27 @trainer.py:173][0m Change temperature from 0.00249 to 0.00238
[33mIP:10.60.242.134 [0m[32m[0229 18:53:31 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:53:31 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024]
[33mIP:10.60.242.134 [0m[32m[0229 18:53:31 @trainer.py:234][0m acc 0.8024
[33mIP:10.60.242.134 [0m[32m[0229 18:53:31 @trainer.py:235][0m max_acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 18:53:31 @trainer.py:217][0m Start to train w for epoch 172
[33mIP:10.60.242.134 [0m[32m[0229 18:53:31 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:53:47 @trainer.py:198][0m Epoch[172] Batch[100] Speed: 267.490380 samples/sec loss: -31.75522 acc: 0.77819 ce: 0.62383 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:54:03 @trainer.py:198][0m Epoch[172] Batch[200] Speed: 411.000038 samples/sec loss: -31.75546 acc: 0.77827 ce: 0.62360 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:54:18 @trainer.py:198][0m Epoch[172] Batch[300] Speed: 410.655683 samples/sec loss: -31.75569 acc: 0.77835 ce: 0.62336 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:54:34 @trainer.py:198][0m Epoch[172] Batch[400] Speed: 418.622687 samples/sec loss: -31.75593 acc: 0.77844 ce: 0.62313 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:54:49 @trainer.py:198][0m Epoch[172] Batch[500] Speed: 413.269488 samples/sec loss: -31.75617 acc: 0.77852 ce: 0.62289 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:55:03 @trainer.py:198][0m Epoch[172] Batch[600] Speed: 445.769462 samples/sec loss: -31.75640 acc: 0.77860 ce: 0.62266 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:55:07 @trainer.py:173][0m Change temperature from 0.00238 to 0.00228
[33mIP:10.60.242.134 [0m[32m[0229 18:55:10 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:55:10 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057]
[33mIP:10.60.242.134 [0m[32m[0229 18:55:10 @trainer.py:234][0m acc 0.8057
[33mIP:10.60.242.134 [0m[32m[0229 18:55:10 @trainer.py:235][0m max_acc 0.8057
[33mIP:10.60.242.134 [0m[32m[0229 18:55:10 @trainer.py:217][0m Start to train w for epoch 173
[33mIP:10.60.242.134 [0m[32m[0229 18:55:10 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:55:26 @trainer.py:198][0m Epoch[173] Batch[100] Speed: 282.141931 samples/sec loss: -31.75672 acc: 0.77872 ce: 0.62234 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:55:41 @trainer.py:198][0m Epoch[173] Batch[200] Speed: 419.814169 samples/sec loss: -31.75696 acc: 0.77881 ce: 0.62209 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:55:57 @trainer.py:198][0m Epoch[173] Batch[300] Speed: 414.398374 samples/sec loss: -31.75720 acc: 0.77888 ce: 0.62185 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:56:12 @trainer.py:198][0m Epoch[173] Batch[400] Speed: 427.057038 samples/sec loss: -31.75745 acc: 0.77897 ce: 0.62161 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:56:27 @trainer.py:198][0m Epoch[173] Batch[500] Speed: 420.599786 samples/sec loss: -31.75771 acc: 0.77907 ce: 0.62135 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:56:42 @trainer.py:198][0m Epoch[173] Batch[600] Speed: 428.674463 samples/sec loss: -31.75793 acc: 0.77915 ce: 0.62113 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:56:46 @trainer.py:173][0m Change temperature from 0.00228 to 0.00218
[33mIP:10.60.242.134 [0m[32m[0229 18:56:49 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:56:49 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015]
[33mIP:10.60.242.134 [0m[32m[0229 18:56:49 @trainer.py:234][0m acc 0.8015
[33mIP:10.60.242.134 [0m[32m[0229 18:56:49 @trainer.py:235][0m max_acc 0.8057
[33mIP:10.60.242.134 [0m[32m[0229 18:56:49 @trainer.py:217][0m Start to train w for epoch 174
[33mIP:10.60.242.134 [0m[32m[0229 18:56:49 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:57:05 @trainer.py:198][0m Epoch[174] Batch[100] Speed: 274.691376 samples/sec loss: -31.75824 acc: 0.77926 ce: 0.62082 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:57:20 @trainer.py:198][0m Epoch[174] Batch[200] Speed: 422.753240 samples/sec loss: -31.75849 acc: 0.77936 ce: 0.62057 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:57:36 @trainer.py:198][0m Epoch[174] Batch[300] Speed: 417.125521 samples/sec loss: -31.75875 acc: 0.77945 ce: 0.62032 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:57:52 @trainer.py:198][0m Epoch[174] Batch[400] Speed: 401.470420 samples/sec loss: -31.75899 acc: 0.77953 ce: 0.62008 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:58:07 @trainer.py:198][0m Epoch[174] Batch[500] Speed: 421.111351 samples/sec loss: -31.75921 acc: 0.77961 ce: 0.61985 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:58:22 @trainer.py:198][0m Epoch[174] Batch[600] Speed: 418.063619 samples/sec loss: -31.75944 acc: 0.77969 ce: 0.61963 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:58:26 @trainer.py:173][0m Change temperature from 0.00218 to 0.00208
[33mIP:10.60.242.134 [0m[32m[0229 18:58:29 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 18:58:29 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981]
[33mIP:10.60.242.134 [0m[32m[0229 18:58:29 @trainer.py:234][0m acc 0.7981
[33mIP:10.60.242.134 [0m[32m[0229 18:58:29 @trainer.py:235][0m max_acc 0.8057
[33mIP:10.60.242.134 [0m[32m[0229 18:58:29 @trainer.py:217][0m Start to train w for epoch 175
[33mIP:10.60.242.134 [0m[32m[0229 18:58:29 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 18:58:45 @trainer.py:198][0m Epoch[175] Batch[100] Speed: 278.627236 samples/sec loss: -31.75974 acc: 0.77980 ce: 0.61932 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:59:01 @trainer.py:198][0m Epoch[175] Batch[200] Speed: 407.056469 samples/sec loss: -31.76000 acc: 0.77989 ce: 0.61907 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:59:16 @trainer.py:198][0m Epoch[175] Batch[300] Speed: 410.624073 samples/sec loss: -31.76023 acc: 0.77997 ce: 0.61883 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:59:32 @trainer.py:198][0m Epoch[175] Batch[400] Speed: 409.549731 samples/sec loss: -31.76047 acc: 0.78006 ce: 0.61860 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 18:59:47 @trainer.py:198][0m Epoch[175] Batch[500] Speed: 437.791670 samples/sec loss: -31.76070 acc: 0.78014 ce: 0.61837 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 19:00:01 @trainer.py:198][0m Epoch[175] Batch[600] Speed: 440.879092 samples/sec loss: -31.76095 acc: 0.78023 ce: 0.61812 lat: -16.18953
[33mIP:10.60.242.134 [0m[32m[0229 19:00:05 @trainer.py:173][0m Change temperature from 0.00208 to 0.00199
[33mIP:10.60.242.134 [0m[32m[0229 19:00:09 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:00:09 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994]
[33mIP:10.60.242.134 [0m[32m[0229 19:00:09 @trainer.py:234][0m acc 0.7994
[33mIP:10.60.242.134 [0m[32m[0229 19:00:09 @trainer.py:235][0m max_acc 0.8057
[33mIP:10.60.242.134 [0m[32m[0229 19:00:09 @trainer.py:217][0m Start to train w for epoch 176
[33mIP:10.60.242.134 [0m[32m[0229 19:00:09 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:00:25 @trainer.py:198][0m Epoch[176] Batch[100] Speed: 270.665777 samples/sec loss: -31.76127 acc: 0.78034 ce: 0.61780 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:00:40 @trainer.py:198][0m Epoch[176] Batch[200] Speed: 417.545385 samples/sec loss: -31.76152 acc: 0.78043 ce: 0.61756 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:00:56 @trainer.py:198][0m Epoch[176] Batch[300] Speed: 408.352741 samples/sec loss: -31.76176 acc: 0.78052 ce: 0.61731 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:01:11 @trainer.py:198][0m Epoch[176] Batch[400] Speed: 428.797159 samples/sec loss: -31.76201 acc: 0.78061 ce: 0.61706 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:01:26 @trainer.py:198][0m Epoch[176] Batch[500] Speed: 430.358721 samples/sec loss: -31.76226 acc: 0.78070 ce: 0.61681 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:01:41 @trainer.py:198][0m Epoch[176] Batch[600] Speed: 417.759291 samples/sec loss: -31.76250 acc: 0.78079 ce: 0.61658 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:01:45 @trainer.py:173][0m Change temperature from 0.00199 to 0.00190
[33mIP:10.60.242.134 [0m[32m[0229 19:01:48 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:01:48 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974]
[33mIP:10.60.242.134 [0m[32m[0229 19:01:48 @trainer.py:234][0m acc 0.7974
[33mIP:10.60.242.134 [0m[32m[0229 19:01:48 @trainer.py:235][0m max_acc 0.8057
[33mIP:10.60.242.134 [0m[32m[0229 19:01:48 @trainer.py:217][0m Start to train w for epoch 177
[33mIP:10.60.242.134 [0m[32m[0229 19:01:48 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:02:03 @trainer.py:198][0m Epoch[177] Batch[100] Speed: 295.738391 samples/sec loss: -31.76281 acc: 0.78090 ce: 0.61626 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:02:18 @trainer.py:198][0m Epoch[177] Batch[200] Speed: 429.170155 samples/sec loss: -31.76305 acc: 0.78098 ce: 0.61602 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:02:33 @trainer.py:198][0m Epoch[177] Batch[300] Speed: 411.096926 samples/sec loss: -31.76329 acc: 0.78106 ce: 0.61579 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:02:49 @trainer.py:198][0m Epoch[177] Batch[400] Speed: 407.266081 samples/sec loss: -31.76355 acc: 0.78116 ce: 0.61553 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:03:04 @trainer.py:198][0m Epoch[177] Batch[500] Speed: 413.707513 samples/sec loss: -31.76378 acc: 0.78124 ce: 0.61530 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:03:20 @trainer.py:198][0m Epoch[177] Batch[600] Speed: 412.733166 samples/sec loss: -31.76402 acc: 0.78133 ce: 0.61506 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:03:23 @trainer.py:173][0m Change temperature from 0.00190 to 0.00182
[33mIP:10.60.242.134 [0m[32m[0229 19:03:27 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:03:27 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058]
[33mIP:10.60.242.134 [0m[32m[0229 19:03:27 @trainer.py:234][0m acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:03:27 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:03:27 @trainer.py:217][0m Start to train w for epoch 178
[33mIP:10.60.242.134 [0m[32m[0229 19:03:27 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:03:44 @trainer.py:198][0m Epoch[178] Batch[100] Speed: 269.400348 samples/sec loss: -31.76434 acc: 0.78144 ce: 0.61474 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:03:59 @trainer.py:198][0m Epoch[178] Batch[200] Speed: 414.197967 samples/sec loss: -31.76459 acc: 0.78153 ce: 0.61449 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:04:15 @trainer.py:198][0m Epoch[178] Batch[300] Speed: 409.130969 samples/sec loss: -31.76486 acc: 0.78162 ce: 0.61423 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:04:30 @trainer.py:198][0m Epoch[178] Batch[400] Speed: 411.419522 samples/sec loss: -31.76509 acc: 0.78171 ce: 0.61400 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:04:46 @trainer.py:198][0m Epoch[178] Batch[500] Speed: 415.864047 samples/sec loss: -31.76533 acc: 0.78179 ce: 0.61375 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:05:01 @trainer.py:198][0m Epoch[178] Batch[600] Speed: 428.003907 samples/sec loss: -31.76557 acc: 0.78187 ce: 0.61351 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:05:04 @trainer.py:173][0m Change temperature from 0.00182 to 0.00174
[33mIP:10.60.242.134 [0m[32m[0229 19:05:07 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:05:07 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947]
[33mIP:10.60.242.134 [0m[32m[0229 19:05:07 @trainer.py:234][0m acc 0.7947
[33mIP:10.60.242.134 [0m[32m[0229 19:05:07 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:05:07 @trainer.py:217][0m Start to train w for epoch 179
[33mIP:10.60.242.134 [0m[32m[0229 19:05:07 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:05:24 @trainer.py:198][0m Epoch[179] Batch[100] Speed: 277.261155 samples/sec loss: -31.76590 acc: 0.78199 ce: 0.61318 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:05:39 @trainer.py:198][0m Epoch[179] Batch[200] Speed: 404.278722 samples/sec loss: -31.76615 acc: 0.78208 ce: 0.61294 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:05:55 @trainer.py:198][0m Epoch[179] Batch[300] Speed: 417.945167 samples/sec loss: -31.76640 acc: 0.78217 ce: 0.61269 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:06:10 @trainer.py:198][0m Epoch[179] Batch[400] Speed: 421.267217 samples/sec loss: -31.76664 acc: 0.78225 ce: 0.61245 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:06:25 @trainer.py:198][0m Epoch[179] Batch[500] Speed: 434.089129 samples/sec loss: -31.76689 acc: 0.78234 ce: 0.61220 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:06:40 @trainer.py:198][0m Epoch[179] Batch[600] Speed: 415.063690 samples/sec loss: -31.76712 acc: 0.78243 ce: 0.61197 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:06:44 @trainer.py:173][0m Change temperature from 0.00174 to 0.00166
[33mIP:10.60.242.134 [0m[32m[0229 19:06:48 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:06:48 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031]
[33mIP:10.60.242.134 [0m[32m[0229 19:06:48 @trainer.py:234][0m acc 0.8031
[33mIP:10.60.242.134 [0m[32m[0229 19:06:48 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:06:48 @trainer.py:217][0m Start to train w for epoch 180
[33mIP:10.60.242.134 [0m[32m[0229 19:06:48 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:07:03 @trainer.py:198][0m Epoch[180] Batch[100] Speed: 279.813061 samples/sec loss: -31.76745 acc: 0.78254 ce: 0.61164 lat: -16.18954
[33mIP:10.60.242.134 [0m[32m[0229 19:07:19 @trainer.py:198][0m Epoch[180] Batch[200] Speed: 413.322068 samples/sec loss: -31.76771 acc: 0.78264 ce: 0.61138 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:07:34 @trainer.py:198][0m Epoch[180] Batch[300] Speed: 421.954830 samples/sec loss: -31.76794 acc: 0.78272 ce: 0.61115 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:07:48 @trainer.py:198][0m Epoch[180] Batch[400] Speed: 439.844483 samples/sec loss: -31.76819 acc: 0.78281 ce: 0.61090 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:08:04 @trainer.py:198][0m Epoch[180] Batch[500] Speed: 414.191307 samples/sec loss: -31.76843 acc: 0.78290 ce: 0.61066 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:08:19 @trainer.py:198][0m Epoch[180] Batch[600] Speed: 428.253363 samples/sec loss: -31.76868 acc: 0.78299 ce: 0.61041 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:08:22 @trainer.py:173][0m Change temperature from 0.00166 to 0.00159
[33mIP:10.60.242.134 [0m[32m[0229 19:08:25 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:08:25 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971]
[33mIP:10.60.242.134 [0m[32m[0229 19:08:25 @trainer.py:234][0m acc 0.7971
[33mIP:10.60.242.134 [0m[32m[0229 19:08:25 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:08:25 @trainer.py:217][0m Start to train w for epoch 181
[33mIP:10.60.242.134 [0m[32m[0229 19:08:25 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:08:41 @trainer.py:198][0m Epoch[181] Batch[100] Speed: 285.097549 samples/sec loss: -31.76901 acc: 0.78311 ce: 0.61008 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:08:57 @trainer.py:198][0m Epoch[181] Batch[200] Speed: 409.217607 samples/sec loss: -31.76928 acc: 0.78320 ce: 0.60982 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:09:12 @trainer.py:198][0m Epoch[181] Batch[300] Speed: 418.882613 samples/sec loss: -31.76953 acc: 0.78329 ce: 0.60956 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:09:27 @trainer.py:198][0m Epoch[181] Batch[400] Speed: 423.860644 samples/sec loss: -31.76979 acc: 0.78338 ce: 0.60931 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:09:42 @trainer.py:198][0m Epoch[181] Batch[500] Speed: 415.906025 samples/sec loss: -31.77002 acc: 0.78347 ce: 0.60908 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:09:57 @trainer.py:198][0m Epoch[181] Batch[600] Speed: 441.148789 samples/sec loss: -31.77026 acc: 0.78355 ce: 0.60883 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:10:01 @trainer.py:173][0m Change temperature from 0.00159 to 0.00152
[33mIP:10.60.242.134 [0m[32m[0229 19:10:05 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:10:05 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046]
[33mIP:10.60.242.134 [0m[32m[0229 19:10:05 @trainer.py:234][0m acc 0.8046
[33mIP:10.60.242.134 [0m[32m[0229 19:10:05 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:10:05 @trainer.py:217][0m Start to train w for epoch 182
[33mIP:10.60.242.134 [0m[32m[0229 19:10:05 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:10:21 @trainer.py:198][0m Epoch[182] Batch[100] Speed: 265.866982 samples/sec loss: -31.77059 acc: 0.78366 ce: 0.60851 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:10:37 @trainer.py:198][0m Epoch[182] Batch[200] Speed: 405.322088 samples/sec loss: -31.77084 acc: 0.78375 ce: 0.60826 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:10:53 @trainer.py:198][0m Epoch[182] Batch[300] Speed: 406.787132 samples/sec loss: -31.77109 acc: 0.78384 ce: 0.60801 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:11:08 @trainer.py:198][0m Epoch[182] Batch[400] Speed: 414.942544 samples/sec loss: -31.77134 acc: 0.78393 ce: 0.60776 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:11:23 @trainer.py:198][0m Epoch[182] Batch[500] Speed: 415.327908 samples/sec loss: -31.77160 acc: 0.78402 ce: 0.60750 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:11:39 @trainer.py:198][0m Epoch[182] Batch[600] Speed: 417.299240 samples/sec loss: -31.77184 acc: 0.78411 ce: 0.60726 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:11:42 @trainer.py:173][0m Change temperature from 0.00152 to 0.00145
[33mIP:10.60.242.134 [0m[32m[0229 19:11:46 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:11:46 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965]
[33mIP:10.60.242.134 [0m[32m[0229 19:11:46 @trainer.py:234][0m acc 0.7965
[33mIP:10.60.242.134 [0m[32m[0229 19:11:46 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:11:46 @trainer.py:217][0m Start to train w for epoch 183
[33mIP:10.60.242.134 [0m[32m[0229 19:11:46 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:12:01 @trainer.py:198][0m Epoch[183] Batch[100] Speed: 285.582619 samples/sec loss: -31.77215 acc: 0.78422 ce: 0.60695 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:12:16 @trainer.py:198][0m Epoch[183] Batch[200] Speed: 422.869672 samples/sec loss: -31.77239 acc: 0.78430 ce: 0.60671 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:12:32 @trainer.py:198][0m Epoch[183] Batch[300] Speed: 415.287550 samples/sec loss: -31.77264 acc: 0.78439 ce: 0.60646 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:12:47 @trainer.py:198][0m Epoch[183] Batch[400] Speed: 420.746746 samples/sec loss: -31.77289 acc: 0.78448 ce: 0.60621 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:13:02 @trainer.py:198][0m Epoch[183] Batch[500] Speed: 419.443855 samples/sec loss: -31.77314 acc: 0.78457 ce: 0.60596 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:13:17 @trainer.py:198][0m Epoch[183] Batch[600] Speed: 421.155849 samples/sec loss: -31.77339 acc: 0.78465 ce: 0.60572 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:13:21 @trainer.py:173][0m Change temperature from 0.00145 to 0.00139
[33mIP:10.60.242.134 [0m[32m[0229 19:13:24 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:13:24 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014]
[33mIP:10.60.242.134 [0m[32m[0229 19:13:24 @trainer.py:234][0m acc 0.8014
[33mIP:10.60.242.134 [0m[32m[0229 19:13:24 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:13:24 @trainer.py:217][0m Start to train w for epoch 184
[33mIP:10.60.242.134 [0m[32m[0229 19:13:24 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:13:40 @trainer.py:198][0m Epoch[184] Batch[100] Speed: 280.134611 samples/sec loss: -31.77369 acc: 0.78476 ce: 0.60541 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:13:56 @trainer.py:198][0m Epoch[184] Batch[200] Speed: 395.519917 samples/sec loss: -31.77396 acc: 0.78485 ce: 0.60515 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:14:12 @trainer.py:198][0m Epoch[184] Batch[300] Speed: 412.890492 samples/sec loss: -31.77420 acc: 0.78493 ce: 0.60491 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:14:27 @trainer.py:198][0m Epoch[184] Batch[400] Speed: 412.893991 samples/sec loss: -31.77445 acc: 0.78502 ce: 0.60466 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:14:43 @trainer.py:198][0m Epoch[184] Batch[500] Speed: 418.370413 samples/sec loss: -31.77468 acc: 0.78510 ce: 0.60443 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:14:58 @trainer.py:198][0m Epoch[184] Batch[600] Speed: 407.421523 samples/sec loss: -31.77493 acc: 0.78519 ce: 0.60417 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:15:02 @trainer.py:173][0m Change temperature from 0.00139 to 0.00133
[33mIP:10.60.242.134 [0m[32m[0229 19:15:06 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:15:06 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023]
[33mIP:10.60.242.134 [0m[32m[0229 19:15:06 @trainer.py:234][0m acc 0.8023
[33mIP:10.60.242.134 [0m[32m[0229 19:15:06 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:15:06 @trainer.py:217][0m Start to train w for epoch 185
[33mIP:10.60.242.134 [0m[32m[0229 19:15:06 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:15:22 @trainer.py:198][0m Epoch[185] Batch[100] Speed: 275.195851 samples/sec loss: -31.77526 acc: 0.78530 ce: 0.60385 lat: -16.18955
[33mIP:10.60.242.134 [0m[32m[0229 19:15:37 @trainer.py:198][0m Epoch[185] Batch[200] Speed: 411.097864 samples/sec loss: -31.77552 acc: 0.78539 ce: 0.60359 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:15:53 @trainer.py:198][0m Epoch[185] Batch[300] Speed: 404.645543 samples/sec loss: -31.77576 acc: 0.78547 ce: 0.60335 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:16:08 @trainer.py:198][0m Epoch[185] Batch[400] Speed: 416.765801 samples/sec loss: -31.77600 acc: 0.78555 ce: 0.60311 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:16:24 @trainer.py:198][0m Epoch[185] Batch[500] Speed: 418.185507 samples/sec loss: -31.77625 acc: 0.78564 ce: 0.60287 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:16:39 @trainer.py:198][0m Epoch[185] Batch[600] Speed: 425.473763 samples/sec loss: -31.77648 acc: 0.78572 ce: 0.60264 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:16:43 @trainer.py:173][0m Change temperature from 0.00133 to 0.00127
[33mIP:10.60.242.134 [0m[32m[0229 19:16:46 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:16:46 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024]
[33mIP:10.60.242.134 [0m[32m[0229 19:16:46 @trainer.py:234][0m acc 0.8024
[33mIP:10.60.242.134 [0m[32m[0229 19:16:46 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:16:46 @trainer.py:217][0m Start to train w for epoch 186
[33mIP:10.60.242.134 [0m[32m[0229 19:16:46 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:17:02 @trainer.py:198][0m Epoch[186] Batch[100] Speed: 270.989995 samples/sec loss: -31.77680 acc: 0.78584 ce: 0.60231 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:17:18 @trainer.py:198][0m Epoch[186] Batch[200] Speed: 409.716652 samples/sec loss: -31.77707 acc: 0.78593 ce: 0.60205 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:17:34 @trainer.py:198][0m Epoch[186] Batch[300] Speed: 409.265586 samples/sec loss: -31.77733 acc: 0.78603 ce: 0.60179 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:17:49 @trainer.py:198][0m Epoch[186] Batch[400] Speed: 420.019214 samples/sec loss: -31.77757 acc: 0.78611 ce: 0.60154 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:18:04 @trainer.py:198][0m Epoch[186] Batch[500] Speed: 420.300139 samples/sec loss: -31.77781 acc: 0.78620 ce: 0.60130 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:18:19 @trainer.py:198][0m Epoch[186] Batch[600] Speed: 436.264433 samples/sec loss: -31.77805 acc: 0.78628 ce: 0.60106 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:18:22 @trainer.py:173][0m Change temperature from 0.00127 to 0.00121
[33mIP:10.60.242.134 [0m[32m[0229 19:18:26 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:18:26 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022]
[33mIP:10.60.242.134 [0m[32m[0229 19:18:26 @trainer.py:234][0m acc 0.8022
[33mIP:10.60.242.134 [0m[32m[0229 19:18:26 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:18:26 @trainer.py:217][0m Start to train w for epoch 187
[33mIP:10.60.242.134 [0m[32m[0229 19:18:26 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:18:42 @trainer.py:198][0m Epoch[187] Batch[100] Speed: 274.595068 samples/sec loss: -31.77835 acc: 0.78639 ce: 0.60076 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:18:58 @trainer.py:198][0m Epoch[187] Batch[200] Speed: 401.130818 samples/sec loss: -31.77860 acc: 0.78648 ce: 0.60051 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:19:14 @trainer.py:198][0m Epoch[187] Batch[300] Speed: 392.158113 samples/sec loss: -31.77886 acc: 0.78657 ce: 0.60026 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:19:30 @trainer.py:198][0m Epoch[187] Batch[400] Speed: 414.026072 samples/sec loss: -31.77910 acc: 0.78666 ce: 0.60002 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:19:45 @trainer.py:198][0m Epoch[187] Batch[500] Speed: 409.029944 samples/sec loss: -31.77936 acc: 0.78674 ce: 0.59976 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:20:00 @trainer.py:198][0m Epoch[187] Batch[600] Speed: 429.071461 samples/sec loss: -31.77961 acc: 0.78683 ce: 0.59952 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:20:04 @trainer.py:173][0m Change temperature from 0.00121 to 0.00116
[33mIP:10.60.242.134 [0m[32m[0229 19:20:08 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:20:08 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056]
[33mIP:10.60.242.134 [0m[32m[0229 19:20:08 @trainer.py:234][0m acc 0.8056
[33mIP:10.60.242.134 [0m[32m[0229 19:20:08 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:20:08 @trainer.py:217][0m Start to train w for epoch 188
[33mIP:10.60.242.134 [0m[32m[0229 19:20:08 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:20:23 @trainer.py:198][0m Epoch[188] Batch[100] Speed: 280.690296 samples/sec loss: -31.77992 acc: 0.78695 ce: 0.59921 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:20:39 @trainer.py:198][0m Epoch[188] Batch[200] Speed: 413.135112 samples/sec loss: -31.78016 acc: 0.78704 ce: 0.59896 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:20:54 @trainer.py:198][0m Epoch[188] Batch[300] Speed: 424.459247 samples/sec loss: -31.78042 acc: 0.78712 ce: 0.59870 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:21:09 @trainer.py:198][0m Epoch[188] Batch[400] Speed: 411.719334 samples/sec loss: -31.78066 acc: 0.78721 ce: 0.59846 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:21:24 @trainer.py:198][0m Epoch[188] Batch[500] Speed: 431.020106 samples/sec loss: -31.78091 acc: 0.78730 ce: 0.59822 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:21:39 @trainer.py:198][0m Epoch[188] Batch[600] Speed: 419.705524 samples/sec loss: -31.78116 acc: 0.78739 ce: 0.59796 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:21:43 @trainer.py:173][0m Change temperature from 0.00116 to 0.00111
[33mIP:10.60.242.134 [0m[32m[0229 19:21:47 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:21:47 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051]
[33mIP:10.60.242.134 [0m[32m[0229 19:21:47 @trainer.py:234][0m acc 0.8051
[33mIP:10.60.242.134 [0m[32m[0229 19:21:47 @trainer.py:235][0m max_acc 0.8058
[33mIP:10.60.242.134 [0m[32m[0229 19:21:47 @trainer.py:217][0m Start to train w for epoch 189
[33mIP:10.60.242.134 [0m[32m[0229 19:21:47 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:22:02 @trainer.py:198][0m Epoch[189] Batch[100] Speed: 277.556693 samples/sec loss: -31.78149 acc: 0.78750 ce: 0.59764 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:22:18 @trainer.py:198][0m Epoch[189] Batch[200] Speed: 407.531412 samples/sec loss: -31.78173 acc: 0.78759 ce: 0.59739 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:22:33 @trainer.py:198][0m Epoch[189] Batch[300] Speed: 427.050122 samples/sec loss: -31.78198 acc: 0.78768 ce: 0.59715 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:22:49 @trainer.py:198][0m Epoch[189] Batch[400] Speed: 405.482621 samples/sec loss: -31.78223 acc: 0.78776 ce: 0.59690 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:23:04 @trainer.py:198][0m Epoch[189] Batch[500] Speed: 414.040441 samples/sec loss: -31.78249 acc: 0.78785 ce: 0.59664 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:23:20 @trainer.py:198][0m Epoch[189] Batch[600] Speed: 424.509302 samples/sec loss: -31.78273 acc: 0.78794 ce: 0.59639 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:23:23 @trainer.py:173][0m Change temperature from 0.00111 to 0.00106
[33mIP:10.60.242.134 [0m[32m[0229 19:23:27 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:23:27 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102]
[33mIP:10.60.242.134 [0m[32m[0229 19:23:27 @trainer.py:234][0m acc 0.8102
[33mIP:10.60.242.134 [0m[32m[0229 19:23:27 @trainer.py:235][0m max_acc 0.8102
[33mIP:10.60.242.134 [0m[32m[0229 19:23:27 @trainer.py:217][0m Start to train w for epoch 190
[33mIP:10.60.242.134 [0m[32m[0229 19:23:27 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:23:45 @trainer.py:198][0m Epoch[190] Batch[100] Speed: 253.982613 samples/sec loss: -31.78306 acc: 0.78805 ce: 0.59607 lat: -16.18956
[33mIP:10.60.242.134 [0m[32m[0229 19:24:01 @trainer.py:198][0m Epoch[190] Batch[200] Speed: 404.117352 samples/sec loss: -31.78332 acc: 0.78814 ce: 0.59581 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:24:16 @trainer.py:198][0m Epoch[190] Batch[300] Speed: 422.389077 samples/sec loss: -31.78357 acc: 0.78823 ce: 0.59556 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:24:31 @trainer.py:198][0m Epoch[190] Batch[400] Speed: 406.300864 samples/sec loss: -31.78383 acc: 0.78832 ce: 0.59531 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:24:47 @trainer.py:198][0m Epoch[190] Batch[500] Speed: 408.754611 samples/sec loss: -31.78407 acc: 0.78841 ce: 0.59507 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:25:02 @trainer.py:198][0m Epoch[190] Batch[600] Speed: 425.581320 samples/sec loss: -31.78432 acc: 0.78850 ce: 0.59482 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:25:06 @trainer.py:173][0m Change temperature from 0.00106 to 0.00101
[33mIP:10.60.242.134 [0m[32m[0229 19:25:10 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:25:10 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098]
[33mIP:10.60.242.134 [0m[32m[0229 19:25:10 @trainer.py:234][0m acc 0.8098
[33mIP:10.60.242.134 [0m[32m[0229 19:25:10 @trainer.py:235][0m max_acc 0.8102
[33mIP:10.60.242.134 [0m[32m[0229 19:25:10 @trainer.py:217][0m Start to train w for epoch 191
[33mIP:10.60.242.134 [0m[32m[0229 19:25:10 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:25:26 @trainer.py:198][0m Epoch[191] Batch[100] Speed: 262.779361 samples/sec loss: -31.78465 acc: 0.78862 ce: 0.59448 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:25:42 @trainer.py:198][0m Epoch[191] Batch[200] Speed: 410.315705 samples/sec loss: -31.78490 acc: 0.78870 ce: 0.59423 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:25:57 @trainer.py:198][0m Epoch[191] Batch[300] Speed: 423.257227 samples/sec loss: -31.78516 acc: 0.78880 ce: 0.59398 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:26:13 @trainer.py:198][0m Epoch[191] Batch[400] Speed: 416.119455 samples/sec loss: -31.78541 acc: 0.78888 ce: 0.59373 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:26:28 @trainer.py:198][0m Epoch[191] Batch[500] Speed: 410.783592 samples/sec loss: -31.78567 acc: 0.78897 ce: 0.59347 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:26:44 @trainer.py:198][0m Epoch[191] Batch[600] Speed: 394.146708 samples/sec loss: -31.78591 acc: 0.78906 ce: 0.59323 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:26:48 @trainer.py:173][0m Change temperature from 0.00101 to 0.00097
[33mIP:10.60.242.134 [0m[32m[0229 19:26:52 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:26:52 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013]
[33mIP:10.60.242.134 [0m[32m[0229 19:26:52 @trainer.py:234][0m acc 0.8013
[33mIP:10.60.242.134 [0m[32m[0229 19:26:52 @trainer.py:235][0m max_acc 0.8102
[33mIP:10.60.242.134 [0m[32m[0229 19:26:52 @trainer.py:217][0m Start to train w for epoch 192
[33mIP:10.60.242.134 [0m[32m[0229 19:26:52 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:27:08 @trainer.py:198][0m Epoch[192] Batch[100] Speed: 270.161026 samples/sec loss: -31.78623 acc: 0.78917 ce: 0.59290 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:27:24 @trainer.py:198][0m Epoch[192] Batch[200] Speed: 408.481786 samples/sec loss: -31.78650 acc: 0.78926 ce: 0.59264 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:27:39 @trainer.py:198][0m Epoch[192] Batch[300] Speed: 413.028421 samples/sec loss: -31.78674 acc: 0.78935 ce: 0.59239 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:27:55 @trainer.py:198][0m Epoch[192] Batch[400] Speed: 408.392141 samples/sec loss: -31.78699 acc: 0.78944 ce: 0.59215 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:28:11 @trainer.py:198][0m Epoch[192] Batch[500] Speed: 406.111055 samples/sec loss: -31.78724 acc: 0.78953 ce: 0.59189 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:28:26 @trainer.py:198][0m Epoch[192] Batch[600] Speed: 427.262761 samples/sec loss: -31.78750 acc: 0.78962 ce: 0.59164 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:28:29 @trainer.py:173][0m Change temperature from 0.00097 to 0.00093
[33mIP:10.60.242.134 [0m[32m[0229 19:28:34 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:28:34 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803]
[33mIP:10.60.242.134 [0m[32m[0229 19:28:34 @trainer.py:234][0m acc 0.803
[33mIP:10.60.242.134 [0m[32m[0229 19:28:34 @trainer.py:235][0m max_acc 0.8102
[33mIP:10.60.242.134 [0m[32m[0229 19:28:34 @trainer.py:217][0m Start to train w for epoch 193
[33mIP:10.60.242.134 [0m[32m[0229 19:28:34 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:28:51 @trainer.py:198][0m Epoch[193] Batch[100] Speed: 256.597105 samples/sec loss: -31.78782 acc: 0.78973 ce: 0.59132 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:29:07 @trainer.py:198][0m Epoch[193] Batch[200] Speed: 394.084950 samples/sec loss: -31.78808 acc: 0.78982 ce: 0.59106 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:29:22 @trainer.py:198][0m Epoch[193] Batch[300] Speed: 412.168202 samples/sec loss: -31.78833 acc: 0.78991 ce: 0.59082 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:29:37 @trainer.py:198][0m Epoch[193] Batch[400] Speed: 432.463575 samples/sec loss: -31.78858 acc: 0.79000 ce: 0.59057 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:29:53 @trainer.py:198][0m Epoch[193] Batch[500] Speed: 413.060688 samples/sec loss: -31.78882 acc: 0.79009 ce: 0.59032 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:30:08 @trainer.py:198][0m Epoch[193] Batch[600] Speed: 414.117927 samples/sec loss: -31.78907 acc: 0.79018 ce: 0.59007 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:30:12 @trainer.py:173][0m Change temperature from 0.00093 to 0.00088
[33mIP:10.60.242.134 [0m[32m[0229 19:30:15 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:30:15 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144]
[33mIP:10.60.242.134 [0m[32m[0229 19:30:15 @trainer.py:234][0m acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:30:15 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:30:15 @trainer.py:217][0m Start to train w for epoch 194
[33mIP:10.60.242.134 [0m[32m[0229 19:30:15 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:30:31 @trainer.py:198][0m Epoch[194] Batch[100] Speed: 278.776891 samples/sec loss: -31.78940 acc: 0.79029 ce: 0.58974 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:30:47 @trainer.py:198][0m Epoch[194] Batch[200] Speed: 406.565530 samples/sec loss: -31.78965 acc: 0.79038 ce: 0.58949 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:31:03 @trainer.py:198][0m Epoch[194] Batch[300] Speed: 400.047004 samples/sec loss: -31.78989 acc: 0.79047 ce: 0.58925 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:31:18 @trainer.py:198][0m Epoch[194] Batch[400] Speed: 413.208977 samples/sec loss: -31.79016 acc: 0.79057 ce: 0.58899 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:31:33 @trainer.py:198][0m Epoch[194] Batch[500] Speed: 426.169674 samples/sec loss: -31.79041 acc: 0.79066 ce: 0.58873 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:31:49 @trainer.py:198][0m Epoch[194] Batch[600] Speed: 422.515296 samples/sec loss: -31.79065 acc: 0.79074 ce: 0.58849 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:31:52 @trainer.py:173][0m Change temperature from 0.00088 to 0.00085
[33mIP:10.60.242.134 [0m[32m[0229 19:31:56 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:31:56 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105]
[33mIP:10.60.242.134 [0m[32m[0229 19:31:56 @trainer.py:234][0m acc 0.8105
[33mIP:10.60.242.134 [0m[32m[0229 19:31:56 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:31:56 @trainer.py:217][0m Start to train w for epoch 195
[33mIP:10.60.242.134 [0m[32m[0229 19:31:56 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:32:12 @trainer.py:198][0m Epoch[195] Batch[100] Speed: 266.902998 samples/sec loss: -31.79099 acc: 0.79086 ce: 0.58816 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:32:28 @trainer.py:198][0m Epoch[195] Batch[200] Speed: 405.604919 samples/sec loss: -31.79124 acc: 0.79095 ce: 0.58791 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:32:44 @trainer.py:198][0m Epoch[195] Batch[300] Speed: 417.513874 samples/sec loss: -31.79148 acc: 0.79104 ce: 0.58767 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:32:59 @trainer.py:198][0m Epoch[195] Batch[400] Speed: 406.994165 samples/sec loss: -31.79174 acc: 0.79113 ce: 0.58741 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:33:15 @trainer.py:198][0m Epoch[195] Batch[500] Speed: 417.930851 samples/sec loss: -31.79199 acc: 0.79123 ce: 0.58716 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:33:30 @trainer.py:198][0m Epoch[195] Batch[600] Speed: 411.869019 samples/sec loss: -31.79224 acc: 0.79131 ce: 0.58691 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:33:34 @trainer.py:173][0m Change temperature from 0.00085 to 0.00081
[33mIP:10.60.242.134 [0m[32m[0229 19:33:37 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:33:37 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003]
[33mIP:10.60.242.134 [0m[32m[0229 19:33:37 @trainer.py:234][0m acc 0.8003
[33mIP:10.60.242.134 [0m[32m[0229 19:33:37 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:33:37 @trainer.py:217][0m Start to train w for epoch 196
[33mIP:10.60.242.134 [0m[32m[0229 19:33:37 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:33:53 @trainer.py:198][0m Epoch[196] Batch[100] Speed: 278.087584 samples/sec loss: -31.79256 acc: 0.79142 ce: 0.58659 lat: -16.18957
[33mIP:10.60.242.134 [0m[32m[0229 19:34:09 @trainer.py:198][0m Epoch[196] Batch[200] Speed: 403.205299 samples/sec loss: -31.79282 acc: 0.79152 ce: 0.58633 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:34:25 @trainer.py:198][0m Epoch[196] Batch[300] Speed: 410.094791 samples/sec loss: -31.79308 acc: 0.79161 ce: 0.58607 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:34:40 @trainer.py:198][0m Epoch[196] Batch[400] Speed: 417.324094 samples/sec loss: -31.79332 acc: 0.79169 ce: 0.58583 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:34:55 @trainer.py:198][0m Epoch[196] Batch[500] Speed: 420.147368 samples/sec loss: -31.79357 acc: 0.79179 ce: 0.58558 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:35:11 @trainer.py:198][0m Epoch[196] Batch[600] Speed: 417.719142 samples/sec loss: -31.79381 acc: 0.79187 ce: 0.58534 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:35:14 @trainer.py:173][0m Change temperature from 0.00081 to 0.00077
[33mIP:10.60.242.134 [0m[32m[0229 19:35:17 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:35:17 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997]
[33mIP:10.60.242.134 [0m[32m[0229 19:35:17 @trainer.py:234][0m acc 0.7997
[33mIP:10.60.242.134 [0m[32m[0229 19:35:17 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:35:17 @trainer.py:217][0m Start to train w for epoch 197
[33mIP:10.60.242.134 [0m[32m[0229 19:35:17 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:35:34 @trainer.py:198][0m Epoch[197] Batch[100] Speed: 276.073607 samples/sec loss: -31.79414 acc: 0.79199 ce: 0.58501 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:35:49 @trainer.py:198][0m Epoch[197] Batch[200] Speed: 421.689271 samples/sec loss: -31.79440 acc: 0.79207 ce: 0.58476 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:36:03 @trainer.py:198][0m Epoch[197] Batch[300] Speed: 462.802046 samples/sec loss: -31.79465 acc: 0.79216 ce: 0.58451 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:36:17 @trainer.py:198][0m Epoch[197] Batch[400] Speed: 435.208546 samples/sec loss: -31.79490 acc: 0.79225 ce: 0.58426 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:36:33 @trainer.py:198][0m Epoch[197] Batch[500] Speed: 418.062695 samples/sec loss: -31.79515 acc: 0.79234 ce: 0.58400 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:36:48 @trainer.py:198][0m Epoch[197] Batch[600] Speed: 418.036125 samples/sec loss: -31.79540 acc: 0.79243 ce: 0.58375 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:36:52 @trainer.py:173][0m Change temperature from 0.00077 to 0.00074
[33mIP:10.60.242.134 [0m[32m[0229 19:36:56 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:36:56 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097]
[33mIP:10.60.242.134 [0m[32m[0229 19:36:56 @trainer.py:234][0m acc 0.8097
[33mIP:10.60.242.134 [0m[32m[0229 19:36:56 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:36:56 @trainer.py:217][0m Start to train w for epoch 198
[33mIP:10.60.242.134 [0m[32m[0229 19:36:56 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:37:13 @trainer.py:198][0m Epoch[198] Batch[100] Speed: 261.525650 samples/sec loss: -31.79572 acc: 0.79254 ce: 0.58344 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:37:28 @trainer.py:198][0m Epoch[198] Batch[200] Speed: 402.764351 samples/sec loss: -31.79597 acc: 0.79263 ce: 0.58319 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:37:44 @trainer.py:198][0m Epoch[198] Batch[300] Speed: 403.637648 samples/sec loss: -31.79624 acc: 0.79272 ce: 0.58292 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:38:00 @trainer.py:198][0m Epoch[198] Batch[400] Speed: 408.859666 samples/sec loss: -31.79649 acc: 0.79281 ce: 0.58267 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:38:15 @trainer.py:198][0m Epoch[198] Batch[500] Speed: 419.699152 samples/sec loss: -31.79674 acc: 0.79290 ce: 0.58242 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:38:31 @trainer.py:198][0m Epoch[198] Batch[600] Speed: 416.319091 samples/sec loss: -31.79700 acc: 0.79299 ce: 0.58216 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:38:34 @trainer.py:173][0m Change temperature from 0.00074 to 0.00071
[33mIP:10.60.242.134 [0m[32m[0229 19:38:38 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:38:38 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071]
[33mIP:10.60.242.134 [0m[32m[0229 19:38:38 @trainer.py:234][0m acc 0.8071
[33mIP:10.60.242.134 [0m[32m[0229 19:38:38 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:38:38 @trainer.py:217][0m Start to train w for epoch 199
[33mIP:10.60.242.134 [0m[32m[0229 19:38:38 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:38:54 @trainer.py:198][0m Epoch[199] Batch[100] Speed: 270.296521 samples/sec loss: -31.79734 acc: 0.79311 ce: 0.58182 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:39:09 @trainer.py:198][0m Epoch[199] Batch[200] Speed: 431.130036 samples/sec loss: -31.79760 acc: 0.79321 ce: 0.58156 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:39:25 @trainer.py:198][0m Epoch[199] Batch[300] Speed: 413.357589 samples/sec loss: -31.79785 acc: 0.79329 ce: 0.58131 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:39:40 @trainer.py:198][0m Epoch[199] Batch[400] Speed: 409.901847 samples/sec loss: -31.79810 acc: 0.79338 ce: 0.58106 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:39:55 @trainer.py:198][0m Epoch[199] Batch[500] Speed: 422.765578 samples/sec loss: -31.79835 acc: 0.79347 ce: 0.58081 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:40:10 @trainer.py:198][0m Epoch[199] Batch[600] Speed: 440.877231 samples/sec loss: -31.79859 acc: 0.79356 ce: 0.58057 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:40:14 @trainer.py:173][0m Change temperature from 0.00071 to 0.00068
[33mIP:10.60.242.134 [0m[32m[0229 19:40:18 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:40:18 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065]
[33mIP:10.60.242.134 [0m[32m[0229 19:40:18 @trainer.py:234][0m acc 0.8065
[33mIP:10.60.242.134 [0m[32m[0229 19:40:18 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:40:18 @trainer.py:217][0m Start to train w for epoch 200
[33mIP:10.60.242.134 [0m[32m[0229 19:40:18 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:40:34 @trainer.py:198][0m Epoch[200] Batch[100] Speed: 263.262204 samples/sec loss: -31.79893 acc: 0.79367 ce: 0.58023 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:40:50 @trainer.py:198][0m Epoch[200] Batch[200] Speed: 403.829434 samples/sec loss: -31.79918 acc: 0.79376 ce: 0.57998 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:41:06 @trainer.py:198][0m Epoch[200] Batch[300] Speed: 403.711890 samples/sec loss: -31.79944 acc: 0.79385 ce: 0.57972 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:41:21 @trainer.py:198][0m Epoch[200] Batch[400] Speed: 412.238532 samples/sec loss: -31.79969 acc: 0.79394 ce: 0.57947 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:41:37 @trainer.py:198][0m Epoch[200] Batch[500] Speed: 416.421675 samples/sec loss: -31.79995 acc: 0.79403 ce: 0.57921 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:41:52 @trainer.py:198][0m Epoch[200] Batch[600] Speed: 419.824970 samples/sec loss: -31.80020 acc: 0.79412 ce: 0.57896 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:41:56 @trainer.py:173][0m Change temperature from 0.00068 to 0.00065
[33mIP:10.60.242.134 [0m[32m[0229 19:41:59 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:41:59 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131]
[33mIP:10.60.242.134 [0m[32m[0229 19:41:59 @trainer.py:234][0m acc 0.8131
[33mIP:10.60.242.134 [0m[32m[0229 19:41:59 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:41:59 @trainer.py:217][0m Start to train w for epoch 201
[33mIP:10.60.242.134 [0m[32m[0229 19:41:59 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:42:15 @trainer.py:198][0m Epoch[201] Batch[100] Speed: 279.968393 samples/sec loss: -31.80053 acc: 0.79423 ce: 0.57864 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:42:30 @trainer.py:198][0m Epoch[201] Batch[200] Speed: 431.676058 samples/sec loss: -31.80078 acc: 0.79433 ce: 0.57838 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:42:46 @trainer.py:198][0m Epoch[201] Batch[300] Speed: 403.075619 samples/sec loss: -31.80104 acc: 0.79442 ce: 0.57812 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:43:01 @trainer.py:198][0m Epoch[201] Batch[400] Speed: 403.187222 samples/sec loss: -31.80129 acc: 0.79451 ce: 0.57788 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:43:17 @trainer.py:198][0m Epoch[201] Batch[500] Speed: 406.281757 samples/sec loss: -31.80154 acc: 0.79460 ce: 0.57762 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:43:33 @trainer.py:198][0m Epoch[201] Batch[600] Speed: 408.010728 samples/sec loss: -31.80181 acc: 0.79469 ce: 0.57735 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:43:36 @trainer.py:173][0m Change temperature from 0.00065 to 0.00062
[33mIP:10.60.242.134 [0m[32m[0229 19:43:40 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:43:40 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103]
[33mIP:10.60.242.134 [0m[32m[0229 19:43:40 @trainer.py:234][0m acc 0.8103
[33mIP:10.60.242.134 [0m[32m[0229 19:43:40 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:43:40 @trainer.py:217][0m Start to train w for epoch 202
[33mIP:10.60.242.134 [0m[32m[0229 19:43:40 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:43:56 @trainer.py:198][0m Epoch[202] Batch[100] Speed: 281.289972 samples/sec loss: -31.80214 acc: 0.79481 ce: 0.57703 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:44:10 @trainer.py:198][0m Epoch[202] Batch[200] Speed: 430.930120 samples/sec loss: -31.80239 acc: 0.79490 ce: 0.57678 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:44:25 @trainer.py:198][0m Epoch[202] Batch[300] Speed: 427.414448 samples/sec loss: -31.80264 acc: 0.79499 ce: 0.57653 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:44:41 @trainer.py:198][0m Epoch[202] Batch[400] Speed: 417.530298 samples/sec loss: -31.80290 acc: 0.79508 ce: 0.57627 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:44:56 @trainer.py:198][0m Epoch[202] Batch[500] Speed: 427.374511 samples/sec loss: -31.80314 acc: 0.79517 ce: 0.57603 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:45:11 @trainer.py:198][0m Epoch[202] Batch[600] Speed: 412.192290 samples/sec loss: -31.80339 acc: 0.79525 ce: 0.57578 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:45:15 @trainer.py:173][0m Change temperature from 0.00062 to 0.00059
[33mIP:10.60.242.134 [0m[32m[0229 19:45:18 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:45:18 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095]
[33mIP:10.60.242.134 [0m[32m[0229 19:45:18 @trainer.py:234][0m acc 0.8095
[33mIP:10.60.242.134 [0m[32m[0229 19:45:18 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:45:18 @trainer.py:217][0m Start to train w for epoch 203
[33mIP:10.60.242.134 [0m[32m[0229 19:45:18 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:45:35 @trainer.py:198][0m Epoch[203] Batch[100] Speed: 274.945855 samples/sec loss: -31.80371 acc: 0.79537 ce: 0.57546 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:45:50 @trainer.py:198][0m Epoch[203] Batch[200] Speed: 423.737426 samples/sec loss: -31.80397 acc: 0.79546 ce: 0.57520 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:46:05 @trainer.py:198][0m Epoch[203] Batch[300] Speed: 423.513300 samples/sec loss: -31.80422 acc: 0.79555 ce: 0.57495 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:46:20 @trainer.py:198][0m Epoch[203] Batch[400] Speed: 407.728825 samples/sec loss: -31.80447 acc: 0.79564 ce: 0.57470 lat: -16.18958
[33mIP:10.60.242.134 [0m[32m[0229 19:46:36 @trainer.py:198][0m Epoch[203] Batch[500] Speed: 410.610091 samples/sec loss: -31.80473 acc: 0.79573 ce: 0.57444 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:46:52 @trainer.py:198][0m Epoch[203] Batch[600] Speed: 403.295590 samples/sec loss: -31.80498 acc: 0.79582 ce: 0.57419 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:46:56 @trainer.py:173][0m Change temperature from 0.00059 to 0.00056
[33mIP:10.60.242.134 [0m[32m[0229 19:46:59 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:46:59 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056]
[33mIP:10.60.242.134 [0m[32m[0229 19:46:59 @trainer.py:234][0m acc 0.8056
[33mIP:10.60.242.134 [0m[32m[0229 19:46:59 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:46:59 @trainer.py:217][0m Start to train w for epoch 204
[33mIP:10.60.242.134 [0m[32m[0229 19:46:59 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:47:15 @trainer.py:198][0m Epoch[204] Batch[100] Speed: 275.100063 samples/sec loss: -31.80530 acc: 0.79594 ce: 0.57387 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:47:30 @trainer.py:198][0m Epoch[204] Batch[200] Speed: 422.382211 samples/sec loss: -31.80555 acc: 0.79603 ce: 0.57362 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:47:46 @trainer.py:198][0m Epoch[204] Batch[300] Speed: 408.248692 samples/sec loss: -31.80581 acc: 0.79612 ce: 0.57336 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:48:01 @trainer.py:198][0m Epoch[204] Batch[400] Speed: 415.455137 samples/sec loss: -31.80605 acc: 0.79621 ce: 0.57312 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:48:17 @trainer.py:198][0m Epoch[204] Batch[500] Speed: 421.479217 samples/sec loss: -31.80631 acc: 0.79630 ce: 0.57286 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:48:32 @trainer.py:198][0m Epoch[204] Batch[600] Speed: 429.361738 samples/sec loss: -31.80656 acc: 0.79639 ce: 0.57261 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:48:35 @trainer.py:173][0m Change temperature from 0.00056 to 0.00054
[33mIP:10.60.242.134 [0m[32m[0229 19:48:39 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:48:39 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061]
[33mIP:10.60.242.134 [0m[32m[0229 19:48:39 @trainer.py:234][0m acc 0.8061
[33mIP:10.60.242.134 [0m[32m[0229 19:48:39 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:48:39 @trainer.py:217][0m Start to train w for epoch 205
[33mIP:10.60.242.134 [0m[32m[0229 19:48:39 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:48:55 @trainer.py:198][0m Epoch[205] Batch[100] Speed: 270.980839 samples/sec loss: -31.80689 acc: 0.79650 ce: 0.57228 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:49:11 @trainer.py:198][0m Epoch[205] Batch[200] Speed: 416.362033 samples/sec loss: -31.80714 acc: 0.79659 ce: 0.57203 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:49:27 @trainer.py:198][0m Epoch[205] Batch[300] Speed: 395.293518 samples/sec loss: -31.80739 acc: 0.79668 ce: 0.57178 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:49:42 @trainer.py:198][0m Epoch[205] Batch[400] Speed: 414.625781 samples/sec loss: -31.80764 acc: 0.79676 ce: 0.57154 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:49:58 @trainer.py:198][0m Epoch[205] Batch[500] Speed: 393.712289 samples/sec loss: -31.80790 acc: 0.79685 ce: 0.57128 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:50:14 @trainer.py:198][0m Epoch[205] Batch[600] Speed: 403.222972 samples/sec loss: -31.80815 acc: 0.79694 ce: 0.57103 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:50:18 @trainer.py:173][0m Change temperature from 0.00054 to 0.00052
[33mIP:10.60.242.134 [0m[32m[0229 19:50:22 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:50:22 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808]
[33mIP:10.60.242.134 [0m[32m[0229 19:50:22 @trainer.py:234][0m acc 0.808
[33mIP:10.60.242.134 [0m[32m[0229 19:50:22 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:50:22 @trainer.py:217][0m Start to train w for epoch 206
[33mIP:10.60.242.134 [0m[32m[0229 19:50:22 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:50:38 @trainer.py:198][0m Epoch[206] Batch[100] Speed: 267.980123 samples/sec loss: -31.80847 acc: 0.79706 ce: 0.57071 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:50:54 @trainer.py:198][0m Epoch[206] Batch[200] Speed: 392.963624 samples/sec loss: -31.80872 acc: 0.79715 ce: 0.57045 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:51:11 @trainer.py:198][0m Epoch[206] Batch[300] Speed: 390.598216 samples/sec loss: -31.80898 acc: 0.79724 ce: 0.57020 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:51:27 @trainer.py:198][0m Epoch[206] Batch[400] Speed: 400.572050 samples/sec loss: -31.80923 acc: 0.79733 ce: 0.56994 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:51:42 @trainer.py:198][0m Epoch[206] Batch[500] Speed: 415.826761 samples/sec loss: -31.80949 acc: 0.79742 ce: 0.56969 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:51:58 @trainer.py:198][0m Epoch[206] Batch[600] Speed: 401.179713 samples/sec loss: -31.80973 acc: 0.79751 ce: 0.56944 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:52:02 @trainer.py:173][0m Change temperature from 0.00052 to 0.00049
[33mIP:10.60.242.134 [0m[32m[0229 19:52:06 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:52:06 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079]
[33mIP:10.60.242.134 [0m[32m[0229 19:52:06 @trainer.py:234][0m acc 0.8079
[33mIP:10.60.242.134 [0m[32m[0229 19:52:06 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:52:06 @trainer.py:217][0m Start to train w for epoch 207
[33mIP:10.60.242.134 [0m[32m[0229 19:52:06 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:52:22 @trainer.py:198][0m Epoch[207] Batch[100] Speed: 264.526409 samples/sec loss: -31.81005 acc: 0.79762 ce: 0.56912 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:52:38 @trainer.py:198][0m Epoch[207] Batch[200] Speed: 408.411738 samples/sec loss: -31.81031 acc: 0.79771 ce: 0.56887 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:52:54 @trainer.py:198][0m Epoch[207] Batch[300] Speed: 394.409192 samples/sec loss: -31.81058 acc: 0.79780 ce: 0.56860 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:53:10 @trainer.py:198][0m Epoch[207] Batch[400] Speed: 409.994191 samples/sec loss: -31.81083 acc: 0.79789 ce: 0.56834 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:53:25 @trainer.py:198][0m Epoch[207] Batch[500] Speed: 416.642521 samples/sec loss: -31.81108 acc: 0.79798 ce: 0.56810 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:53:41 @trainer.py:198][0m Epoch[207] Batch[600] Speed: 419.261169 samples/sec loss: -31.81133 acc: 0.79807 ce: 0.56785 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:53:44 @trainer.py:173][0m Change temperature from 0.00049 to 0.00047
[33mIP:10.60.242.134 [0m[32m[0229 19:53:48 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:53:48 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065]
[33mIP:10.60.242.134 [0m[32m[0229 19:53:48 @trainer.py:234][0m acc 0.8065
[33mIP:10.60.242.134 [0m[32m[0229 19:53:48 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:53:48 @trainer.py:217][0m Start to train w for epoch 208
[33mIP:10.60.242.134 [0m[32m[0229 19:53:48 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:54:03 @trainer.py:198][0m Epoch[208] Batch[100] Speed: 280.627970 samples/sec loss: -31.81166 acc: 0.79818 ce: 0.56752 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:54:19 @trainer.py:198][0m Epoch[208] Batch[200] Speed: 415.679097 samples/sec loss: -31.81193 acc: 0.79828 ce: 0.56725 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:54:33 @trainer.py:198][0m Epoch[208] Batch[300] Speed: 438.784441 samples/sec loss: -31.81217 acc: 0.79836 ce: 0.56701 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:54:48 @trainer.py:198][0m Epoch[208] Batch[400] Speed: 428.464808 samples/sec loss: -31.81242 acc: 0.79845 ce: 0.56676 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:55:03 @trainer.py:198][0m Epoch[208] Batch[500] Speed: 422.357316 samples/sec loss: -31.81267 acc: 0.79853 ce: 0.56651 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:55:19 @trainer.py:198][0m Epoch[208] Batch[600] Speed: 418.308386 samples/sec loss: -31.81292 acc: 0.79862 ce: 0.56626 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:55:22 @trainer.py:173][0m Change temperature from 0.00047 to 0.00045
[33mIP:10.60.242.134 [0m[32m[0229 19:55:26 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:55:26 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089]
[33mIP:10.60.242.134 [0m[32m[0229 19:55:26 @trainer.py:234][0m acc 0.8089
[33mIP:10.60.242.134 [0m[32m[0229 19:55:26 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:55:26 @trainer.py:217][0m Start to train w for epoch 209
[33mIP:10.60.242.134 [0m[32m[0229 19:55:26 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:55:41 @trainer.py:198][0m Epoch[209] Batch[100] Speed: 289.213923 samples/sec loss: -31.81325 acc: 0.79874 ce: 0.56593 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:55:56 @trainer.py:198][0m Epoch[209] Batch[200] Speed: 418.230764 samples/sec loss: -31.81351 acc: 0.79883 ce: 0.56567 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:56:12 @trainer.py:198][0m Epoch[209] Batch[300] Speed: 407.716130 samples/sec loss: -31.81376 acc: 0.79891 ce: 0.56542 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:56:27 @trainer.py:198][0m Epoch[209] Batch[400] Speed: 416.333684 samples/sec loss: -31.81402 acc: 0.79900 ce: 0.56516 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:56:42 @trainer.py:198][0m Epoch[209] Batch[500] Speed: 420.489798 samples/sec loss: -31.81427 acc: 0.79909 ce: 0.56491 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:56:57 @trainer.py:198][0m Epoch[209] Batch[600] Speed: 442.745714 samples/sec loss: -31.81452 acc: 0.79918 ce: 0.56466 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:57:00 @trainer.py:173][0m Change temperature from 0.00045 to 0.00043
[33mIP:10.60.242.134 [0m[32m[0229 19:57:04 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:57:04 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805]
[33mIP:10.60.242.134 [0m[32m[0229 19:57:04 @trainer.py:234][0m acc 0.805
[33mIP:10.60.242.134 [0m[32m[0229 19:57:04 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:57:04 @trainer.py:217][0m Start to train w for epoch 210
[33mIP:10.60.242.134 [0m[32m[0229 19:57:04 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:57:21 @trainer.py:198][0m Epoch[210] Batch[100] Speed: 268.428042 samples/sec loss: -31.81484 acc: 0.79929 ce: 0.56434 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:57:36 @trainer.py:198][0m Epoch[210] Batch[200] Speed: 420.394509 samples/sec loss: -31.81510 acc: 0.79938 ce: 0.56409 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:57:52 @trainer.py:198][0m Epoch[210] Batch[300] Speed: 407.520746 samples/sec loss: -31.81536 acc: 0.79947 ce: 0.56382 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:58:06 @trainer.py:198][0m Epoch[210] Batch[400] Speed: 431.574460 samples/sec loss: -31.81561 acc: 0.79955 ce: 0.56357 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:58:22 @trainer.py:198][0m Epoch[210] Batch[500] Speed: 420.672013 samples/sec loss: -31.81586 acc: 0.79964 ce: 0.56333 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:58:38 @trainer.py:198][0m Epoch[210] Batch[600] Speed: 398.992371 samples/sec loss: -31.81611 acc: 0.79973 ce: 0.56307 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:58:42 @trainer.py:173][0m Change temperature from 0.00043 to 0.00041
[33mIP:10.60.242.134 [0m[32m[0229 19:58:45 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 19:58:45 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125]
[33mIP:10.60.242.134 [0m[32m[0229 19:58:45 @trainer.py:234][0m acc 0.8125
[33mIP:10.60.242.134 [0m[32m[0229 19:58:45 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 19:58:45 @trainer.py:217][0m Start to train w for epoch 211
[33mIP:10.60.242.134 [0m[32m[0229 19:58:45 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 19:59:01 @trainer.py:198][0m Epoch[211] Batch[100] Speed: 269.834394 samples/sec loss: -31.81643 acc: 0.79985 ce: 0.56275 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:59:17 @trainer.py:198][0m Epoch[211] Batch[200] Speed: 416.663067 samples/sec loss: -31.81669 acc: 0.79994 ce: 0.56249 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:59:32 @trainer.py:198][0m Epoch[211] Batch[300] Speed: 411.028106 samples/sec loss: -31.81695 acc: 0.80003 ce: 0.56224 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 19:59:48 @trainer.py:198][0m Epoch[211] Batch[400] Speed: 412.518669 samples/sec loss: -31.81720 acc: 0.80012 ce: 0.56198 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:00:03 @trainer.py:198][0m Epoch[211] Batch[500] Speed: 427.027717 samples/sec loss: -31.81745 acc: 0.80021 ce: 0.56173 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:00:18 @trainer.py:198][0m Epoch[211] Batch[600] Speed: 411.273056 samples/sec loss: -31.81770 acc: 0.80030 ce: 0.56149 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:00:22 @trainer.py:173][0m Change temperature from 0.00041 to 0.00039
[33mIP:10.60.242.134 [0m[32m[0229 20:00:26 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:00:26 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085]
[33mIP:10.60.242.134 [0m[32m[0229 20:00:26 @trainer.py:234][0m acc 0.8085
[33mIP:10.60.242.134 [0m[32m[0229 20:00:26 @trainer.py:235][0m max_acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 20:00:26 @trainer.py:217][0m Start to train w for epoch 212
[33mIP:10.60.242.134 [0m[32m[0229 20:00:26 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:00:43 @trainer.py:198][0m Epoch[212] Batch[100] Speed: 265.720910 samples/sec loss: -31.81803 acc: 0.80041 ce: 0.56116 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:00:58 @trainer.py:198][0m Epoch[212] Batch[200] Speed: 412.999336 samples/sec loss: -31.81827 acc: 0.80050 ce: 0.56091 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:01:13 @trainer.py:198][0m Epoch[212] Batch[300] Speed: 418.335133 samples/sec loss: -31.81853 acc: 0.80059 ce: 0.56065 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:01:27 @trainer.py:198][0m Epoch[212] Batch[400] Speed: 458.645163 samples/sec loss: -31.81879 acc: 0.80068 ce: 0.56040 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:01:42 @trainer.py:198][0m Epoch[212] Batch[500] Speed: 424.043041 samples/sec loss: -31.81905 acc: 0.80077 ce: 0.56013 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:01:58 @trainer.py:198][0m Epoch[212] Batch[600] Speed: 418.941116 samples/sec loss: -31.81931 acc: 0.80086 ce: 0.55988 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:02:01 @trainer.py:173][0m Change temperature from 0.00039 to 0.00038
[33mIP:10.60.242.134 [0m[32m[0229 20:02:05 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:02:05 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158]
[33mIP:10.60.242.134 [0m[32m[0229 20:02:05 @trainer.py:234][0m acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:02:05 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:02:05 @trainer.py:217][0m Start to train w for epoch 213
[33mIP:10.60.242.134 [0m[32m[0229 20:02:05 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:02:20 @trainer.py:198][0m Epoch[213] Batch[100] Speed: 283.503967 samples/sec loss: -31.81963 acc: 0.80098 ce: 0.55956 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:02:35 @trainer.py:198][0m Epoch[213] Batch[200] Speed: 437.744880 samples/sec loss: -31.81989 acc: 0.80107 ce: 0.55930 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:02:49 @trainer.py:198][0m Epoch[213] Batch[300] Speed: 461.958820 samples/sec loss: -31.82014 acc: 0.80116 ce: 0.55904 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:03:03 @trainer.py:198][0m Epoch[213] Batch[400] Speed: 443.748519 samples/sec loss: -31.82040 acc: 0.80125 ce: 0.55879 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:03:18 @trainer.py:198][0m Epoch[213] Batch[500] Speed: 434.004761 samples/sec loss: -31.82066 acc: 0.80134 ce: 0.55853 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:03:32 @trainer.py:198][0m Epoch[213] Batch[600] Speed: 443.965310 samples/sec loss: -31.82090 acc: 0.80142 ce: 0.55828 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:03:36 @trainer.py:173][0m Change temperature from 0.00038 to 0.00036
[33mIP:10.60.242.134 [0m[32m[0229 20:03:40 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:03:40 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062]
[33mIP:10.60.242.134 [0m[32m[0229 20:03:40 @trainer.py:234][0m acc 0.8062
[33mIP:10.60.242.134 [0m[32m[0229 20:03:40 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:03:40 @trainer.py:217][0m Start to train w for epoch 214
[33mIP:10.60.242.134 [0m[32m[0229 20:03:40 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:03:56 @trainer.py:198][0m Epoch[214] Batch[100] Speed: 270.640199 samples/sec loss: -31.82123 acc: 0.80154 ce: 0.55796 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:04:11 @trainer.py:198][0m Epoch[214] Batch[200] Speed: 425.521514 samples/sec loss: -31.82148 acc: 0.80163 ce: 0.55771 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:04:26 @trainer.py:198][0m Epoch[214] Batch[300] Speed: 417.468169 samples/sec loss: -31.82173 acc: 0.80171 ce: 0.55746 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:04:42 @trainer.py:198][0m Epoch[214] Batch[400] Speed: 416.327304 samples/sec loss: -31.82198 acc: 0.80180 ce: 0.55721 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:04:57 @trainer.py:198][0m Epoch[214] Batch[500] Speed: 417.327727 samples/sec loss: -31.82223 acc: 0.80189 ce: 0.55696 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:05:12 @trainer.py:198][0m Epoch[214] Batch[600] Speed: 424.430879 samples/sec loss: -31.82249 acc: 0.80198 ce: 0.55670 lat: -16.18959
[33mIP:10.60.242.134 [0m[32m[0229 20:05:16 @trainer.py:173][0m Change temperature from 0.00036 to 0.00034
[33mIP:10.60.242.134 [0m[32m[0229 20:05:20 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:05:20 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062]
[33mIP:10.60.242.134 [0m[32m[0229 20:05:20 @trainer.py:234][0m acc 0.8062
[33mIP:10.60.242.134 [0m[32m[0229 20:05:20 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:05:20 @trainer.py:217][0m Start to train w for epoch 215
[33mIP:10.60.242.134 [0m[32m[0229 20:05:20 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:05:36 @trainer.py:198][0m Epoch[215] Batch[100] Speed: 266.224398 samples/sec loss: -31.82281 acc: 0.80210 ce: 0.55638 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:05:52 @trainer.py:198][0m Epoch[215] Batch[200] Speed: 410.628382 samples/sec loss: -31.82306 acc: 0.80219 ce: 0.55613 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:06:06 @trainer.py:198][0m Epoch[215] Batch[300] Speed: 437.342664 samples/sec loss: -31.82333 acc: 0.80228 ce: 0.55586 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:06:22 @trainer.py:198][0m Epoch[215] Batch[400] Speed: 410.092510 samples/sec loss: -31.82358 acc: 0.80237 ce: 0.55561 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:06:37 @trainer.py:198][0m Epoch[215] Batch[500] Speed: 419.841425 samples/sec loss: -31.82383 acc: 0.80246 ce: 0.55536 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:06:52 @trainer.py:198][0m Epoch[215] Batch[600] Speed: 423.817193 samples/sec loss: -31.82409 acc: 0.80256 ce: 0.55510 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:06:56 @trainer.py:173][0m Change temperature from 0.00034 to 0.00033
[33mIP:10.60.242.134 [0m[32m[0229 20:06:59 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:06:59 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131]
[33mIP:10.60.242.134 [0m[32m[0229 20:06:59 @trainer.py:234][0m acc 0.8131
[33mIP:10.60.242.134 [0m[32m[0229 20:06:59 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:06:59 @trainer.py:217][0m Start to train w for epoch 216
[33mIP:10.60.242.134 [0m[32m[0229 20:06:59 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:07:15 @trainer.py:198][0m Epoch[216] Batch[100] Speed: 287.488433 samples/sec loss: -31.82441 acc: 0.80266 ce: 0.55478 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:07:30 @trainer.py:198][0m Epoch[216] Batch[200] Speed: 420.975393 samples/sec loss: -31.82466 acc: 0.80276 ce: 0.55453 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:07:45 @trainer.py:198][0m Epoch[216] Batch[300] Speed: 411.328993 samples/sec loss: -31.82491 acc: 0.80284 ce: 0.55428 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:08:01 @trainer.py:198][0m Epoch[216] Batch[400] Speed: 409.190647 samples/sec loss: -31.82516 acc: 0.80293 ce: 0.55404 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:08:17 @trainer.py:198][0m Epoch[216] Batch[500] Speed: 405.413574 samples/sec loss: -31.82542 acc: 0.80302 ce: 0.55378 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:08:32 @trainer.py:198][0m Epoch[216] Batch[600] Speed: 415.434369 samples/sec loss: -31.82566 acc: 0.80311 ce: 0.55353 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:08:36 @trainer.py:173][0m Change temperature from 0.00033 to 0.00031
[33mIP:10.60.242.134 [0m[32m[0229 20:08:39 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:08:39 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805]
[33mIP:10.60.242.134 [0m[32m[0229 20:08:39 @trainer.py:234][0m acc 0.805
[33mIP:10.60.242.134 [0m[32m[0229 20:08:39 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:08:39 @trainer.py:217][0m Start to train w for epoch 217
[33mIP:10.60.242.134 [0m[32m[0229 20:08:39 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:08:56 @trainer.py:198][0m Epoch[217] Batch[100] Speed: 271.817304 samples/sec loss: -31.82599 acc: 0.80322 ce: 0.55321 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:09:11 @trainer.py:198][0m Epoch[217] Batch[200] Speed: 408.730755 samples/sec loss: -31.82624 acc: 0.80331 ce: 0.55295 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:09:27 @trainer.py:198][0m Epoch[217] Batch[300] Speed: 418.426366 samples/sec loss: -31.82649 acc: 0.80340 ce: 0.55270 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:09:42 @trainer.py:198][0m Epoch[217] Batch[400] Speed: 411.338914 samples/sec loss: -31.82676 acc: 0.80349 ce: 0.55244 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:09:58 @trainer.py:198][0m Epoch[217] Batch[500] Speed: 416.800765 samples/sec loss: -31.82701 acc: 0.80358 ce: 0.55218 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:10:13 @trainer.py:198][0m Epoch[217] Batch[600] Speed: 420.057342 samples/sec loss: -31.82726 acc: 0.80367 ce: 0.55193 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:10:17 @trainer.py:173][0m Change temperature from 0.00031 to 0.00030
[33mIP:10.60.242.134 [0m[32m[0229 20:10:21 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:10:21 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981]
[33mIP:10.60.242.134 [0m[32m[0229 20:10:21 @trainer.py:234][0m acc 0.7981
[33mIP:10.60.242.134 [0m[32m[0229 20:10:21 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:10:21 @trainer.py:217][0m Start to train w for epoch 218
[33mIP:10.60.242.134 [0m[32m[0229 20:10:21 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:10:36 @trainer.py:198][0m Epoch[218] Batch[100] Speed: 273.964576 samples/sec loss: -31.82759 acc: 0.80379 ce: 0.55160 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:10:52 @trainer.py:198][0m Epoch[218] Batch[200] Speed: 407.742661 samples/sec loss: -31.82786 acc: 0.80388 ce: 0.55134 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:11:07 @trainer.py:198][0m Epoch[218] Batch[300] Speed: 421.254200 samples/sec loss: -31.82810 acc: 0.80396 ce: 0.55110 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:11:23 @trainer.py:198][0m Epoch[218] Batch[400] Speed: 407.917093 samples/sec loss: -31.82834 acc: 0.80405 ce: 0.55085 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:11:38 @trainer.py:198][0m Epoch[218] Batch[500] Speed: 413.646631 samples/sec loss: -31.82860 acc: 0.80414 ce: 0.55059 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:11:55 @trainer.py:198][0m Epoch[218] Batch[600] Speed: 389.297203 samples/sec loss: -31.82886 acc: 0.80423 ce: 0.55033 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:11:58 @trainer.py:173][0m Change temperature from 0.00030 to 0.00029
[33mIP:10.60.242.134 [0m[32m[0229 20:12:01 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:12:01 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086]
[33mIP:10.60.242.134 [0m[32m[0229 20:12:01 @trainer.py:234][0m acc 0.8086
[33mIP:10.60.242.134 [0m[32m[0229 20:12:01 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:12:01 @trainer.py:217][0m Start to train w for epoch 219
[33mIP:10.60.242.134 [0m[32m[0229 20:12:01 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:12:19 @trainer.py:198][0m Epoch[219] Batch[100] Speed: 265.018294 samples/sec loss: -31.82917 acc: 0.80435 ce: 0.55002 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:12:35 @trainer.py:198][0m Epoch[219] Batch[200] Speed: 389.448755 samples/sec loss: -31.82943 acc: 0.80444 ce: 0.54976 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:12:51 @trainer.py:198][0m Epoch[219] Batch[300] Speed: 413.913419 samples/sec loss: -31.82969 acc: 0.80453 ce: 0.54950 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:13:06 @trainer.py:198][0m Epoch[219] Batch[400] Speed: 408.523885 samples/sec loss: -31.82995 acc: 0.80462 ce: 0.54925 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:13:22 @trainer.py:198][0m Epoch[219] Batch[500] Speed: 409.973221 samples/sec loss: -31.83019 acc: 0.80470 ce: 0.54901 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:13:38 @trainer.py:198][0m Epoch[219] Batch[600] Speed: 405.606273 samples/sec loss: -31.83043 acc: 0.80479 ce: 0.54876 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:13:42 @trainer.py:173][0m Change temperature from 0.00029 to 0.00027
[33mIP:10.60.242.134 [0m[32m[0229 20:13:46 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:13:46 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089]
[33mIP:10.60.242.134 [0m[32m[0229 20:13:46 @trainer.py:234][0m acc 0.8089
[33mIP:10.60.242.134 [0m[32m[0229 20:13:46 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:13:46 @trainer.py:217][0m Start to train w for epoch 220
[33mIP:10.60.242.134 [0m[32m[0229 20:13:46 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:14:02 @trainer.py:198][0m Epoch[220] Batch[100] Speed: 259.901416 samples/sec loss: -31.83076 acc: 0.80490 ce: 0.54844 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:14:18 @trainer.py:198][0m Epoch[220] Batch[200] Speed: 400.344203 samples/sec loss: -31.83101 acc: 0.80499 ce: 0.54819 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:14:34 @trainer.py:198][0m Epoch[220] Batch[300] Speed: 410.278786 samples/sec loss: -31.83126 acc: 0.80508 ce: 0.54793 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:14:49 @trainer.py:198][0m Epoch[220] Batch[400] Speed: 417.392364 samples/sec loss: -31.83151 acc: 0.80517 ce: 0.54768 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:15:05 @trainer.py:198][0m Epoch[220] Batch[500] Speed: 414.877919 samples/sec loss: -31.83178 acc: 0.80526 ce: 0.54742 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:15:20 @trainer.py:198][0m Epoch[220] Batch[600] Speed: 422.216933 samples/sec loss: -31.83203 acc: 0.80535 ce: 0.54717 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:15:24 @trainer.py:173][0m Change temperature from 0.00027 to 0.00026
[33mIP:10.60.242.134 [0m[32m[0229 20:15:27 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:15:27 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099]
[33mIP:10.60.242.134 [0m[32m[0229 20:15:27 @trainer.py:234][0m acc 0.8099
[33mIP:10.60.242.134 [0m[32m[0229 20:15:27 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:15:27 @trainer.py:217][0m Start to train w for epoch 221
[33mIP:10.60.242.134 [0m[32m[0229 20:15:27 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:15:44 @trainer.py:198][0m Epoch[221] Batch[100] Speed: 271.172185 samples/sec loss: -31.83234 acc: 0.80546 ce: 0.54686 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:15:59 @trainer.py:198][0m Epoch[221] Batch[200] Speed: 416.919049 samples/sec loss: -31.83259 acc: 0.80555 ce: 0.54661 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:16:13 @trainer.py:198][0m Epoch[221] Batch[300] Speed: 441.235232 samples/sec loss: -31.83285 acc: 0.80563 ce: 0.54635 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:16:28 @trainer.py:198][0m Epoch[221] Batch[400] Speed: 425.433108 samples/sec loss: -31.83310 acc: 0.80572 ce: 0.54610 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:16:44 @trainer.py:198][0m Epoch[221] Batch[500] Speed: 416.291187 samples/sec loss: -31.83335 acc: 0.80581 ce: 0.54585 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:16:59 @trainer.py:198][0m Epoch[221] Batch[600] Speed: 431.730330 samples/sec loss: -31.83360 acc: 0.80590 ce: 0.54560 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:17:02 @trainer.py:173][0m Change temperature from 0.00026 to 0.00025
[33mIP:10.60.242.134 [0m[32m[0229 20:17:05 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:17:05 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096]
[33mIP:10.60.242.134 [0m[32m[0229 20:17:05 @trainer.py:234][0m acc 0.8096
[33mIP:10.60.242.134 [0m[32m[0229 20:17:05 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:17:05 @trainer.py:217][0m Start to train w for epoch 222
[33mIP:10.60.242.134 [0m[32m[0229 20:17:05 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:17:22 @trainer.py:198][0m Epoch[222] Batch[100] Speed: 273.056484 samples/sec loss: -31.83391 acc: 0.80601 ce: 0.54529 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:17:38 @trainer.py:198][0m Epoch[222] Batch[200] Speed: 399.190595 samples/sec loss: -31.83416 acc: 0.80610 ce: 0.54504 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:17:54 @trainer.py:198][0m Epoch[222] Batch[300] Speed: 413.267185 samples/sec loss: -31.83441 acc: 0.80619 ce: 0.54478 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:18:09 @trainer.py:198][0m Epoch[222] Batch[400] Speed: 415.815785 samples/sec loss: -31.83467 acc: 0.80628 ce: 0.54453 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:18:24 @trainer.py:198][0m Epoch[222] Batch[500] Speed: 413.705192 samples/sec loss: -31.83491 acc: 0.80636 ce: 0.54429 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:18:39 @trainer.py:198][0m Epoch[222] Batch[600] Speed: 427.147711 samples/sec loss: -31.83516 acc: 0.80645 ce: 0.54404 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:18:43 @trainer.py:173][0m Change temperature from 0.00025 to 0.00024
[33mIP:10.60.242.134 [0m[32m[0229 20:18:46 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:18:46 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101]
[33mIP:10.60.242.134 [0m[32m[0229 20:18:46 @trainer.py:234][0m acc 0.8101
[33mIP:10.60.242.134 [0m[32m[0229 20:18:46 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:18:46 @trainer.py:217][0m Start to train w for epoch 223
[33mIP:10.60.242.134 [0m[32m[0229 20:18:46 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:19:02 @trainer.py:198][0m Epoch[223] Batch[100] Speed: 282.088844 samples/sec loss: -31.83547 acc: 0.80656 ce: 0.54373 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:19:17 @trainer.py:198][0m Epoch[223] Batch[200] Speed: 426.271789 samples/sec loss: -31.83572 acc: 0.80665 ce: 0.54348 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:19:32 @trainer.py:198][0m Epoch[223] Batch[300] Speed: 435.752462 samples/sec loss: -31.83597 acc: 0.80674 ce: 0.54323 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:19:47 @trainer.py:198][0m Epoch[223] Batch[400] Speed: 422.721059 samples/sec loss: -31.83622 acc: 0.80682 ce: 0.54298 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:20:02 @trainer.py:198][0m Epoch[223] Batch[500] Speed: 415.198310 samples/sec loss: -31.83648 acc: 0.80691 ce: 0.54272 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:20:18 @trainer.py:198][0m Epoch[223] Batch[600] Speed: 417.666685 samples/sec loss: -31.83672 acc: 0.80700 ce: 0.54248 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:20:21 @trainer.py:173][0m Change temperature from 0.00024 to 0.00023
[33mIP:10.60.242.134 [0m[32m[0229 20:20:25 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:20:25 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109]
[33mIP:10.60.242.134 [0m[32m[0229 20:20:25 @trainer.py:234][0m acc 0.8109
[33mIP:10.60.242.134 [0m[32m[0229 20:20:25 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:20:25 @trainer.py:217][0m Start to train w for epoch 224
[33mIP:10.60.242.134 [0m[32m[0229 20:20:25 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:20:41 @trainer.py:198][0m Epoch[224] Batch[100] Speed: 272.157620 samples/sec loss: -31.83704 acc: 0.80711 ce: 0.54216 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:20:57 @trainer.py:198][0m Epoch[224] Batch[200] Speed: 405.037329 samples/sec loss: -31.83729 acc: 0.80720 ce: 0.54191 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:21:13 @trainer.py:198][0m Epoch[224] Batch[300] Speed: 409.253868 samples/sec loss: -31.83755 acc: 0.80729 ce: 0.54165 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:21:28 @trainer.py:198][0m Epoch[224] Batch[400] Speed: 411.949582 samples/sec loss: -31.83779 acc: 0.80738 ce: 0.54141 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:21:44 @trainer.py:198][0m Epoch[224] Batch[500] Speed: 416.141607 samples/sec loss: -31.83805 acc: 0.80747 ce: 0.54115 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:21:59 @trainer.py:198][0m Epoch[224] Batch[600] Speed: 415.067900 samples/sec loss: -31.83830 acc: 0.80756 ce: 0.54090 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:22:03 @trainer.py:173][0m Change temperature from 0.00023 to 0.00022
[33mIP:10.60.242.134 [0m[32m[0229 20:22:06 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:22:06 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029]
[33mIP:10.60.242.134 [0m[32m[0229 20:22:06 @trainer.py:234][0m acc 0.8029
[33mIP:10.60.242.134 [0m[32m[0229 20:22:06 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:22:06 @trainer.py:217][0m Start to train w for epoch 225
[33mIP:10.60.242.134 [0m[32m[0229 20:22:06 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:22:21 @trainer.py:198][0m Epoch[225] Batch[100] Speed: 286.533741 samples/sec loss: -31.83861 acc: 0.80767 ce: 0.54059 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:22:36 @trainer.py:198][0m Epoch[225] Batch[200] Speed: 428.292713 samples/sec loss: -31.83886 acc: 0.80776 ce: 0.54034 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:22:51 @trainer.py:198][0m Epoch[225] Batch[300] Speed: 423.757607 samples/sec loss: -31.83911 acc: 0.80785 ce: 0.54009 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:23:07 @trainer.py:198][0m Epoch[225] Batch[400] Speed: 420.725551 samples/sec loss: -31.83936 acc: 0.80793 ce: 0.53984 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:23:22 @trainer.py:198][0m Epoch[225] Batch[500] Speed: 413.464304 samples/sec loss: -31.83961 acc: 0.80802 ce: 0.53959 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:23:38 @trainer.py:198][0m Epoch[225] Batch[600] Speed: 414.677035 samples/sec loss: -31.83986 acc: 0.80811 ce: 0.53934 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:23:41 @trainer.py:173][0m Change temperature from 0.00022 to 0.00021
[33mIP:10.60.242.134 [0m[32m[0229 20:23:45 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:23:45 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106]
[33mIP:10.60.242.134 [0m[32m[0229 20:23:45 @trainer.py:234][0m acc 0.8106
[33mIP:10.60.242.134 [0m[32m[0229 20:23:45 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:23:45 @trainer.py:217][0m Start to train w for epoch 226
[33mIP:10.60.242.134 [0m[32m[0229 20:23:45 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:24:00 @trainer.py:198][0m Epoch[226] Batch[100] Speed: 278.724947 samples/sec loss: -31.84017 acc: 0.80822 ce: 0.53903 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:24:15 @trainer.py:198][0m Epoch[226] Batch[200] Speed: 426.499726 samples/sec loss: -31.84041 acc: 0.80830 ce: 0.53879 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:24:31 @trainer.py:198][0m Epoch[226] Batch[300] Speed: 411.813845 samples/sec loss: -31.84066 acc: 0.80839 ce: 0.53855 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:24:47 @trainer.py:198][0m Epoch[226] Batch[400] Speed: 408.409415 samples/sec loss: -31.84090 acc: 0.80848 ce: 0.53830 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:25:02 @trainer.py:198][0m Epoch[226] Batch[500] Speed: 416.556777 samples/sec loss: -31.84115 acc: 0.80857 ce: 0.53805 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:25:17 @trainer.py:198][0m Epoch[226] Batch[600] Speed: 425.332426 samples/sec loss: -31.84140 acc: 0.80865 ce: 0.53780 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:25:21 @trainer.py:173][0m Change temperature from 0.00021 to 0.00020
[33mIP:10.60.242.134 [0m[32m[0229 20:25:25 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:25:25 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099]
[33mIP:10.60.242.134 [0m[32m[0229 20:25:25 @trainer.py:234][0m acc 0.8099
[33mIP:10.60.242.134 [0m[32m[0229 20:25:25 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:25:25 @trainer.py:217][0m Start to train w for epoch 227
[33mIP:10.60.242.134 [0m[32m[0229 20:25:25 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:25:40 @trainer.py:198][0m Epoch[227] Batch[100] Speed: 273.772668 samples/sec loss: -31.84171 acc: 0.80876 ce: 0.53749 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:25:56 @trainer.py:198][0m Epoch[227] Batch[200] Speed: 406.091187 samples/sec loss: -31.84196 acc: 0.80885 ce: 0.53724 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:26:12 @trainer.py:198][0m Epoch[227] Batch[300] Speed: 417.590457 samples/sec loss: -31.84222 acc: 0.80894 ce: 0.53699 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:26:27 @trainer.py:198][0m Epoch[227] Batch[400] Speed: 417.566501 samples/sec loss: -31.84247 acc: 0.80903 ce: 0.53674 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:26:42 @trainer.py:198][0m Epoch[227] Batch[500] Speed: 427.021338 samples/sec loss: -31.84271 acc: 0.80912 ce: 0.53649 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:26:57 @trainer.py:198][0m Epoch[227] Batch[600] Speed: 429.911109 samples/sec loss: -31.84296 acc: 0.80920 ce: 0.53624 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:27:00 @trainer.py:173][0m Change temperature from 0.00020 to 0.00019
[33mIP:10.60.242.134 [0m[32m[0229 20:27:03 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:27:03 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089]
[33mIP:10.60.242.134 [0m[32m[0229 20:27:03 @trainer.py:234][0m acc 0.8089
[33mIP:10.60.242.134 [0m[32m[0229 20:27:03 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:27:03 @trainer.py:217][0m Start to train w for epoch 228
[33mIP:10.60.242.134 [0m[32m[0229 20:27:03 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:27:19 @trainer.py:198][0m Epoch[228] Batch[100] Speed: 294.414704 samples/sec loss: -31.84327 acc: 0.80931 ce: 0.53593 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:27:34 @trainer.py:198][0m Epoch[228] Batch[200] Speed: 425.090668 samples/sec loss: -31.84353 acc: 0.80941 ce: 0.53568 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:27:49 @trainer.py:198][0m Epoch[228] Batch[300] Speed: 412.235942 samples/sec loss: -31.84377 acc: 0.80949 ce: 0.53543 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:28:05 @trainer.py:198][0m Epoch[228] Batch[400] Speed: 415.624945 samples/sec loss: -31.84401 acc: 0.80958 ce: 0.53519 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:28:19 @trainer.py:198][0m Epoch[228] Batch[500] Speed: 441.083535 samples/sec loss: -31.84426 acc: 0.80967 ce: 0.53494 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:28:34 @trainer.py:198][0m Epoch[228] Batch[600] Speed: 417.052186 samples/sec loss: -31.84451 acc: 0.80975 ce: 0.53469 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:28:38 @trainer.py:173][0m Change temperature from 0.00019 to 0.00018
[33mIP:10.60.242.134 [0m[32m[0229 20:28:41 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:28:41 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085]
[33mIP:10.60.242.134 [0m[32m[0229 20:28:41 @trainer.py:234][0m acc 0.8085
[33mIP:10.60.242.134 [0m[32m[0229 20:28:41 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:28:41 @trainer.py:217][0m Start to train w for epoch 229
[33mIP:10.60.242.134 [0m[32m[0229 20:28:41 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:28:56 @trainer.py:198][0m Epoch[229] Batch[100] Speed: 295.736895 samples/sec loss: -31.84481 acc: 0.80986 ce: 0.53439 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:29:11 @trainer.py:198][0m Epoch[229] Batch[200] Speed: 435.488374 samples/sec loss: -31.84506 acc: 0.80995 ce: 0.53415 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:29:26 @trainer.py:198][0m Epoch[229] Batch[300] Speed: 416.397084 samples/sec loss: -31.84530 acc: 0.81003 ce: 0.53391 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:29:41 @trainer.py:198][0m Epoch[229] Batch[400] Speed: 418.813318 samples/sec loss: -31.84555 acc: 0.81012 ce: 0.53365 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:29:56 @trainer.py:198][0m Epoch[229] Batch[500] Speed: 427.366870 samples/sec loss: -31.84580 acc: 0.81021 ce: 0.53340 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:30:11 @trainer.py:198][0m Epoch[229] Batch[600] Speed: 435.274550 samples/sec loss: -31.84605 acc: 0.81030 ce: 0.53316 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:30:15 @trainer.py:173][0m Change temperature from 0.00018 to 0.00018
[33mIP:10.60.242.134 [0m[32m[0229 20:30:18 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:30:18 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034]
[33mIP:10.60.242.134 [0m[32m[0229 20:30:18 @trainer.py:234][0m acc 0.8034
[33mIP:10.60.242.134 [0m[32m[0229 20:30:18 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:30:18 @trainer.py:217][0m Start to train w for epoch 230
[33mIP:10.60.242.134 [0m[32m[0229 20:30:18 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:30:34 @trainer.py:198][0m Epoch[230] Batch[100] Speed: 274.781952 samples/sec loss: -31.84635 acc: 0.81041 ce: 0.53285 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:30:50 @trainer.py:198][0m Epoch[230] Batch[200] Speed: 414.998553 samples/sec loss: -31.84660 acc: 0.81049 ce: 0.53261 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:31:06 @trainer.py:198][0m Epoch[230] Batch[300] Speed: 402.860750 samples/sec loss: -31.84684 acc: 0.81058 ce: 0.53237 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:31:21 @trainer.py:198][0m Epoch[230] Batch[400] Speed: 416.958915 samples/sec loss: -31.84709 acc: 0.81067 ce: 0.53212 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:31:36 @trainer.py:198][0m Epoch[230] Batch[500] Speed: 414.268006 samples/sec loss: -31.84733 acc: 0.81075 ce: 0.53187 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:31:51 @trainer.py:198][0m Epoch[230] Batch[600] Speed: 453.632719 samples/sec loss: -31.84757 acc: 0.81084 ce: 0.53163 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:31:54 @trainer.py:173][0m Change temperature from 0.00018 to 0.00017
[33mIP:10.60.242.134 [0m[32m[0229 20:31:57 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:31:57 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802]
[33mIP:10.60.242.134 [0m[32m[0229 20:31:57 @trainer.py:234][0m acc 0.802
[33mIP:10.60.242.134 [0m[32m[0229 20:31:57 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:31:57 @trainer.py:217][0m Start to train w for epoch 231
[33mIP:10.60.242.134 [0m[32m[0229 20:31:57 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:32:13 @trainer.py:198][0m Epoch[231] Batch[100] Speed: 285.376137 samples/sec loss: -31.84788 acc: 0.81094 ce: 0.53132 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:32:28 @trainer.py:198][0m Epoch[231] Batch[200] Speed: 418.428825 samples/sec loss: -31.84812 acc: 0.81103 ce: 0.53108 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:32:43 @trainer.py:198][0m Epoch[231] Batch[300] Speed: 430.036594 samples/sec loss: -31.84836 acc: 0.81112 ce: 0.53084 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:32:59 @trainer.py:198][0m Epoch[231] Batch[400] Speed: 415.015831 samples/sec loss: -31.84861 acc: 0.81121 ce: 0.53060 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:33:14 @trainer.py:198][0m Epoch[231] Batch[500] Speed: 410.982035 samples/sec loss: -31.84885 acc: 0.81129 ce: 0.53035 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:33:30 @trainer.py:198][0m Epoch[231] Batch[600] Speed: 416.138517 samples/sec loss: -31.84909 acc: 0.81138 ce: 0.53011 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:33:33 @trainer.py:173][0m Change temperature from 0.00017 to 0.00016
[33mIP:10.60.242.134 [0m[32m[0229 20:33:37 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:33:37 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109]
[33mIP:10.60.242.134 [0m[32m[0229 20:33:37 @trainer.py:234][0m acc 0.8109
[33mIP:10.60.242.134 [0m[32m[0229 20:33:37 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:33:37 @trainer.py:217][0m Start to train w for epoch 232
[33mIP:10.60.242.134 [0m[32m[0229 20:33:37 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:33:54 @trainer.py:198][0m Epoch[232] Batch[100] Speed: 265.443953 samples/sec loss: -31.84941 acc: 0.81149 ce: 0.52979 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:34:09 @trainer.py:198][0m Epoch[232] Batch[200] Speed: 406.869012 samples/sec loss: -31.84966 acc: 0.81158 ce: 0.52955 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:34:25 @trainer.py:198][0m Epoch[232] Batch[300] Speed: 408.727705 samples/sec loss: -31.84990 acc: 0.81167 ce: 0.52930 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:34:41 @trainer.py:198][0m Epoch[232] Batch[400] Speed: 410.455665 samples/sec loss: -31.85015 acc: 0.81176 ce: 0.52906 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:34:56 @trainer.py:198][0m Epoch[232] Batch[500] Speed: 416.950159 samples/sec loss: -31.85039 acc: 0.81184 ce: 0.52881 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:35:11 @trainer.py:198][0m Epoch[232] Batch[600] Speed: 425.726064 samples/sec loss: -31.85063 acc: 0.81193 ce: 0.52857 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:35:15 @trainer.py:173][0m Change temperature from 0.00016 to 0.00015
[33mIP:10.60.242.134 [0m[32m[0229 20:35:18 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:35:18 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807]
[33mIP:10.60.242.134 [0m[32m[0229 20:35:18 @trainer.py:234][0m acc 0.807
[33mIP:10.60.242.134 [0m[32m[0229 20:35:18 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:35:18 @trainer.py:217][0m Start to train w for epoch 233
[33mIP:10.60.242.134 [0m[32m[0229 20:35:18 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:35:34 @trainer.py:198][0m Epoch[233] Batch[100] Speed: 282.155350 samples/sec loss: -31.85094 acc: 0.81204 ce: 0.52827 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:35:49 @trainer.py:198][0m Epoch[233] Batch[200] Speed: 428.485688 samples/sec loss: -31.85118 acc: 0.81212 ce: 0.52802 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:36:04 @trainer.py:198][0m Epoch[233] Batch[300] Speed: 418.630619 samples/sec loss: -31.85143 acc: 0.81221 ce: 0.52778 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:36:20 @trainer.py:198][0m Epoch[233] Batch[400] Speed: 405.267669 samples/sec loss: -31.85166 acc: 0.81230 ce: 0.52754 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:36:35 @trainer.py:198][0m Epoch[233] Batch[500] Speed: 410.960114 samples/sec loss: -31.85191 acc: 0.81238 ce: 0.52730 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:36:50 @trainer.py:198][0m Epoch[233] Batch[600] Speed: 423.605108 samples/sec loss: -31.85214 acc: 0.81246 ce: 0.52707 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:36:54 @trainer.py:173][0m Change temperature from 0.00015 to 0.00015
[33mIP:10.60.242.134 [0m[32m[0229 20:36:58 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:36:58 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144]
[33mIP:10.60.242.134 [0m[32m[0229 20:36:58 @trainer.py:234][0m acc 0.8144
[33mIP:10.60.242.134 [0m[32m[0229 20:36:58 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:36:58 @trainer.py:217][0m Start to train w for epoch 234
[33mIP:10.60.242.134 [0m[32m[0229 20:36:58 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:37:14 @trainer.py:198][0m Epoch[234] Batch[100] Speed: 267.977485 samples/sec loss: -31.85243 acc: 0.81257 ce: 0.52677 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:37:30 @trainer.py:198][0m Epoch[234] Batch[200] Speed: 406.649089 samples/sec loss: -31.85268 acc: 0.81265 ce: 0.52653 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:37:45 @trainer.py:198][0m Epoch[234] Batch[300] Speed: 415.155177 samples/sec loss: -31.85292 acc: 0.81274 ce: 0.52628 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:38:01 @trainer.py:198][0m Epoch[234] Batch[400] Speed: 409.123667 samples/sec loss: -31.85317 acc: 0.81283 ce: 0.52604 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:38:17 @trainer.py:198][0m Epoch[234] Batch[500] Speed: 410.446163 samples/sec loss: -31.85340 acc: 0.81290 ce: 0.52581 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:38:32 @trainer.py:198][0m Epoch[234] Batch[600] Speed: 407.956595 samples/sec loss: -31.85364 acc: 0.81299 ce: 0.52557 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:38:36 @trainer.py:173][0m Change temperature from 0.00015 to 0.00014
[33mIP:10.60.242.134 [0m[32m[0229 20:38:40 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:38:40 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092]
[33mIP:10.60.242.134 [0m[32m[0229 20:38:40 @trainer.py:234][0m acc 0.8092
[33mIP:10.60.242.134 [0m[32m[0229 20:38:40 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:38:40 @trainer.py:217][0m Start to train w for epoch 235
[33mIP:10.60.242.134 [0m[32m[0229 20:38:40 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:38:56 @trainer.py:198][0m Epoch[235] Batch[100] Speed: 273.048107 samples/sec loss: -31.85393 acc: 0.81309 ce: 0.52527 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:39:11 @trainer.py:198][0m Epoch[235] Batch[200] Speed: 417.317515 samples/sec loss: -31.85418 acc: 0.81318 ce: 0.52502 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:39:27 @trainer.py:198][0m Epoch[235] Batch[300] Speed: 412.503195 samples/sec loss: -31.85442 acc: 0.81327 ce: 0.52478 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:39:42 @trainer.py:198][0m Epoch[235] Batch[400] Speed: 415.699021 samples/sec loss: -31.85466 acc: 0.81335 ce: 0.52455 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:39:58 @trainer.py:198][0m Epoch[235] Batch[500] Speed: 400.606579 samples/sec loss: -31.85490 acc: 0.81344 ce: 0.52430 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:40:13 @trainer.py:198][0m Epoch[235] Batch[600] Speed: 420.628930 samples/sec loss: -31.85513 acc: 0.81352 ce: 0.52408 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:40:17 @trainer.py:173][0m Change temperature from 0.00014 to 0.00013
[33mIP:10.60.242.134 [0m[32m[0229 20:40:20 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:40:20 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089]
[33mIP:10.60.242.134 [0m[32m[0229 20:40:20 @trainer.py:234][0m acc 0.8089
[33mIP:10.60.242.134 [0m[32m[0229 20:40:20 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:40:20 @trainer.py:217][0m Start to train w for epoch 236
[33mIP:10.60.242.134 [0m[32m[0229 20:40:20 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:40:37 @trainer.py:198][0m Epoch[236] Batch[100] Speed: 274.099906 samples/sec loss: -31.85542 acc: 0.81362 ce: 0.52379 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:40:52 @trainer.py:198][0m Epoch[236] Batch[200] Speed: 416.476702 samples/sec loss: -31.85566 acc: 0.81371 ce: 0.52354 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:41:07 @trainer.py:198][0m Epoch[236] Batch[300] Speed: 424.851472 samples/sec loss: -31.85591 acc: 0.81379 ce: 0.52330 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:41:21 @trainer.py:198][0m Epoch[236] Batch[400] Speed: 442.474193 samples/sec loss: -31.85615 acc: 0.81388 ce: 0.52306 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:41:36 @trainer.py:198][0m Epoch[236] Batch[500] Speed: 432.474953 samples/sec loss: -31.85639 acc: 0.81396 ce: 0.52281 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:41:51 @trainer.py:198][0m Epoch[236] Batch[600] Speed: 436.651229 samples/sec loss: -31.85663 acc: 0.81405 ce: 0.52258 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:41:54 @trainer.py:173][0m Change temperature from 0.00013 to 0.00013
[33mIP:10.60.242.134 [0m[32m[0229 20:41:58 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:41:58 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112]
[33mIP:10.60.242.134 [0m[32m[0229 20:41:58 @trainer.py:234][0m acc 0.8112
[33mIP:10.60.242.134 [0m[32m[0229 20:41:58 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:41:58 @trainer.py:217][0m Start to train w for epoch 237
[33mIP:10.60.242.134 [0m[32m[0229 20:41:58 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:42:14 @trainer.py:198][0m Epoch[237] Batch[100] Speed: 278.703448 samples/sec loss: -31.85693 acc: 0.81415 ce: 0.52228 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:42:30 @trainer.py:198][0m Epoch[237] Batch[200] Speed: 404.992591 samples/sec loss: -31.85718 acc: 0.81424 ce: 0.52203 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:42:45 @trainer.py:198][0m Epoch[237] Batch[300] Speed: 421.488740 samples/sec loss: -31.85741 acc: 0.81432 ce: 0.52180 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:43:00 @trainer.py:198][0m Epoch[237] Batch[400] Speed: 411.524027 samples/sec loss: -31.85765 acc: 0.81441 ce: 0.52156 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:43:15 @trainer.py:198][0m Epoch[237] Batch[500] Speed: 427.115258 samples/sec loss: -31.85789 acc: 0.81449 ce: 0.52132 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:43:31 @trainer.py:198][0m Epoch[237] Batch[600] Speed: 424.300951 samples/sec loss: -31.85812 acc: 0.81457 ce: 0.52109 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:43:34 @trainer.py:173][0m Change temperature from 0.00013 to 0.00012
[33mIP:10.60.242.134 [0m[32m[0229 20:43:38 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:43:38 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071]
[33mIP:10.60.242.134 [0m[32m[0229 20:43:38 @trainer.py:234][0m acc 0.8071
[33mIP:10.60.242.134 [0m[32m[0229 20:43:38 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:43:38 @trainer.py:217][0m Start to train w for epoch 238
[33mIP:10.60.242.134 [0m[32m[0229 20:43:38 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:43:55 @trainer.py:198][0m Epoch[238] Batch[100] Speed: 259.083788 samples/sec loss: -31.85841 acc: 0.81468 ce: 0.52079 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:44:12 @trainer.py:198][0m Epoch[238] Batch[200] Speed: 387.715368 samples/sec loss: -31.85865 acc: 0.81476 ce: 0.52056 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:44:28 @trainer.py:198][0m Epoch[238] Batch[300] Speed: 386.631357 samples/sec loss: -31.85889 acc: 0.81485 ce: 0.52032 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:44:44 @trainer.py:198][0m Epoch[238] Batch[400] Speed: 404.650411 samples/sec loss: -31.85913 acc: 0.81493 ce: 0.52008 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:45:00 @trainer.py:198][0m Epoch[238] Batch[500] Speed: 412.836250 samples/sec loss: -31.85936 acc: 0.81501 ce: 0.51984 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:45:16 @trainer.py:198][0m Epoch[238] Batch[600] Speed: 399.651361 samples/sec loss: -31.85960 acc: 0.81509 ce: 0.51961 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:45:19 @trainer.py:173][0m Change temperature from 0.00012 to 0.00012
[33mIP:10.60.242.134 [0m[32m[0229 20:45:23 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:45:23 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102]
[33mIP:10.60.242.134 [0m[32m[0229 20:45:23 @trainer.py:234][0m acc 0.8102
[33mIP:10.60.242.134 [0m[32m[0229 20:45:23 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:45:23 @trainer.py:217][0m Start to train w for epoch 239
[33mIP:10.60.242.134 [0m[32m[0229 20:45:23 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:45:40 @trainer.py:198][0m Epoch[239] Batch[100] Speed: 264.928999 samples/sec loss: -31.85989 acc: 0.81520 ce: 0.51931 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:45:55 @trainer.py:198][0m Epoch[239] Batch[200] Speed: 427.016502 samples/sec loss: -31.86013 acc: 0.81528 ce: 0.51908 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:46:10 @trainer.py:198][0m Epoch[239] Batch[300] Speed: 418.852031 samples/sec loss: -31.86036 acc: 0.81536 ce: 0.51884 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:46:25 @trainer.py:198][0m Epoch[239] Batch[400] Speed: 418.072116 samples/sec loss: -31.86061 acc: 0.81545 ce: 0.51860 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:46:40 @trainer.py:198][0m Epoch[239] Batch[500] Speed: 423.838379 samples/sec loss: -31.86084 acc: 0.81553 ce: 0.51837 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:46:55 @trainer.py:198][0m Epoch[239] Batch[600] Speed: 427.893901 samples/sec loss: -31.86108 acc: 0.81562 ce: 0.51813 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:46:59 @trainer.py:173][0m Change temperature from 0.00012 to 0.00011
[33mIP:10.60.242.134 [0m[32m[0229 20:47:03 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:47:03 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127]
[33mIP:10.60.242.134 [0m[32m[0229 20:47:03 @trainer.py:234][0m acc 0.8127
[33mIP:10.60.242.134 [0m[32m[0229 20:47:03 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:47:03 @trainer.py:217][0m Start to train w for epoch 240
[33mIP:10.60.242.134 [0m[32m[0229 20:47:03 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:47:20 @trainer.py:198][0m Epoch[240] Batch[100] Speed: 261.320702 samples/sec loss: -31.86138 acc: 0.81572 ce: 0.51783 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:47:36 @trainer.py:198][0m Epoch[240] Batch[200] Speed: 398.525804 samples/sec loss: -31.86161 acc: 0.81581 ce: 0.51760 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:47:52 @trainer.py:198][0m Epoch[240] Batch[300] Speed: 408.431928 samples/sec loss: -31.86184 acc: 0.81589 ce: 0.51737 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:48:07 @trainer.py:198][0m Epoch[240] Batch[400] Speed: 410.773012 samples/sec loss: -31.86207 acc: 0.81597 ce: 0.51714 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:48:23 @trainer.py:198][0m Epoch[240] Batch[500] Speed: 405.274400 samples/sec loss: -31.86231 acc: 0.81605 ce: 0.51690 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:48:39 @trainer.py:198][0m Epoch[240] Batch[600] Speed: 410.237823 samples/sec loss: -31.86254 acc: 0.81613 ce: 0.51667 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:48:42 @trainer.py:173][0m Change temperature from 0.00011 to 0.00011
[33mIP:10.60.242.134 [0m[32m[0229 20:48:45 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:48:45 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086]
[33mIP:10.60.242.134 [0m[32m[0229 20:48:45 @trainer.py:234][0m acc 0.8086
[33mIP:10.60.242.134 [0m[32m[0229 20:48:45 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:48:45 @trainer.py:217][0m Start to train w for epoch 241
[33mIP:10.60.242.134 [0m[32m[0229 20:48:45 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:49:00 @trainer.py:198][0m Epoch[241] Batch[100] Speed: 300.723174 samples/sec loss: -31.86283 acc: 0.81624 ce: 0.51638 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:49:14 @trainer.py:198][0m Epoch[241] Batch[200] Speed: 438.628390 samples/sec loss: -31.86307 acc: 0.81632 ce: 0.51614 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:49:29 @trainer.py:198][0m Epoch[241] Batch[300] Speed: 432.985798 samples/sec loss: -31.86330 acc: 0.81640 ce: 0.51591 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:49:44 @trainer.py:198][0m Epoch[241] Batch[400] Speed: 420.985362 samples/sec loss: -31.86354 acc: 0.81649 ce: 0.51567 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:50:00 @trainer.py:198][0m Epoch[241] Batch[500] Speed: 402.995543 samples/sec loss: -31.86377 acc: 0.81657 ce: 0.51544 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:50:16 @trainer.py:198][0m Epoch[241] Batch[600] Speed: 422.151675 samples/sec loss: -31.86400 acc: 0.81665 ce: 0.51521 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:50:19 @trainer.py:173][0m Change temperature from 0.00011 to 0.00010
[33mIP:10.60.242.134 [0m[32m[0229 20:50:23 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:50:23 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087]
[33mIP:10.60.242.134 [0m[32m[0229 20:50:23 @trainer.py:234][0m acc 0.8087
[33mIP:10.60.242.134 [0m[32m[0229 20:50:23 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:50:23 @trainer.py:217][0m Start to train w for epoch 242
[33mIP:10.60.242.134 [0m[32m[0229 20:50:23 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:50:39 @trainer.py:198][0m Epoch[242] Batch[100] Speed: 274.991985 samples/sec loss: -31.86430 acc: 0.81675 ce: 0.51491 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:50:54 @trainer.py:198][0m Epoch[242] Batch[200] Speed: 414.092055 samples/sec loss: -31.86453 acc: 0.81683 ce: 0.51468 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:51:10 @trainer.py:198][0m Epoch[242] Batch[300] Speed: 404.892067 samples/sec loss: -31.86476 acc: 0.81692 ce: 0.51445 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:51:25 @trainer.py:198][0m Epoch[242] Batch[400] Speed: 418.413296 samples/sec loss: -31.86499 acc: 0.81700 ce: 0.51422 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:51:41 @trainer.py:198][0m Epoch[242] Batch[500] Speed: 413.253156 samples/sec loss: -31.86523 acc: 0.81708 ce: 0.51398 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:51:57 @trainer.py:198][0m Epoch[242] Batch[600] Speed: 401.529428 samples/sec loss: -31.86546 acc: 0.81716 ce: 0.51375 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:52:00 @trainer.py:173][0m Change temperature from 0.00010 to 0.00010
[33mIP:10.60.242.134 [0m[32m[0229 20:52:04 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:52:04 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087, 0.8141]
[33mIP:10.60.242.134 [0m[32m[0229 20:52:04 @trainer.py:234][0m acc 0.8141
[33mIP:10.60.242.134 [0m[32m[0229 20:52:04 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:52:04 @trainer.py:217][0m Start to train w for epoch 243
[33mIP:10.60.242.134 [0m[32m[0229 20:52:04 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:52:20 @trainer.py:198][0m Epoch[243] Batch[100] Speed: 278.305398 samples/sec loss: -31.86575 acc: 0.81727 ce: 0.51346 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:52:35 @trainer.py:198][0m Epoch[243] Batch[200] Speed: 419.747664 samples/sec loss: -31.86599 acc: 0.81735 ce: 0.51322 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:52:50 @trainer.py:198][0m Epoch[243] Batch[300] Speed: 423.099112 samples/sec loss: -31.86622 acc: 0.81743 ce: 0.51299 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:53:05 @trainer.py:198][0m Epoch[243] Batch[400] Speed: 421.839598 samples/sec loss: -31.86644 acc: 0.81751 ce: 0.51277 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:53:21 @trainer.py:198][0m Epoch[243] Batch[500] Speed: 420.989370 samples/sec loss: -31.86668 acc: 0.81759 ce: 0.51252 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:53:36 @trainer.py:198][0m Epoch[243] Batch[600] Speed: 419.857756 samples/sec loss: -31.86692 acc: 0.81768 ce: 0.51229 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:53:39 @trainer.py:173][0m Change temperature from 0.00010 to 0.00009
[33mIP:10.60.242.134 [0m[32m[0229 20:53:44 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:53:44 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087, 0.8141, 0.8046]
[33mIP:10.60.242.134 [0m[32m[0229 20:53:44 @trainer.py:234][0m acc 0.8046
[33mIP:10.60.242.134 [0m[32m[0229 20:53:44 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:53:44 @trainer.py:217][0m Start to train w for epoch 244
[33mIP:10.60.242.134 [0m[32m[0229 20:53:44 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:53:59 @trainer.py:198][0m Epoch[244] Batch[100] Speed: 278.260448 samples/sec loss: -31.86720 acc: 0.81778 ce: 0.51201 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:54:14 @trainer.py:198][0m Epoch[244] Batch[200] Speed: 418.387217 samples/sec loss: -31.86743 acc: 0.81786 ce: 0.51178 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:54:30 @trainer.py:198][0m Epoch[244] Batch[300] Speed: 413.982666 samples/sec loss: -31.86765 acc: 0.81794 ce: 0.51156 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:54:45 @trainer.py:198][0m Epoch[244] Batch[400] Speed: 413.109921 samples/sec loss: -31.86788 acc: 0.81801 ce: 0.51133 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:55:01 @trainer.py:198][0m Epoch[244] Batch[500] Speed: 411.216649 samples/sec loss: -31.86810 acc: 0.81809 ce: 0.51111 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:55:16 @trainer.py:198][0m Epoch[244] Batch[600] Speed: 417.515459 samples/sec loss: -31.86833 acc: 0.81817 ce: 0.51088 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:55:20 @trainer.py:173][0m Change temperature from 0.00009 to 0.00009
[33mIP:10.60.242.134 [0m[32m[0229 20:55:23 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:55:23 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087, 0.8141, 0.8046, 0.8113]
[33mIP:10.60.242.134 [0m[32m[0229 20:55:23 @trainer.py:234][0m acc 0.8113
[33mIP:10.60.242.134 [0m[32m[0229 20:55:23 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:55:23 @trainer.py:217][0m Start to train w for epoch 245
[33mIP:10.60.242.134 [0m[32m[0229 20:55:23 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:55:40 @trainer.py:198][0m Epoch[245] Batch[100] Speed: 263.705945 samples/sec loss: -31.86862 acc: 0.81828 ce: 0.51059 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:55:56 @trainer.py:198][0m Epoch[245] Batch[200] Speed: 401.834212 samples/sec loss: -31.86885 acc: 0.81836 ce: 0.51036 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:56:11 @trainer.py:198][0m Epoch[245] Batch[300] Speed: 417.143768 samples/sec loss: -31.86908 acc: 0.81843 ce: 0.51013 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:56:27 @trainer.py:198][0m Epoch[245] Batch[400] Speed: 412.678744 samples/sec loss: -31.86930 acc: 0.81851 ce: 0.50991 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:56:43 @trainer.py:198][0m Epoch[245] Batch[500] Speed: 400.025155 samples/sec loss: -31.86953 acc: 0.81859 ce: 0.50968 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:56:59 @trainer.py:198][0m Epoch[245] Batch[600] Speed: 406.538597 samples/sec loss: -31.86976 acc: 0.81868 ce: 0.50945 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:57:02 @trainer.py:173][0m Change temperature from 0.00009 to 0.00009
[33mIP:10.60.242.134 [0m[32m[0229 20:57:06 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:57:06 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087, 0.8141, 0.8046, 0.8113, 0.8063]
[33mIP:10.60.242.134 [0m[32m[0229 20:57:06 @trainer.py:234][0m acc 0.8063
[33mIP:10.60.242.134 [0m[32m[0229 20:57:06 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:57:06 @trainer.py:217][0m Start to train w for epoch 246
[33mIP:10.60.242.134 [0m[32m[0229 20:57:06 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:57:23 @trainer.py:198][0m Epoch[246] Batch[100] Speed: 265.911712 samples/sec loss: -31.87004 acc: 0.81878 ce: 0.50917 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:57:39 @trainer.py:198][0m Epoch[246] Batch[200] Speed: 396.636916 samples/sec loss: -31.87026 acc: 0.81885 ce: 0.50895 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:57:55 @trainer.py:198][0m Epoch[246] Batch[300] Speed: 407.164969 samples/sec loss: -31.87049 acc: 0.81893 ce: 0.50872 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:58:10 @trainer.py:198][0m Epoch[246] Batch[400] Speed: 415.476955 samples/sec loss: -31.87071 acc: 0.81901 ce: 0.50850 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:58:26 @trainer.py:198][0m Epoch[246] Batch[500] Speed: 409.769013 samples/sec loss: -31.87094 acc: 0.81909 ce: 0.50827 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:58:41 @trainer.py:198][0m Epoch[246] Batch[600] Speed: 413.636981 samples/sec loss: -31.87116 acc: 0.81917 ce: 0.50805 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:58:45 @trainer.py:173][0m Change temperature from 0.00009 to 0.00008
[33mIP:10.60.242.134 [0m[32m[0229 20:58:48 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 20:58:48 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087, 0.8141, 0.8046, 0.8113, 0.8063, 0.8083]
[33mIP:10.60.242.134 [0m[32m[0229 20:58:48 @trainer.py:234][0m acc 0.8083
[33mIP:10.60.242.134 [0m[32m[0229 20:58:48 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 20:58:48 @trainer.py:217][0m Start to train w for epoch 247
[33mIP:10.60.242.134 [0m[32m[0229 20:58:48 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 20:59:05 @trainer.py:198][0m Epoch[247] Batch[100] Speed: 272.057449 samples/sec loss: -31.87145 acc: 0.81927 ce: 0.50776 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:59:20 @trainer.py:198][0m Epoch[247] Batch[200] Speed: 406.107621 samples/sec loss: -31.87167 acc: 0.81935 ce: 0.50754 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:59:36 @trainer.py:198][0m Epoch[247] Batch[300] Speed: 411.536752 samples/sec loss: -31.87189 acc: 0.81943 ce: 0.50732 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 20:59:51 @trainer.py:198][0m Epoch[247] Batch[400] Speed: 420.600919 samples/sec loss: -31.87211 acc: 0.81950 ce: 0.50710 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 21:00:07 @trainer.py:198][0m Epoch[247] Batch[500] Speed: 407.111134 samples/sec loss: -31.87234 acc: 0.81958 ce: 0.50687 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 21:00:23 @trainer.py:198][0m Epoch[247] Batch[600] Speed: 406.236388 samples/sec loss: -31.87257 acc: 0.81967 ce: 0.50664 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 21:00:26 @trainer.py:173][0m Change temperature from 0.00008 to 0.00008
[33mIP:10.60.242.134 [0m[32m[0229 21:00:30 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 21:00:30 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087, 0.8141, 0.8046, 0.8113, 0.8063, 0.8083, 0.8098]
[33mIP:10.60.242.134 [0m[32m[0229 21:00:30 @trainer.py:234][0m acc 0.8098
[33mIP:10.60.242.134 [0m[32m[0229 21:00:30 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 21:00:30 @trainer.py:217][0m Start to train w for epoch 248
[33mIP:10.60.242.134 [0m[32m[0229 21:00:30 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 21:00:46 @trainer.py:198][0m Epoch[248] Batch[100] Speed: 271.528664 samples/sec loss: -31.87286 acc: 0.81977 ce: 0.50635 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 21:01:02 @trainer.py:198][0m Epoch[248] Batch[200] Speed: 400.027962 samples/sec loss: -31.87308 acc: 0.81985 ce: 0.50613 lat: -16.18961
[33mIP:10.60.242.134 [0m[32m[0229 21:01:18 @trainer.py:198][0m Epoch[248] Batch[300] Speed: 414.511912 samples/sec loss: -31.87330 acc: 0.81993 ce: 0.50591 lat: -16.18961
[33mIP:10.60.242.134 [0m[32m[0229 21:01:33 @trainer.py:198][0m Epoch[248] Batch[400] Speed: 411.389793 samples/sec loss: -31.87352 acc: 0.82000 ce: 0.50569 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 21:01:48 @trainer.py:198][0m Epoch[248] Batch[500] Speed: 420.635949 samples/sec loss: -31.87374 acc: 0.82008 ce: 0.50547 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 21:02:04 @trainer.py:198][0m Epoch[248] Batch[600] Speed: 419.259100 samples/sec loss: -31.87396 acc: 0.82016 ce: 0.50525 lat: -16.18960
[33mIP:10.60.242.134 [0m[32m[0229 21:02:07 @trainer.py:173][0m Change temperature from 0.00008 to 0.00007
[33mIP:10.60.242.134 [0m[32m[0229 21:02:10 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 21:02:10 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087, 0.8141, 0.8046, 0.8113, 0.8063, 0.8083, 0.8098, 0.8071]
[33mIP:10.60.242.134 [0m[32m[0229 21:02:10 @trainer.py:234][0m acc 0.8071
[33mIP:10.60.242.134 [0m[32m[0229 21:02:10 @trainer.py:235][0m max_acc 0.8158
[33mIP:10.60.242.134 [0m[32m[0229 21:02:10 @trainer.py:217][0m Start to train w for epoch 249
[33mIP:10.60.242.134 [0m[32m[0229 21:02:10 @trainer.py:218][0m warming up until epoch 2
[33mIP:10.60.242.134 [0m[32m[0229 21:02:26 @trainer.py:198][0m Epoch[249] Batch[100] Speed: 283.103182 samples/sec loss: -31.87425 acc: 0.82026 ce: 0.50496 lat: -16.18961
[33mIP:10.60.242.134 [0m[32m[0229 21:02:42 @trainer.py:198][0m Epoch[249] Batch[200] Speed: 408.065657 samples/sec loss: -31.87447 acc: 0.82034 ce: 0.50474 lat: -16.18961
[33mIP:10.60.242.134 [0m[32m[0229 21:02:58 @trainer.py:198][0m Epoch[249] Batch[300] Speed: 408.257409 samples/sec loss: -31.87468 acc: 0.82041 ce: 0.50453 lat: -16.18961
[33mIP:10.60.242.134 [0m[32m[0229 21:03:13 @trainer.py:198][0m Epoch[249] Batch[400] Speed: 409.820012 samples/sec loss: -31.87491 acc: 0.82049 ce: 0.50430 lat: -16.18961
[33mIP:10.60.242.134 [0m[32m[0229 21:03:29 @trainer.py:198][0m Epoch[249] Batch[500] Speed: 405.674111 samples/sec loss: -31.87513 acc: 0.82057 ce: 0.50408 lat: -16.18961
[33mIP:10.60.242.134 [0m[32m[0229 21:03:45 @trainer.py:198][0m Epoch[249] Batch[600] Speed: 412.054021 samples/sec loss: -31.87536 acc: 0.82065 ce: 0.50385 lat: -16.18961
[33mIP:10.60.242.134 [0m[32m[0229 21:03:48 @trainer.py:173][0m Change temperature from 0.00007 to 0.00007
[33mIP:10.60.242.134 [0m[32m[0229 21:03:52 @trainer.py:232][0m arg_thetas are:
 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
[33mIP:10.60.242.134 [0m[32m[0229 21:03:52 @trainer.py:233][0m acc curve [0.2524, 0.3558, 0.3917, 0.4345, 0.4671, 0.4898, 0.4984, 0.4889, 0.5301, 0.5267, 0.5648, 0.5835, 0.5788, 0.5892, 0.586, 0.5662, 0.5761, 0.5975, 0.6225, 0.617, 0.6389, 0.6494, 0.6441, 0.6533, 0.6646, 0.6589, 0.6685, 0.6709, 0.6681, 0.6704, 0.6586, 0.6369, 0.6706, 0.6694, 0.6772, 0.6771, 0.6953, 0.6887, 0.6963, 0.6942, 0.6867, 0.7054, 0.7105, 0.7138, 0.7257, 0.7391, 0.733, 0.7309, 0.7371, 0.7337, 0.7327, 0.7473, 0.7418, 0.7427, 0.7448, 0.7469, 0.747, 0.7487, 0.744, 0.7481, 0.7433, 0.7495, 0.7493, 0.7283, 0.7322, 0.713, 0.7345, 0.736, 0.7368, 0.73, 0.7353, 0.7446, 0.7389, 0.754, 0.7431, 0.7572, 0.7488, 0.7606, 0.7447, 0.76, 0.7588, 0.7646, 0.7638, 0.7648, 0.761, 0.77, 0.7652, 0.7698, 0.774, 0.7682, 0.7686, 0.7836, 0.773, 0.7832, 0.7776, 0.7874, 0.7797, 0.7829, 0.7844, 0.7857, 0.7775, 0.7759, 0.7868, 0.7827, 0.7794, 0.7831, 0.792, 0.7918, 0.7919, 0.7875, 0.7846, 0.7842, 0.7897, 0.7823, 0.7868, 0.788, 0.7927, 0.7872, 0.785, 0.7886, 0.7897, 0.7947, 0.7916, 0.7875, 0.7875, 0.7882, 0.7898, 0.77, 0.7594, 0.7776, 0.77, 0.7622, 0.7769, 0.7699, 0.7707, 0.7754, 0.7727, 0.7829, 0.7691, 0.7846, 0.777, 0.7883, 0.7784, 0.7767, 0.7813, 0.7836, 0.7927, 0.7856, 0.7888, 0.7896, 0.7941, 0.7936, 0.7891, 0.7958, 0.7814, 0.7838, 0.793, 0.7989, 0.7912, 0.7914, 0.7978, 0.7959, 0.7998, 0.7946, 0.8029, 0.7878, 0.793, 0.7978, 0.7922, 0.7892, 0.8027, 0.8024, 0.8057, 0.8015, 0.7981, 0.7994, 0.7974, 0.8058, 0.7947, 0.8031, 0.7971, 0.8046, 0.7965, 0.8014, 0.8023, 0.8024, 0.8022, 0.8056, 0.8051, 0.8102, 0.8098, 0.8013, 0.803, 0.8144, 0.8105, 0.8003, 0.7997, 0.8097, 0.8071, 0.8065, 0.8131, 0.8103, 0.8095, 0.8056, 0.8061, 0.808, 0.8079, 0.8065, 0.8089, 0.805, 0.8125, 0.8085, 0.8158, 0.8062, 0.8062, 0.8131, 0.805, 0.7981, 0.8086, 0.8089, 0.8099, 0.8096, 0.8101, 0.8109, 0.8029, 0.8106, 0.8099, 0.8089, 0.8085, 0.8034, 0.802, 0.8109, 0.807, 0.8144, 0.8092, 0.8089, 0.8112, 0.8071, 0.8102, 0.8127, 0.8086, 0.8087, 0.8141, 0.8046, 0.8113, 0.8063, 0.8083, 0.8098, 0.8071, 0.8081]
[33mIP:10.60.242.134 [0m[32m[0229 21:03:52 @trainer.py:234][0m acc 0.8081
[33mIP:10.60.242.134 [0m[32m[0229 21:03:52 @trainer.py:235][0m max_acc 0.8158
